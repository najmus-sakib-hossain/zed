{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "all",
  "type": "registry:ui",
  "description": "All UI components from ElevenLabs UI",
  "dependencies": [
    "@elevenlabs/elevenlabs-js",
    "@elevenlabs/react",
    "@radix-ui/react-dropdown-menu",
    "@radix-ui/react-slider",
    "@react-three/drei",
    "@react-three/fiber",
    "@types/three",
    "class-variance-authority",
    "lucide-react",
    "motion",
    "streamdown",
    "three",
    "use-stick-to-bottom"
  ],
  "registryDependencies": [
    "avatar",
    "badge",
    "button",
    "card",
    "command",
    "dropdown-menu",
    "https://ui.elevenlabs.io/r/audio-player.json",
    "https://ui.elevenlabs.io/r/live-waveform.json",
    "https://ui.elevenlabs.io/r/orb.json",
    "https://ui.elevenlabs.io/r/scrub-bar.json",
    "https://ui.elevenlabs.io/r/use-scribe.json",
    "popover",
    "progress",
    "separator",
    "textarea"
  ],
  "files": [
    {
      "path": "components/ui/orb.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport { useEffect, useMemo, useRef } from \"react\"\nimport { useTexture } from \"@react-three/drei\"\nimport { Canvas, useFrame, useThree } from \"@react-three/fiber\"\nimport * as THREE from \"three\"\n\nexport type AgentState = null | \"thinking\" | \"listening\" | \"talking\"\n\ntype OrbProps = {\n  colors?: [string, string]\n  colorsRef?: React.RefObject<[string, string]>\n  resizeDebounce?: number\n  seed?: number\n  agentState?: AgentState\n  volumeMode?: \"auto\" | \"manual\"\n  manualInput?: number\n  manualOutput?: number\n  inputVolumeRef?: React.RefObject<number>\n  outputVolumeRef?: React.RefObject<number>\n  getInputVolume?: () => number\n  getOutputVolume?: () => number\n  className?: string\n}\n\nexport function Orb({\n  colors = [\"#CADCFC\", \"#A0B9D1\"],\n  colorsRef,\n  resizeDebounce = 100,\n  seed,\n  agentState = null,\n  volumeMode = \"auto\",\n  manualInput,\n  manualOutput,\n  inputVolumeRef,\n  outputVolumeRef,\n  getInputVolume,\n  getOutputVolume,\n  className,\n}: OrbProps) {\n  return (\n    <div className={className ?? \"relative h-full w-full\"}>\n      <Canvas\n        resize={{ debounce: resizeDebounce }}\n        gl={{\n          alpha: true,\n          antialias: true,\n          premultipliedAlpha: true,\n        }}\n      >\n        <Scene\n          colors={colors}\n          colorsRef={colorsRef}\n          seed={seed}\n          agentState={agentState}\n          volumeMode={volumeMode}\n          manualInput={manualInput}\n          manualOutput={manualOutput}\n          inputVolumeRef={inputVolumeRef}\n          outputVolumeRef={outputVolumeRef}\n          getInputVolume={getInputVolume}\n          getOutputVolume={getOutputVolume}\n        />\n      </Canvas>\n    </div>\n  )\n}\n\nfunction Scene({\n  colors,\n  colorsRef,\n  seed,\n  agentState,\n  volumeMode,\n  manualInput,\n  manualOutput,\n  inputVolumeRef,\n  outputVolumeRef,\n  getInputVolume,\n  getOutputVolume,\n}: {\n  colors: [string, string]\n  colorsRef?: React.RefObject<[string, string]>\n  seed?: number\n  agentState: AgentState\n  volumeMode: \"auto\" | \"manual\"\n  manualInput?: number\n  manualOutput?: number\n  inputVolumeRef?: React.RefObject<number>\n  outputVolumeRef?: React.RefObject<number>\n  getInputVolume?: () => number\n  getOutputVolume?: () => number\n}) {\n  const { gl } = useThree()\n  const circleRef =\n    useRef<THREE.Mesh<THREE.CircleGeometry, THREE.ShaderMaterial>>(null)\n  const initialColorsRef = useRef<[string, string]>(colors)\n  const targetColor1Ref = useRef(new THREE.Color(colors[0]))\n  const targetColor2Ref = useRef(new THREE.Color(colors[1]))\n  const animSpeedRef = useRef(0.1)\n  const perlinNoiseTexture = useTexture(\n    \"https://storage.googleapis.com/eleven-public-cdn/images/perlin-noise.png\"\n  )\n\n  const agentRef = useRef<AgentState>(agentState)\n  const modeRef = useRef<\"auto\" | \"manual\">(volumeMode)\n  const manualInRef = useRef<number>(manualInput ?? 0)\n  const manualOutRef = useRef<number>(manualOutput ?? 0)\n  const curInRef = useRef(0)\n  const curOutRef = useRef(0)\n\n  useEffect(() => {\n    agentRef.current = agentState\n  }, [agentState])\n\n  useEffect(() => {\n    modeRef.current = volumeMode\n  }, [volumeMode])\n\n  useEffect(() => {\n    manualInRef.current = clamp01(\n      manualInput ?? inputVolumeRef?.current ?? getInputVolume?.() ?? 0\n    )\n  }, [manualInput, inputVolumeRef, getInputVolume])\n\n  useEffect(() => {\n    manualOutRef.current = clamp01(\n      manualOutput ?? outputVolumeRef?.current ?? getOutputVolume?.() ?? 0\n    )\n  }, [manualOutput, outputVolumeRef, getOutputVolume])\n\n  const random = useMemo(\n    () => splitmix32(seed ?? Math.floor(Math.random() * 2 ** 32)),\n    [seed]\n  )\n  const offsets = useMemo(\n    () =>\n      new Float32Array(Array.from({ length: 7 }, () => random() * Math.PI * 2)),\n    [random]\n  )\n\n  useEffect(() => {\n    targetColor1Ref.current = new THREE.Color(colors[0])\n    targetColor2Ref.current = new THREE.Color(colors[1])\n  }, [colors])\n\n  useEffect(() => {\n    const apply = () => {\n      if (!circleRef.current) return\n      const isDark = document.documentElement.classList.contains(\"dark\")\n      circleRef.current.material.uniforms.uInverted.value = isDark ? 1 : 0\n    }\n\n    apply()\n\n    const observer = new MutationObserver(apply)\n    observer.observe(document.documentElement, {\n      attributes: true,\n      attributeFilter: [\"class\"],\n    })\n    return () => observer.disconnect()\n  }, [])\n\n  useFrame((_, delta: number) => {\n    const mat = circleRef.current?.material\n    if (!mat) return\n    const live = colorsRef?.current\n    if (live) {\n      if (live[0]) targetColor1Ref.current.set(live[0])\n      if (live[1]) targetColor2Ref.current.set(live[1])\n    }\n    const u = mat.uniforms\n    u.uTime.value += delta * 0.5\n\n    if (u.uOpacity.value < 1) {\n      u.uOpacity.value = Math.min(1, u.uOpacity.value + delta * 2)\n    }\n\n    let targetIn = 0\n    let targetOut = 0.3\n    if (modeRef.current === \"manual\") {\n      targetIn = clamp01(\n        manualInput ?? inputVolumeRef?.current ?? getInputVolume?.() ?? 0\n      )\n      targetOut = clamp01(\n        manualOutput ?? outputVolumeRef?.current ?? getOutputVolume?.() ?? 0\n      )\n    } else {\n      const t = u.uTime.value * 2\n      if (agentRef.current === null) {\n        targetIn = 0\n        targetOut = 0.3\n      } else if (agentRef.current === \"listening\") {\n        targetIn = clamp01(0.55 + Math.sin(t * 3.2) * 0.35)\n        targetOut = 0.45\n      } else if (agentRef.current === \"talking\") {\n        targetIn = clamp01(0.65 + Math.sin(t * 4.8) * 0.22)\n        targetOut = clamp01(0.75 + Math.sin(t * 3.6) * 0.22)\n      } else {\n        const base = 0.38 + 0.07 * Math.sin(t * 0.7)\n        const wander = 0.05 * Math.sin(t * 2.1) * Math.sin(t * 0.37 + 1.2)\n        targetIn = clamp01(base + wander)\n        targetOut = clamp01(0.48 + 0.12 * Math.sin(t * 1.05 + 0.6))\n      }\n    }\n\n    curInRef.current += (targetIn - curInRef.current) * 0.2\n    curOutRef.current += (targetOut - curOutRef.current) * 0.2\n\n    const targetSpeed = 0.1 + (1 - Math.pow(curOutRef.current - 1, 2)) * 0.9\n    animSpeedRef.current += (targetSpeed - animSpeedRef.current) * 0.12\n\n    u.uAnimation.value += delta * animSpeedRef.current\n    u.uInputVolume.value = curInRef.current\n    u.uOutputVolume.value = curOutRef.current\n    u.uColor1.value.lerp(targetColor1Ref.current, 0.08)\n    u.uColor2.value.lerp(targetColor2Ref.current, 0.08)\n  })\n\n  useEffect(() => {\n    const canvas = gl.domElement\n    const onContextLost = (event: Event) => {\n      event.preventDefault()\n      setTimeout(() => {\n        gl.forceContextRestore()\n      }, 1)\n    }\n    canvas.addEventListener(\"webglcontextlost\", onContextLost, false)\n    return () =>\n      canvas.removeEventListener(\"webglcontextlost\", onContextLost, false)\n  }, [gl])\n\n  const uniforms = useMemo(() => {\n    perlinNoiseTexture.wrapS = THREE.RepeatWrapping\n    perlinNoiseTexture.wrapT = THREE.RepeatWrapping\n    const isDark =\n      typeof document !== \"undefined\" &&\n      document.documentElement.classList.contains(\"dark\")\n    return {\n      uColor1: new THREE.Uniform(new THREE.Color(initialColorsRef.current[0])),\n      uColor2: new THREE.Uniform(new THREE.Color(initialColorsRef.current[1])),\n      uOffsets: { value: offsets },\n      uPerlinTexture: new THREE.Uniform(perlinNoiseTexture),\n      uTime: new THREE.Uniform(0),\n      uAnimation: new THREE.Uniform(0.1),\n      uInverted: new THREE.Uniform(isDark ? 1 : 0),\n      uInputVolume: new THREE.Uniform(0),\n      uOutputVolume: new THREE.Uniform(0),\n      uOpacity: new THREE.Uniform(0),\n    }\n  }, [perlinNoiseTexture, offsets])\n\n  return (\n    <mesh ref={circleRef}>\n      <circleGeometry args={[3.5, 64]} />\n      <shaderMaterial\n        uniforms={uniforms}\n        fragmentShader={fragmentShader}\n        vertexShader={vertexShader}\n        transparent={true}\n      />\n    </mesh>\n  )\n}\n\nfunction splitmix32(a: number) {\n  return function () {\n    a |= 0\n    a = (a + 0x9e3779b9) | 0\n    let t = a ^ (a >>> 16)\n    t = Math.imul(t, 0x21f0aaad)\n    t = t ^ (t >>> 15)\n    t = Math.imul(t, 0x735a2d97)\n    return ((t = t ^ (t >>> 15)) >>> 0) / 4294967296\n  }\n}\n\nfunction clamp01(n: number) {\n  if (!Number.isFinite(n)) return 0\n  return Math.min(1, Math.max(0, n))\n}\nconst vertexShader = /* glsl */ `\nuniform float uTime;\nuniform sampler2D uPerlinTexture;\nvarying vec2 vUv;\n\nvoid main() {\n  vUv = uv;\n  gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n}\n`\n\nconst fragmentShader = /* glsl */ `\nuniform float uTime;\nuniform float uAnimation;\nuniform float uInverted;\nuniform float uOffsets[7];\nuniform vec3 uColor1;\nuniform vec3 uColor2;\nuniform float uInputVolume;\nuniform float uOutputVolume;\nuniform float uOpacity;\nuniform sampler2D uPerlinTexture;\nvarying vec2 vUv;\n\nconst float PI = 3.14159265358979323846;\n\n// Draw a single oval with soft edges and calculate its gradient color\nbool drawOval(vec2 polarUv, vec2 polarCenter, float a, float b, bool reverseGradient, float softness, out vec4 color) {\n    vec2 p = polarUv - polarCenter;\n    float oval = (p.x * p.x) / (a * a) + (p.y * p.y) / (b * b);\n\n    float edge = smoothstep(1.0, 1.0 - softness, oval);\n\n    if (edge > 0.0) {\n        float gradient = reverseGradient ? (1.0 - (p.x / a + 1.0) / 2.0) : ((p.x / a + 1.0) / 2.0);\n        // Flatten gradient toward middle value for more uniform appearance\n        gradient = mix(0.5, gradient, 0.1);\n        color = vec4(vec3(gradient), 0.85 * edge);\n        return true;\n    }\n    return false;\n}\n\n// Map grayscale value to a 4-color ramp (color1, color2, color3, color4)\nvec3 colorRamp(float grayscale, vec3 color1, vec3 color2, vec3 color3, vec3 color4) {\n    if (grayscale < 0.33) {\n        return mix(color1, color2, grayscale * 3.0);\n    } else if (grayscale < 0.66) {\n        return mix(color2, color3, (grayscale - 0.33) * 3.0);\n    } else {\n        return mix(color3, color4, (grayscale - 0.66) * 3.0);\n    }\n}\n\nvec2 hash2(vec2 p) {\n    return fract(sin(vec2(dot(p, vec2(127.1, 311.7)), dot(p, vec2(269.5, 183.3)))) * 43758.5453);\n}\n\n// 2D noise for the ring\nfloat noise2D(vec2 p) {\n    vec2 i = floor(p);\n    vec2 f = fract(p);\n    \n    vec2 u = f * f * (3.0 - 2.0 * f);\n    float n = mix(\n        mix(dot(hash2(i + vec2(0.0, 0.0)), f - vec2(0.0, 0.0)),\n            dot(hash2(i + vec2(1.0, 0.0)), f - vec2(1.0, 0.0)), u.x),\n        mix(dot(hash2(i + vec2(0.0, 1.0)), f - vec2(0.0, 1.0)),\n            dot(hash2(i + vec2(1.0, 1.0)), f - vec2(1.0, 1.0)), u.x),\n        u.y\n    );\n\n    return 0.5 + 0.5 * n;\n}\n\nfloat sharpRing(vec3 decomposed, float time) {\n    float ringStart = 1.0;\n    float ringWidth = 0.3;\n    float noiseScale = 5.0;\n\n    float noise = mix(\n        noise2D(vec2(decomposed.x, time) * noiseScale),\n        noise2D(vec2(decomposed.y, time) * noiseScale),\n        decomposed.z\n    );\n\n    noise = (noise - 0.5) * 2.5;\n\n    return ringStart + noise * ringWidth * 1.5;\n}\n\nfloat smoothRing(vec3 decomposed, float time) {\n    float ringStart = 0.9;\n    float ringWidth = 0.2;\n    float noiseScale = 6.0;\n\n    float noise = mix(\n        noise2D(vec2(decomposed.x, time) * noiseScale),\n        noise2D(vec2(decomposed.y, time) * noiseScale),\n        decomposed.z\n    );\n\n    noise = (noise - 0.5) * 5.0;\n\n    return ringStart + noise * ringWidth;\n}\n\nfloat flow(vec3 decomposed, float time) {\n    return mix(\n        texture(uPerlinTexture, vec2(time, decomposed.x / 2.0)).r,\n        texture(uPerlinTexture, vec2(time, decomposed.y / 2.0)).r,\n        decomposed.z\n    );\n}\n\nvoid main() {\n    // Normalize vUv to be centered around (0.0, 0.0)\n    vec2 uv = vUv * 2.0 - 1.0;\n\n    // Convert uv to polar coordinates\n    float radius = length(uv);\n    float theta = atan(uv.y, uv.x);\n    if (theta < 0.0) theta += 2.0 * PI; // Normalize theta to [0, 2*PI]\n\n    // Decomposed angle is used for sampling noise textures without seams:\n    // float noise = mix(sample(decomposed.x), sample(decomposed.y), decomposed.z);\n    vec3 decomposed = vec3(\n        // angle in the range [0, 1]\n        theta / (2.0 * PI),\n        // angle offset by 180 degrees in the range [1, 2]\n        mod(theta / (2.0 * PI) + 0.5, 1.0) + 1.0,\n        // mixing factor between two noises\n        abs(theta / PI - 1.0)\n    );\n\n    // Add noise to the angle for a flow-like distortion (reduced for flatter look)\n    float noise = flow(decomposed, radius * 0.03 - uAnimation * 0.2) - 0.5;\n    theta += noise * mix(0.08, 0.25, uOutputVolume);\n\n    // Initialize the base color to white\n    vec4 color = vec4(1.0, 1.0, 1.0, 1.0);\n\n    // Original parameters for the ovals in polar coordinates\n    float originalCenters[7] = float[7](0.0, 0.5 * PI, 1.0 * PI, 1.5 * PI, 2.0 * PI, 2.5 * PI, 3.0 * PI);\n\n    // Parameters for the animated centers in polar coordinates\n    float centers[7];\n    for (int i = 0; i < 7; i++) {\n        centers[i] = originalCenters[i] + 0.5 * sin(uTime / 20.0 + uOffsets[i]);\n    }\n\n    float a, b;\n    vec4 ovalColor;\n\n    // Check if the pixel is inside any of the ovals\n    for (int i = 0; i < 7; i++) {\n        float noise = texture(uPerlinTexture, vec2(mod(centers[i] + uTime * 0.05, 1.0), 0.5)).r;\n        a = 0.5 + noise * 0.3; // Increased for more coverage\n        b = noise * mix(3.5, 2.5, uInputVolume); // Increased height for fuller appearance\n        bool reverseGradient = (i % 2 == 1); // Reverse gradient for every second oval\n\n        // Calculate the distance in polar coordinates\n        float distTheta = min(\n            abs(theta - centers[i]),\n            min(\n                abs(theta + 2.0 * PI - centers[i]),\n                abs(theta - 2.0 * PI - centers[i])\n            )\n        );\n        float distRadius = radius;\n\n        float softness = 0.6; // Increased softness for flatter, less pronounced edges\n\n        // Check if the pixel is inside the oval in polar coordinates\n        if (drawOval(vec2(distTheta, distRadius), vec2(0.0, 0.0), a, b, reverseGradient, softness, ovalColor)) {\n            // Blend the oval color with the existing color\n            color.rgb = mix(color.rgb, ovalColor.rgb, ovalColor.a);\n            color.a = max(color.a, ovalColor.a); // Max alpha\n        }\n    }\n    \n    // Calculate both noisy rings\n    float ringRadius1 = sharpRing(decomposed, uTime * 0.1);\n    float ringRadius2 = smoothRing(decomposed, uTime * 0.1);\n    \n    // Adjust rings based on input volume (reduced for flatter appearance)\n    float inputRadius1 = radius + uInputVolume * 0.2;\n    float inputRadius2 = radius + uInputVolume * 0.15;\n    float opacity1 = mix(0.2, 0.6, uInputVolume);\n    float opacity2 = mix(0.15, 0.45, uInputVolume);\n\n    // Blend both rings\n    float ringAlpha1 = (inputRadius2 >= ringRadius1) ? opacity1 : 0.0;\n    float ringAlpha2 = smoothstep(ringRadius2 - 0.05, ringRadius2 + 0.05, inputRadius1) * opacity2;\n    \n    float totalRingAlpha = max(ringAlpha1, ringAlpha2);\n    \n    // Apply screen blend mode for combined rings\n    vec3 ringColor = vec3(1.0); // White ring color\n    color.rgb = 1.0 - (1.0 - color.rgb) * (1.0 - ringColor * totalRingAlpha);\n\n    // Define colours to ramp against greyscale (could increase the amount of colours in the ramp)\n    vec3 color1 = vec3(0.0, 0.0, 0.0); // Black\n    vec3 color2 = uColor1; // Darker Color\n    vec3 color3 = uColor2; // Lighter Color\n    vec3 color4 = vec3(1.0, 1.0, 1.0); // White\n\n    // Convert grayscale color to the color ramp\n    float luminance = mix(color.r, 1.0 - color.r, uInverted);\n    color.rgb = colorRamp(luminance, color1, color2, color3, color4); // Apply the color ramp\n\n    // Apply fade-in opacity\n    color.a *= uOpacity;\n\n    gl_FragColor = color;\n}\n`\n"
    },
    {
      "path": "components/ui/waveform.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport {\n  useCallback,\n  useEffect,\n  useMemo,\n  useRef,\n  useState,\n  type HTMLAttributes,\n} from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nexport type WaveformProps = HTMLAttributes<HTMLDivElement> & {\n  data?: number[]\n  barWidth?: number\n  barHeight?: number\n  barGap?: number\n  barRadius?: number\n  barColor?: string\n  fadeEdges?: boolean\n  fadeWidth?: number\n  height?: string | number\n  active?: boolean\n  onBarClick?: (index: number, value: number) => void\n}\n\nexport const Waveform = ({\n  data = [],\n  barWidth = 4,\n  barHeight: baseBarHeight = 4,\n  barGap = 2,\n  barRadius = 2,\n  barColor,\n  fadeEdges = true,\n  fadeWidth = 24,\n  height = 128,\n  onBarClick,\n  className,\n  ...props\n}: WaveformProps) => {\n  const canvasRef = useRef<HTMLCanvasElement>(null)\n  const containerRef = useRef<HTMLDivElement>(null)\n  const heightStyle = typeof height === \"number\" ? `${height}px` : height\n\n  useEffect(() => {\n    const canvas = canvasRef.current\n    const container = containerRef.current\n    if (!canvas || !container) return\n\n    const resizeObserver = new ResizeObserver(() => {\n      const rect = container.getBoundingClientRect()\n      const dpr = window.devicePixelRatio || 1\n\n      canvas.width = rect.width * dpr\n      canvas.height = rect.height * dpr\n      canvas.style.width = `${rect.width}px`\n      canvas.style.height = `${rect.height}px`\n\n      const ctx = canvas.getContext(\"2d\")\n      if (ctx) {\n        ctx.scale(dpr, dpr)\n        renderWaveform()\n      }\n    })\n\n    const renderWaveform = () => {\n      const ctx = canvas.getContext(\"2d\")\n      if (!ctx) return\n\n      const rect = canvas.getBoundingClientRect()\n      ctx.clearRect(0, 0, rect.width, rect.height)\n\n      const computedBarColor =\n        barColor ||\n        getComputedStyle(canvas).getPropertyValue(\"--foreground\") ||\n        \"#000\"\n\n      const barCount = Math.floor(rect.width / (barWidth + barGap))\n      const centerY = rect.height / 2\n\n      for (let i = 0; i < barCount; i++) {\n        const dataIndex = Math.floor((i / barCount) * data.length)\n        const value = data[dataIndex] || 0\n        const barHeight = Math.max(baseBarHeight, value * rect.height * 0.8)\n        const x = i * (barWidth + barGap)\n        const y = centerY - barHeight / 2\n\n        ctx.fillStyle = computedBarColor\n        ctx.globalAlpha = 0.3 + value * 0.7\n\n        if (barRadius > 0) {\n          ctx.beginPath()\n          ctx.roundRect(x, y, barWidth, barHeight, barRadius)\n          ctx.fill()\n        } else {\n          ctx.fillRect(x, y, barWidth, barHeight)\n        }\n      }\n\n      if (fadeEdges && fadeWidth > 0 && rect.width > 0) {\n        const gradient = ctx.createLinearGradient(0, 0, rect.width, 0)\n        const fadePercent = Math.min(0.2, fadeWidth / rect.width)\n\n        gradient.addColorStop(0, \"rgba(255,255,255,1)\")\n        gradient.addColorStop(fadePercent, \"rgba(255,255,255,0)\")\n        gradient.addColorStop(1 - fadePercent, \"rgba(255,255,255,0)\")\n        gradient.addColorStop(1, \"rgba(255,255,255,1)\")\n\n        ctx.globalCompositeOperation = \"destination-out\"\n        ctx.fillStyle = gradient\n        ctx.fillRect(0, 0, rect.width, rect.height)\n        ctx.globalCompositeOperation = \"source-over\"\n      }\n\n      ctx.globalAlpha = 1\n    }\n\n    resizeObserver.observe(container)\n    renderWaveform()\n\n    return () => resizeObserver.disconnect()\n  }, [\n    data,\n    barWidth,\n    baseBarHeight,\n    barGap,\n    barRadius,\n    barColor,\n    fadeEdges,\n    fadeWidth,\n  ])\n\n  const handleClick = (e: React.MouseEvent<HTMLCanvasElement>) => {\n    if (!onBarClick) return\n\n    const rect = canvasRef.current?.getBoundingClientRect()\n    if (!rect) return\n\n    const x = e.clientX - rect.left\n    const barIndex = Math.floor(x / (barWidth + barGap))\n    const dataIndex = Math.floor(\n      (barIndex * data.length) / Math.floor(rect.width / (barWidth + barGap))\n    )\n\n    if (dataIndex >= 0 && dataIndex < data.length) {\n      onBarClick(dataIndex, data[dataIndex])\n    }\n  }\n\n  return (\n    <div\n      className={cn(\"relative\", className)}\n      ref={containerRef}\n      style={{ height: heightStyle }}\n      {...props}\n    >\n      <canvas\n        className=\"block h-full w-full\"\n        onClick={handleClick}\n        ref={canvasRef}\n      />\n    </div>\n  )\n}\n\nexport type ScrollingWaveformProps = Omit<\n  WaveformProps,\n  \"data\" | \"onBarClick\"\n> & {\n  speed?: number\n  barCount?: number\n  data?: number[]\n}\n\nexport const ScrollingWaveform = ({\n  speed = 50,\n  barCount = 60,\n  barWidth = 4,\n  barHeight: baseBarHeight = 4,\n  barGap = 2,\n  barRadius = 2,\n  barColor,\n  fadeEdges = true,\n  fadeWidth = 24,\n  height = 128,\n  data,\n  className,\n  ...props\n}: ScrollingWaveformProps) => {\n  const canvasRef = useRef<HTMLCanvasElement>(null)\n  const containerRef = useRef<HTMLDivElement>(null)\n  const barsRef = useRef<Array<{ x: number; height: number }>>([])\n  const animationRef = useRef<number>(0)\n  const lastTimeRef = useRef<number>(0)\n  const seedRef = useRef(Math.random())\n  const dataIndexRef = useRef(0)\n  const heightStyle = typeof height === \"number\" ? `${height}px` : height\n\n  useEffect(() => {\n    const canvas = canvasRef.current\n    const container = containerRef.current\n    if (!canvas || !container) return\n\n    const resizeObserver = new ResizeObserver(() => {\n      const rect = container.getBoundingClientRect()\n      const dpr = window.devicePixelRatio || 1\n\n      canvas.width = rect.width * dpr\n      canvas.height = rect.height * dpr\n      canvas.style.width = `${rect.width}px`\n      canvas.style.height = `${rect.height}px`\n\n      const ctx = canvas.getContext(\"2d\")\n      if (ctx) {\n        ctx.scale(dpr, dpr)\n      }\n\n      if (barsRef.current.length === 0) {\n        const step = barWidth + barGap\n        let currentX = rect.width\n        let index = 0\n        const seededRandom = (i: number) => {\n          const x = Math.sin(seedRef.current * 10000 + i) * 10000\n          return x - Math.floor(x)\n        }\n        while (currentX > -step) {\n          barsRef.current.push({\n            x: currentX,\n            height: 0.2 + seededRandom(index++) * 0.6,\n          })\n          currentX -= step\n        }\n      }\n    })\n\n    resizeObserver.observe(container)\n    return () => resizeObserver.disconnect()\n  }, [barWidth, barGap])\n\n  useEffect(() => {\n    const canvas = canvasRef.current\n    if (!canvas) return\n\n    const ctx = canvas.getContext(\"2d\")\n    if (!ctx) return\n\n    const animate = (currentTime: number) => {\n      const deltaTime = lastTimeRef.current\n        ? (currentTime - lastTimeRef.current) / 1000\n        : 0\n      lastTimeRef.current = currentTime\n\n      const rect = canvas.getBoundingClientRect()\n      ctx.clearRect(0, 0, rect.width, rect.height)\n\n      const computedBarColor =\n        barColor ||\n        getComputedStyle(canvas).getPropertyValue(\"--foreground\") ||\n        \"#000\"\n\n      const step = barWidth + barGap\n      for (let i = 0; i < barsRef.current.length; i++) {\n        barsRef.current[i].x -= speed * deltaTime\n      }\n\n      barsRef.current = barsRef.current.filter(\n        (bar) => bar.x + barWidth > -step\n      )\n\n      while (\n        barsRef.current.length === 0 ||\n        barsRef.current[barsRef.current.length - 1].x < rect.width\n      ) {\n        const lastBar = barsRef.current[barsRef.current.length - 1]\n        const nextX = lastBar ? lastBar.x + step : rect.width\n\n        let newHeight: number\n        if (data && data.length > 0) {\n          newHeight = data[dataIndexRef.current % data.length] || 0.1\n          dataIndexRef.current = (dataIndexRef.current + 1) % data.length\n        } else {\n          const time = Date.now() / 1000\n          const uniqueIndex = barsRef.current.length + time * 0.01\n          const seededRandom = (index: number) => {\n            const x = Math.sin(seedRef.current * 10000 + index * 137.5) * 10000\n            return x - Math.floor(x)\n          }\n          const wave1 = Math.sin(uniqueIndex * 0.1) * 0.2\n          const wave2 = Math.cos(uniqueIndex * 0.05) * 0.15\n          const randomComponent = seededRandom(uniqueIndex) * 0.4\n          newHeight = Math.max(\n            0.1,\n            Math.min(0.9, 0.3 + wave1 + wave2 + randomComponent)\n          )\n        }\n\n        barsRef.current.push({\n          x: nextX,\n          height: newHeight,\n        })\n        if (barsRef.current.length > barCount * 2) break\n      }\n\n      const centerY = rect.height / 2\n      for (const bar of barsRef.current) {\n        if (bar.x < rect.width && bar.x + barWidth > 0) {\n          const barHeight = Math.max(\n            baseBarHeight,\n            bar.height * rect.height * 0.6\n          )\n          const y = centerY - barHeight / 2\n\n          ctx.fillStyle = computedBarColor\n          ctx.globalAlpha = 0.3 + bar.height * 0.7\n\n          if (barRadius > 0) {\n            ctx.beginPath()\n            ctx.roundRect(bar.x, y, barWidth, barHeight, barRadius)\n            ctx.fill()\n          } else {\n            ctx.fillRect(bar.x, y, barWidth, barHeight)\n          }\n        }\n      }\n\n      if (fadeEdges && fadeWidth > 0) {\n        const gradient = ctx.createLinearGradient(0, 0, rect.width, 0)\n        const fadePercent = Math.min(0.2, fadeWidth / rect.width)\n\n        gradient.addColorStop(0, \"rgba(255,255,255,1)\")\n        gradient.addColorStop(fadePercent, \"rgba(255,255,255,0)\")\n        gradient.addColorStop(1 - fadePercent, \"rgba(255,255,255,0)\")\n        gradient.addColorStop(1, \"rgba(255,255,255,1)\")\n\n        ctx.globalCompositeOperation = \"destination-out\"\n        ctx.fillStyle = gradient\n        ctx.fillRect(0, 0, rect.width, rect.height)\n        ctx.globalCompositeOperation = \"source-over\"\n      }\n\n      ctx.globalAlpha = 1\n\n      animationRef.current = requestAnimationFrame(animate)\n    }\n\n    animationRef.current = requestAnimationFrame(animate)\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current)\n      }\n    }\n  }, [\n    speed,\n    barCount,\n    barWidth,\n    baseBarHeight,\n    barGap,\n    barRadius,\n    barColor,\n    fadeEdges,\n    fadeWidth,\n    data,\n  ])\n\n  return (\n    <div\n      className={cn(\"relative flex items-center\", className)}\n      ref={containerRef}\n      style={{ height: heightStyle }}\n      {...props}\n    >\n      <canvas className=\"block h-full w-full\" ref={canvasRef} />\n    </div>\n  )\n}\n\nexport type AudioScrubberProps = WaveformProps & {\n  currentTime?: number\n  duration?: number\n  onSeek?: (time: number) => void\n  showHandle?: boolean\n}\n\nexport const AudioScrubber = ({\n  data = [],\n  currentTime = 0,\n  duration = 100,\n  onSeek,\n  showHandle = true,\n  barWidth = 3,\n  barHeight,\n  barGap = 1,\n  barRadius = 1,\n  barColor,\n  height = 128,\n  className,\n  ...props\n}: AudioScrubberProps) => {\n  const [isDragging, setIsDragging] = useState(false)\n  const [localProgress, setLocalProgress] = useState(0)\n  const containerRef = useRef<HTMLDivElement>(null)\n\n  const waveformData =\n    data.length > 0\n      ? data\n      : Array.from({ length: 100 }, () => 0.2 + Math.random() * 0.6)\n\n  useEffect(() => {\n    if (!isDragging && duration > 0) {\n      setLocalProgress(currentTime / duration)\n    }\n  }, [currentTime, duration, isDragging])\n\n  const handleScrub = useCallback(\n    (clientX: number) => {\n      const container = containerRef.current\n      if (!container) return\n\n      const rect = container.getBoundingClientRect()\n      const x = Math.max(0, Math.min(clientX - rect.left, rect.width))\n      const progress = x / rect.width\n      const newTime = progress * duration\n\n      setLocalProgress(progress)\n      onSeek?.(newTime)\n    },\n    [duration, onSeek]\n  )\n\n  const handleMouseDown = (e: React.MouseEvent<HTMLDivElement>) => {\n    e.preventDefault()\n    setIsDragging(true)\n    handleScrub(e.clientX)\n  }\n\n  useEffect(() => {\n    if (!isDragging) return\n\n    const handleMouseMove = (e: MouseEvent) => {\n      handleScrub(e.clientX)\n    }\n\n    const handleMouseUp = () => {\n      setIsDragging(false)\n    }\n\n    document.addEventListener(\"mousemove\", handleMouseMove)\n    document.addEventListener(\"mouseup\", handleMouseUp)\n\n    return () => {\n      document.removeEventListener(\"mousemove\", handleMouseMove)\n      document.removeEventListener(\"mouseup\", handleMouseUp)\n    }\n  }, [isDragging, duration, handleScrub])\n\n  const heightStyle = typeof height === \"number\" ? `${height}px` : height\n\n  return (\n    <div\n      aria-label=\"Audio waveform scrubber\"\n      aria-valuemax={duration}\n      aria-valuemin={0}\n      aria-valuenow={currentTime}\n      className={cn(\"relative cursor-pointer select-none\", className)}\n      onMouseDown={handleMouseDown}\n      ref={containerRef}\n      role=\"slider\"\n      style={{ height: heightStyle }}\n      tabIndex={0}\n      {...props}\n    >\n      <Waveform\n        barColor={barColor}\n        barGap={barGap}\n        barRadius={barRadius}\n        barWidth={barWidth}\n        barHeight={barHeight}\n        data={waveformData}\n        fadeEdges={false}\n      />\n\n      <div\n        className=\"bg-primary/20 pointer-events-none absolute inset-y-0 left-0\"\n        style={{ width: `${localProgress * 100}%` }}\n      />\n\n      <div\n        className=\"bg-primary pointer-events-none absolute top-0 bottom-0 w-0.5\"\n        style={{ left: `${localProgress * 100}%` }}\n      />\n\n      {showHandle && (\n        <div\n          className=\"border-background bg-primary pointer-events-none absolute top-1/2 h-4 w-4 -translate-x-1/2 -translate-y-1/2 rounded-full border-2 shadow-lg transition-transform hover:scale-110\"\n          style={{ left: `${localProgress * 100}%` }}\n        />\n      )}\n    </div>\n  )\n}\n\nexport type MicrophoneWaveformProps = WaveformProps & {\n  active?: boolean\n  processing?: boolean\n  fftSize?: number\n  smoothingTimeConstant?: number\n  sensitivity?: number\n  onError?: (error: Error) => void\n}\n\nexport const MicrophoneWaveform = ({\n  active = false,\n  processing = false,\n  fftSize = 256,\n  smoothingTimeConstant = 0.8,\n  sensitivity = 1,\n  onError,\n  ...props\n}: MicrophoneWaveformProps) => {\n  const [data, setData] = useState<number[]>([])\n  const analyserRef = useRef<AnalyserNode | null>(null)\n  const audioContextRef = useRef<AudioContext | null>(null)\n  const streamRef = useRef<MediaStream | null>(null)\n  const animationIdRef = useRef<number | null>(null)\n  const processingAnimationRef = useRef<number | null>(null)\n  const lastActiveDataRef = useRef<number[]>([])\n  const transitionProgressRef = useRef(0)\n\n  useEffect(() => {\n    if (processing && !active) {\n      let time = 0\n      transitionProgressRef.current = 0\n\n      const animateProcessing = () => {\n        time += 0.03\n        transitionProgressRef.current = Math.min(\n          1,\n          transitionProgressRef.current + 0.02\n        )\n\n        const processingData = []\n        const barCount = 45\n\n        for (let i = 0; i < barCount; i++) {\n          const normalizedPosition = (i - barCount / 2) / (barCount / 2)\n          const centerWeight = 1 - Math.abs(normalizedPosition) * 0.4\n\n          const wave1 = Math.sin(time * 1.5 + i * 0.15) * 0.25\n          const wave2 = Math.sin(time * 0.8 - i * 0.1) * 0.2\n          const wave3 = Math.cos(time * 2 + i * 0.05) * 0.15\n          const combinedWave = wave1 + wave2 + wave3\n          const processingValue = (0.2 + combinedWave) * centerWeight\n\n          let finalValue = processingValue\n          if (\n            lastActiveDataRef.current.length > 0 &&\n            transitionProgressRef.current < 1\n          ) {\n            const lastDataIndex = Math.floor(\n              (i / barCount) * lastActiveDataRef.current.length\n            )\n            const lastValue = lastActiveDataRef.current[lastDataIndex] || 0\n            finalValue =\n              lastValue * (1 - transitionProgressRef.current) +\n              processingValue * transitionProgressRef.current\n          }\n\n          processingData.push(Math.max(0.05, Math.min(1, finalValue)))\n        }\n\n        setData(processingData)\n        processingAnimationRef.current =\n          requestAnimationFrame(animateProcessing)\n      }\n\n      animateProcessing()\n\n      return () => {\n        if (processingAnimationRef.current) {\n          cancelAnimationFrame(processingAnimationRef.current)\n        }\n      }\n    } else if (!active && !processing) {\n      if (data.length > 0) {\n        let fadeProgress = 0\n        const fadeToIdle = () => {\n          fadeProgress += 0.03\n          if (fadeProgress < 1) {\n            const fadedData = data.map((value) => value * (1 - fadeProgress))\n            setData(fadedData)\n            requestAnimationFrame(fadeToIdle)\n          } else {\n            setData([])\n          }\n        }\n        fadeToIdle()\n      }\n      return\n    }\n  }, [processing, active])\n\n  useEffect(() => {\n    if (!active) {\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach((track) => track.stop())\n      }\n      if (\n        audioContextRef.current &&\n        audioContextRef.current.state !== \"closed\"\n      ) {\n        audioContextRef.current.close()\n      }\n      if (animationIdRef.current) {\n        cancelAnimationFrame(animationIdRef.current)\n      }\n      return\n    }\n\n    const setupMicrophone = async () => {\n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({\n          audio: true,\n        })\n        streamRef.current = stream\n\n        const audioContext = new (window.AudioContext ||\n          (window as unknown as { webkitAudioContext: typeof AudioContext })\n            .webkitAudioContext)()\n        const analyser = audioContext.createAnalyser()\n        analyser.fftSize = fftSize\n        analyser.smoothingTimeConstant = smoothingTimeConstant\n\n        const source = audioContext.createMediaStreamSource(stream)\n        source.connect(analyser)\n\n        audioContextRef.current = audioContext\n        analyserRef.current = analyser\n\n        const dataArray = new Uint8Array(analyser.frequencyBinCount)\n\n        const updateData = () => {\n          if (!analyserRef.current || !active) return\n\n          analyserRef.current.getByteFrequencyData(dataArray)\n\n          const startFreq = Math.floor(dataArray.length * 0.05)\n          const endFreq = Math.floor(dataArray.length * 0.4)\n          const relevantData = dataArray.slice(startFreq, endFreq)\n\n          const halfLength = Math.floor(relevantData.length / 2)\n          const normalizedData = []\n\n          for (let i = halfLength - 1; i >= 0; i--) {\n            const value = Math.min(1, (relevantData[i] / 255) * sensitivity)\n            normalizedData.push(value)\n          }\n\n          for (let i = 0; i < halfLength; i++) {\n            const value = Math.min(1, (relevantData[i] / 255) * sensitivity)\n            normalizedData.push(value)\n          }\n\n          setData(normalizedData)\n          lastActiveDataRef.current = normalizedData\n\n          animationIdRef.current = requestAnimationFrame(updateData)\n        }\n\n        updateData()\n      } catch (error) {\n        onError?.(error as Error)\n      }\n    }\n\n    setupMicrophone()\n\n    return () => {\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach((track) => track.stop())\n      }\n      if (\n        audioContextRef.current &&\n        audioContextRef.current.state !== \"closed\"\n      ) {\n        audioContextRef.current.close()\n      }\n      if (animationIdRef.current) {\n        cancelAnimationFrame(animationIdRef.current)\n      }\n    }\n  }, [active, fftSize, smoothingTimeConstant, sensitivity, onError])\n\n  return <Waveform data={data} {...props} />\n}\n\nexport type StaticWaveformProps = WaveformProps & {\n  bars?: number\n  seed?: number\n}\n\nexport const StaticWaveform = ({\n  bars = 40,\n  seed = 42,\n  ...props\n}: StaticWaveformProps) => {\n  const data = useMemo(() => {\n    const random = (seedValue: number) => {\n      const x = Math.sin(seedValue) * 10000\n      return x - Math.floor(x)\n    }\n\n    return Array.from({ length: bars }, (_, i) => 0.2 + random(seed + i) * 0.6)\n  }, [bars, seed])\n\n  return <Waveform data={data} {...props} />\n}\n\nexport type LiveMicrophoneWaveformProps = Omit<\n  ScrollingWaveformProps,\n  \"barCount\"\n> & {\n  active?: boolean\n  fftSize?: number\n  smoothingTimeConstant?: number\n  sensitivity?: number\n  onError?: (error: Error) => void\n  historySize?: number\n  updateRate?: number\n  savedHistoryRef?: React.MutableRefObject<number[]>\n  dragOffset?: number\n  setDragOffset?: (offset: number) => void\n  enableAudioPlayback?: boolean\n  playbackRate?: number\n}\n\nexport const LiveMicrophoneWaveform = ({\n  active = false,\n  fftSize = 256,\n  smoothingTimeConstant = 0.8,\n  sensitivity = 1,\n  onError,\n  historySize = 150,\n  updateRate = 50,\n  barWidth = 3,\n  barHeight: baseBarHeight = 4,\n  barGap = 1,\n  barRadius = 1,\n  barColor,\n  fadeEdges = true,\n  fadeWidth = 24,\n  height = 128,\n  className,\n  savedHistoryRef,\n  dragOffset: externalDragOffset,\n  setDragOffset: externalSetDragOffset,\n  enableAudioPlayback = true,\n  playbackRate = 1,\n  ...props\n}: LiveMicrophoneWaveformProps) => {\n  const canvasRef = useRef<HTMLCanvasElement>(null)\n  const containerRef = useRef<HTMLDivElement>(null)\n  const internalHistoryRef = useRef<number[]>([])\n  const historyRef = savedHistoryRef || internalHistoryRef\n  const analyserRef = useRef<AnalyserNode | null>(null)\n  const audioContextRef = useRef<AudioContext | null>(null)\n  const streamRef = useRef<MediaStream | null>(null)\n  const animationRef = useRef<number>(0)\n  const lastUpdateRef = useRef<number>(0)\n  const [internalDragOffset, setInternalDragOffset] = useState(0)\n  const [isDragging, setIsDragging] = useState(false)\n  const [playbackPosition, setPlaybackPosition] = useState<number | null>(null)\n  const dragStartXRef = useRef<number>(0)\n  const dragStartOffsetRef = useRef<number>(0)\n  const playbackStartTimeRef = useRef<number>(0)\n\n  // Audio recording and playback refs\n  const mediaRecorderRef = useRef<MediaRecorder | null>(null)\n  const audioChunksRef = useRef<Blob[]>([])\n  const audioBufferRef = useRef<AudioBuffer | null>(null)\n  const sourceNodeRef = useRef<AudioBufferSourceNode | null>(null)\n  const scrubSourceRef = useRef<AudioBufferSourceNode | null>(null)\n\n  // Use external drag state if provided, otherwise use internal\n  const dragOffset = externalDragOffset ?? internalDragOffset\n  const setDragOffset = externalSetDragOffset ?? setInternalDragOffset\n\n  const heightStyle = typeof height === \"number\" ? `${height}px` : height\n\n  useEffect(() => {\n    const canvas = canvasRef.current\n    const container = containerRef.current\n    if (!canvas || !container) return\n\n    const resizeObserver = new ResizeObserver(() => {\n      const rect = container.getBoundingClientRect()\n      const dpr = window.devicePixelRatio || 1\n\n      canvas.width = rect.width * dpr\n      canvas.height = rect.height * dpr\n      canvas.style.width = `${rect.width}px`\n      canvas.style.height = `${rect.height}px`\n\n      const ctx = canvas.getContext(\"2d\")\n      if (ctx) {\n        ctx.scale(dpr, dpr)\n      }\n    })\n\n    resizeObserver.observe(container)\n    return () => resizeObserver.disconnect()\n  }, [])\n\n  useEffect(() => {\n    if (!active) {\n      if (\n        mediaRecorderRef.current &&\n        mediaRecorderRef.current.state !== \"inactive\"\n      ) {\n        mediaRecorderRef.current.stop()\n      }\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach((track) => track.stop())\n      }\n      // Process recorded audio when stopping\n      if (enableAudioPlayback && audioChunksRef.current.length > 0) {\n        const audioBlob = new Blob(audioChunksRef.current, {\n          type: \"audio/webm\",\n        })\n        processAudioBlob(audioBlob)\n      }\n      return\n    }\n\n    setDragOffset?.(0)\n    historyRef.current = []\n    audioChunksRef.current = []\n    audioBufferRef.current = null\n    setPlaybackPosition(null)\n\n    const setupMicrophone = async () => {\n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({\n          audio: true,\n        })\n        streamRef.current = stream\n\n        const audioContext = new (window.AudioContext ||\n          (window as unknown as { webkitAudioContext: typeof AudioContext })\n            .webkitAudioContext)()\n        const analyser = audioContext.createAnalyser()\n        analyser.fftSize = fftSize\n        analyser.smoothingTimeConstant = smoothingTimeConstant\n\n        const source = audioContext.createMediaStreamSource(stream)\n        source.connect(analyser)\n\n        audioContextRef.current = audioContext\n        analyserRef.current = analyser\n\n        if (enableAudioPlayback) {\n          const mediaRecorder = new MediaRecorder(stream)\n          mediaRecorderRef.current = mediaRecorder\n\n          mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n              audioChunksRef.current.push(event.data)\n            }\n          }\n\n          mediaRecorder.start(100)\n        }\n      } catch (error) {\n        onError?.(error as Error)\n      }\n    }\n\n    setupMicrophone()\n\n    return () => {\n      if (\n        mediaRecorderRef.current &&\n        mediaRecorderRef.current.state !== \"inactive\"\n      ) {\n        mediaRecorderRef.current.stop()\n      }\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach((track) => track.stop())\n      }\n      if (sourceNodeRef.current) {\n        sourceNodeRef.current.stop()\n      }\n      if (scrubSourceRef.current) {\n        scrubSourceRef.current.stop()\n      }\n    }\n  }, [\n    active,\n    fftSize,\n    smoothingTimeConstant,\n    onError,\n    setDragOffset,\n    enableAudioPlayback,\n    historyRef,\n  ])\n\n  const processAudioBlob = async (blob: Blob) => {\n    try {\n      const arrayBuffer = await blob.arrayBuffer()\n      if (audioContextRef.current) {\n        const audioBuffer =\n          await audioContextRef.current.decodeAudioData(arrayBuffer)\n        audioBufferRef.current = audioBuffer\n      }\n    } catch (error) {\n      console.error(\"Error processing audio:\", error)\n    }\n  }\n\n  const playScrubSound = useCallback(\n    (position: number, direction: number) => {\n      if (\n        !enableAudioPlayback ||\n        !audioBufferRef.current ||\n        !audioContextRef.current\n      )\n        return\n\n      if (scrubSourceRef.current) {\n        try {\n          scrubSourceRef.current.stop()\n        } catch {}\n      }\n\n      const source = audioContextRef.current.createBufferSource()\n      source.buffer = audioBufferRef.current\n\n      const speed = Math.abs(direction)\n      const playbackRate =\n        direction > 0\n          ? Math.min(3, 1 + speed * 0.1)\n          : Math.max(-3, -1 - speed * 0.1)\n\n      source.playbackRate.value = playbackRate\n\n      const filter = audioContextRef.current.createBiquadFilter()\n      filter.type = \"lowpass\"\n      filter.frequency.value = Math.max(200, 2000 - speed * 100)\n\n      source.connect(filter)\n      filter.connect(audioContextRef.current.destination)\n\n      const startTime = Math.max(\n        0,\n        Math.min(position, audioBufferRef.current.duration - 0.1)\n      )\n      source.start(0, startTime, 0.1)\n      scrubSourceRef.current = source\n    },\n    [enableAudioPlayback]\n  )\n\n  const playFromPosition = useCallback(\n    (position: number) => {\n      if (\n        !enableAudioPlayback ||\n        !audioBufferRef.current ||\n        !audioContextRef.current\n      )\n        return\n\n      if (sourceNodeRef.current) {\n        try {\n          sourceNodeRef.current.stop()\n        } catch {}\n      }\n\n      const source = audioContextRef.current.createBufferSource()\n      source.buffer = audioBufferRef.current\n      source.playbackRate.value = playbackRate\n      source.connect(audioContextRef.current.destination)\n\n      const startTime = Math.max(\n        0,\n        Math.min(position, audioBufferRef.current.duration)\n      )\n      source.start(0, startTime)\n      sourceNodeRef.current = source\n\n      playbackStartTimeRef.current =\n        audioContextRef.current.currentTime - startTime\n      setPlaybackPosition(startTime)\n\n      source.onended = () => {\n        setPlaybackPosition(null)\n      }\n    },\n    [enableAudioPlayback, playbackRate]\n  )\n\n  useEffect(() => {\n    if (playbackPosition === null || !audioBufferRef.current) return\n\n    let animationId: number\n    const updatePlaybackVisual = () => {\n      if (\n        audioContextRef.current &&\n        sourceNodeRef.current &&\n        audioBufferRef.current\n      ) {\n        const elapsed =\n          audioContextRef.current.currentTime - playbackStartTimeRef.current\n        const currentPos = playbackPosition + elapsed * playbackRate\n\n        if (currentPos < audioBufferRef.current.duration) {\n          const progressRatio = currentPos / audioBufferRef.current.duration\n          const currentBarIndex = Math.floor(\n            progressRatio * historyRef.current.length\n          )\n          const step = barWidth + barGap\n\n          const containerWidth =\n            containerRef.current?.getBoundingClientRect().width || 0\n          const viewBars = Math.floor(containerWidth / step)\n          const targetOffset =\n            -(currentBarIndex - (historyRef.current.length - viewBars)) * step\n          const clampedOffset = Math.max(\n            -(historyRef.current.length - viewBars) * step,\n            Math.min(0, targetOffset)\n          )\n\n          setDragOffset?.(clampedOffset)\n          animationId = requestAnimationFrame(updatePlaybackVisual)\n        } else {\n          setPlaybackPosition(null)\n          const step = barWidth + barGap\n          const containerWidth =\n            containerRef.current?.getBoundingClientRect().width || 0\n          const viewBars = Math.floor(containerWidth / step)\n          setDragOffset?.(-(historyRef.current.length - viewBars) * step)\n        }\n      }\n    }\n\n    animationId = requestAnimationFrame(updatePlaybackVisual)\n\n    return () => {\n      if (animationId) cancelAnimationFrame(animationId)\n    }\n  }, [\n    playbackPosition,\n    playbackRate,\n    barWidth,\n    baseBarHeight,\n    barGap,\n    setDragOffset,\n    historyRef,\n  ])\n\n  useEffect(() => {\n    const canvas = canvasRef.current\n    if (!canvas) return\n    if (!active && historyRef.current.length === 0 && playbackPosition === null)\n      return\n\n    const ctx = canvas.getContext(\"2d\")\n    if (!ctx) return\n\n    const animate = (currentTime: number) => {\n      if (active && currentTime - lastUpdateRef.current > updateRate) {\n        lastUpdateRef.current = currentTime\n\n        if (analyserRef.current) {\n          const dataArray = new Uint8Array(\n            analyserRef.current.frequencyBinCount\n          )\n          analyserRef.current.getByteFrequencyData(dataArray)\n\n          let sum = 0\n          for (let i = 0; i < dataArray.length; i++) {\n            sum += dataArray[i]\n          }\n          const average = (sum / dataArray.length / 255) * sensitivity\n\n          historyRef.current.push(Math.min(1, Math.max(0.05, average)))\n\n          if (historyRef.current.length > historySize) {\n            historyRef.current.shift()\n          }\n        }\n      }\n\n      const rect = canvas.getBoundingClientRect()\n      ctx.clearRect(0, 0, rect.width, rect.height)\n\n      const computedBarColor =\n        barColor ||\n        getComputedStyle(canvas).getPropertyValue(\"--foreground\") ||\n        \"#000\"\n\n      const step = barWidth + barGap\n      const barCount = Math.floor(rect.width / step)\n      const centerY = rect.height / 2\n\n      const dataToRender = historyRef.current\n\n      if (dataToRender.length > 0) {\n        const offsetInBars = Math.floor(dragOffset / step)\n\n        for (let i = 0; i < barCount; i++) {\n          let dataIndex\n\n          if (active) {\n            dataIndex = dataToRender.length - 1 - i\n          } else {\n            dataIndex = Math.max(\n              0,\n              Math.min(\n                dataToRender.length - 1,\n                dataToRender.length - 1 - i - Math.floor(offsetInBars)\n              )\n            )\n          }\n\n          if (dataIndex >= 0 && dataIndex < dataToRender.length) {\n            const value = dataToRender[dataIndex]\n            if (value !== undefined) {\n              const x = rect.width - (i + 1) * step\n              const barHeight = Math.max(\n                baseBarHeight,\n                value * rect.height * 0.7\n              )\n              const y = centerY - barHeight / 2\n\n              ctx.fillStyle = computedBarColor\n              ctx.globalAlpha = 0.3 + value * 0.7\n\n              if (barRadius > 0) {\n                ctx.beginPath()\n                ctx.roundRect(x, y, barWidth, barHeight, barRadius)\n                ctx.fill()\n              } else {\n                ctx.fillRect(x, y, barWidth, barHeight)\n              }\n            }\n          }\n        }\n      }\n\n      if (fadeEdges && fadeWidth > 0) {\n        const gradient = ctx.createLinearGradient(0, 0, rect.width, 0)\n        const fadePercent = Math.min(0.2, fadeWidth / rect.width)\n\n        gradient.addColorStop(0, \"rgba(255,255,255,1)\")\n        gradient.addColorStop(fadePercent, \"rgba(255,255,255,0)\")\n        gradient.addColorStop(1 - fadePercent, \"rgba(255,255,255,0)\")\n        gradient.addColorStop(1, \"rgba(255,255,255,1)\")\n\n        ctx.globalCompositeOperation = \"destination-out\"\n        ctx.fillStyle = gradient\n        ctx.fillRect(0, 0, rect.width, rect.height)\n        ctx.globalCompositeOperation = \"source-over\"\n      }\n\n      ctx.globalAlpha = 1\n\n      animationRef.current = requestAnimationFrame(animate)\n    }\n\n    if (active || historyRef.current.length > 0 || playbackPosition !== null) {\n      animationRef.current = requestAnimationFrame(animate)\n    }\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current)\n      }\n    }\n  }, [\n    active,\n    sensitivity,\n    updateRate,\n    historySize,\n    barWidth,\n    baseBarHeight,\n    barGap,\n    barRadius,\n    barColor,\n    fadeEdges,\n    fadeWidth,\n    dragOffset,\n    playbackPosition,\n    historyRef,\n  ])\n\n  const handleMouseDown = (e: React.MouseEvent<HTMLDivElement>) => {\n    if (active || historyRef.current.length === 0) return\n\n    e.preventDefault()\n    setIsDragging(true)\n    dragStartXRef.current = e.clientX\n    dragStartOffsetRef.current = dragOffset\n  }\n\n  useEffect(() => {\n    if (!isDragging) return\n\n    let lastScrubTime = 0\n    let lastMouseX = dragStartXRef.current\n    const handleMouseMove = (e: MouseEvent) => {\n      const deltaX = e.clientX - dragStartXRef.current\n      const newOffset = dragStartOffsetRef.current - deltaX * 0.5 // Reduce sensitivity\n\n      const step = barWidth + barGap\n      const maxBars = historyRef.current.length\n      const viewWidth = canvasRef.current?.getBoundingClientRect().width || 0\n      const viewBars = Math.floor(viewWidth / step)\n\n      const maxOffset = Math.max(0, (maxBars - viewBars) * step)\n      const minOffset = 0\n      const clampedOffset = Math.max(minOffset, Math.min(maxOffset, newOffset))\n\n      setDragOffset?.(clampedOffset)\n\n      const now = Date.now()\n      if (\n        enableAudioPlayback &&\n        audioBufferRef.current &&\n        now - lastScrubTime > 50\n      ) {\n        lastScrubTime = now\n        const offsetBars = Math.floor(clampedOffset / step)\n        const rightmostBarIndex = Math.max(\n          0,\n          Math.min(maxBars - 1, maxBars - 1 - offsetBars)\n        )\n        const audioPosition =\n          (rightmostBarIndex / maxBars) * audioBufferRef.current.duration\n        const direction = e.clientX - lastMouseX\n        lastMouseX = e.clientX\n        playScrubSound(\n          Math.max(\n            0,\n            Math.min(audioBufferRef.current.duration - 0.1, audioPosition)\n          ),\n          direction\n        )\n      }\n    }\n\n    const handleMouseUp = () => {\n      setIsDragging(false)\n\n      if (enableAudioPlayback && audioBufferRef.current) {\n        const step = barWidth + barGap\n        const maxBars = historyRef.current.length\n        const offsetBars = Math.floor(dragOffset / step)\n        const rightmostBarIndex = Math.max(\n          0,\n          Math.min(maxBars - 1, maxBars - 1 - offsetBars)\n        )\n        const audioPosition =\n          (rightmostBarIndex / maxBars) * audioBufferRef.current.duration\n        playFromPosition(\n          Math.max(\n            0,\n            Math.min(audioBufferRef.current.duration - 0.1, audioPosition)\n          )\n        )\n      }\n\n      if (scrubSourceRef.current) {\n        try {\n          scrubSourceRef.current.stop()\n        } catch {}\n      }\n    }\n\n    document.addEventListener(\"mousemove\", handleMouseMove)\n    document.addEventListener(\"mouseup\", handleMouseUp)\n\n    return () => {\n      document.removeEventListener(\"mousemove\", handleMouseMove)\n      document.removeEventListener(\"mouseup\", handleMouseUp)\n    }\n  }, [\n    isDragging,\n    barWidth,\n    barGap,\n    setDragOffset,\n    dragOffset,\n    enableAudioPlayback,\n    playScrubSound,\n    playFromPosition,\n    historyRef,\n  ])\n\n  return (\n    <div\n      className={cn(\n        \"relative flex items-center\",\n        !active && historyRef.current.length > 0 && \"cursor-pointer\",\n        className\n      )}\n      onMouseDown={handleMouseDown}\n      ref={containerRef}\n      role={!active && historyRef.current.length > 0 ? \"slider\" : undefined}\n      aria-label={\n        !active && historyRef.current.length > 0\n          ? \"Drag to scrub through recording\"\n          : undefined\n      }\n      aria-valuenow={\n        !active && historyRef.current.length > 0\n          ? Math.abs(dragOffset)\n          : undefined\n      }\n      aria-valuemin={!active && historyRef.current.length > 0 ? 0 : undefined}\n      aria-valuemax={\n        !active && historyRef.current.length > 0\n          ? historyRef.current.length\n          : undefined\n      }\n      tabIndex={!active && historyRef.current.length > 0 ? 0 : undefined}\n      style={{ height: heightStyle }}\n      {...props}\n    >\n      <canvas className=\"block h-full w-full\" ref={canvasRef} />\n    </div>\n  )\n}\n\nexport type RecordingWaveformProps = Omit<\n  WaveformProps,\n  \"data\" | \"onBarClick\"\n> & {\n  recording?: boolean\n  fftSize?: number\n  smoothingTimeConstant?: number\n  sensitivity?: number\n  onError?: (error: Error) => void\n  onRecordingComplete?: (data: number[]) => void\n  updateRate?: number\n  showHandle?: boolean\n}\n\nexport const RecordingWaveform = ({\n  recording = false,\n  fftSize = 256,\n  smoothingTimeConstant = 0.8,\n  sensitivity = 1,\n  onError,\n  onRecordingComplete,\n  updateRate = 50,\n  showHandle = true,\n  barWidth = 3,\n  barHeight: baseBarHeight = 4,\n  barGap = 1,\n  barRadius = 1,\n  barColor,\n  height = 128,\n  className,\n  ...props\n}: RecordingWaveformProps) => {\n  const [recordedData, setRecordedData] = useState<number[]>([])\n  const [viewPosition, setViewPosition] = useState(1)\n  const [isDragging, setIsDragging] = useState(false)\n  const [isRecordingComplete, setIsRecordingComplete] = useState(false)\n\n  const canvasRef = useRef<HTMLCanvasElement>(null)\n  const containerRef = useRef<HTMLDivElement>(null)\n  const recordingDataRef = useRef<number[]>([])\n  const analyserRef = useRef<AnalyserNode | null>(null)\n  const audioContextRef = useRef<AudioContext | null>(null)\n  const streamRef = useRef<MediaStream | null>(null)\n  const animationRef = useRef<number>(0)\n  const lastUpdateRef = useRef<number>(0)\n\n  const heightStyle = typeof height === \"number\" ? `${height}px` : height\n\n  useEffect(() => {\n    const canvas = canvasRef.current\n    const container = containerRef.current\n    if (!canvas || !container) return\n\n    const resizeObserver = new ResizeObserver(() => {\n      const rect = container.getBoundingClientRect()\n      const dpr = window.devicePixelRatio || 1\n\n      canvas.width = rect.width * dpr\n      canvas.height = rect.height * dpr\n      canvas.style.width = `${rect.width}px`\n      canvas.style.height = `${rect.height}px`\n\n      const ctx = canvas.getContext(\"2d\")\n      if (ctx) {\n        ctx.scale(dpr, dpr)\n      }\n    })\n\n    resizeObserver.observe(container)\n    return () => resizeObserver.disconnect()\n  }, [])\n\n  useEffect(() => {\n    if (!recording) {\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach((track) => track.stop())\n      }\n      if (\n        audioContextRef.current &&\n        audioContextRef.current.state !== \"closed\"\n      ) {\n        audioContextRef.current.close()\n      }\n\n      if (recordingDataRef.current.length > 0) {\n        setRecordedData([...recordingDataRef.current])\n        setIsRecordingComplete(true)\n        onRecordingComplete?.(recordingDataRef.current)\n      }\n      return\n    }\n\n    setIsRecordingComplete(false)\n    recordingDataRef.current = []\n    setRecordedData([])\n    setViewPosition(1)\n\n    const setupMicrophone = async () => {\n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({\n          audio: true,\n        })\n        streamRef.current = stream\n\n        const audioContext = new (window.AudioContext ||\n          (window as unknown as { webkitAudioContext: typeof AudioContext })\n            .webkitAudioContext)()\n        const analyser = audioContext.createAnalyser()\n        analyser.fftSize = fftSize\n        analyser.smoothingTimeConstant = smoothingTimeConstant\n\n        const source = audioContext.createMediaStreamSource(stream)\n        source.connect(analyser)\n\n        audioContextRef.current = audioContext\n        analyserRef.current = analyser\n      } catch (error) {\n        onError?.(error as Error)\n      }\n    }\n\n    setupMicrophone()\n\n    return () => {\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach((track) => track.stop())\n      }\n      if (\n        audioContextRef.current &&\n        audioContextRef.current.state !== \"closed\"\n      ) {\n        audioContextRef.current.close()\n      }\n    }\n  }, [recording, fftSize, smoothingTimeConstant, onError, onRecordingComplete])\n\n  useEffect(() => {\n    const canvas = canvasRef.current\n    if (!canvas) return\n\n    const ctx = canvas.getContext(\"2d\")\n    if (!ctx) return\n\n    const animate = (currentTime: number) => {\n      if (recording && currentTime - lastUpdateRef.current > updateRate) {\n        lastUpdateRef.current = currentTime\n\n        if (analyserRef.current) {\n          const dataArray = new Uint8Array(\n            analyserRef.current.frequencyBinCount\n          )\n          analyserRef.current.getByteFrequencyData(dataArray)\n\n          let sum = 0\n          for (let i = 0; i < dataArray.length; i++) {\n            sum += dataArray[i]\n          }\n          const average = (sum / dataArray.length / 255) * sensitivity\n\n          recordingDataRef.current.push(Math.min(1, Math.max(0.05, average)))\n        }\n      }\n\n      const rect = canvas.getBoundingClientRect()\n      ctx.clearRect(0, 0, rect.width, rect.height)\n\n      const computedBarColor =\n        barColor ||\n        getComputedStyle(canvas).getPropertyValue(\"--foreground\") ||\n        \"#000\"\n\n      const dataToRender = recording ? recordingDataRef.current : recordedData\n\n      if (dataToRender.length > 0) {\n        const step = barWidth + barGap\n        const barsVisible = Math.floor(rect.width / step)\n        const centerY = rect.height / 2\n\n        let startIndex = 0\n        if (!recording && isRecordingComplete) {\n          const totalBars = dataToRender.length\n          if (totalBars > barsVisible) {\n            startIndex = Math.floor((totalBars - barsVisible) * viewPosition)\n          }\n        } else if (recording) {\n          startIndex = Math.max(0, dataToRender.length - barsVisible)\n        }\n\n        for (\n          let i = 0;\n          i < barsVisible && startIndex + i < dataToRender.length;\n          i++\n        ) {\n          const value = dataToRender[startIndex + i] || 0.1\n          const x = i * step\n          const barHeight = Math.max(baseBarHeight, value * rect.height * 0.7)\n          const y = centerY - barHeight / 2\n\n          ctx.fillStyle = computedBarColor\n          ctx.globalAlpha = 0.3 + value * 0.7\n\n          if (barRadius > 0) {\n            ctx.beginPath()\n            ctx.roundRect(x, y, barWidth, barHeight, barRadius)\n            ctx.fill()\n          } else {\n            ctx.fillRect(x, y, barWidth, barHeight)\n          }\n        }\n\n        if (!recording && isRecordingComplete && showHandle) {\n          const indicatorX = rect.width * viewPosition\n\n          ctx.strokeStyle = computedBarColor\n          ctx.globalAlpha = 0.5\n          ctx.lineWidth = 2\n          ctx.beginPath()\n          ctx.moveTo(indicatorX, 0)\n          ctx.lineTo(indicatorX, rect.height)\n          ctx.stroke()\n          ctx.fillStyle = computedBarColor\n          ctx.globalAlpha = 1\n          ctx.beginPath()\n          ctx.arc(indicatorX, centerY, 6, 0, Math.PI * 2)\n          ctx.fill()\n        }\n      }\n\n      ctx.globalAlpha = 1\n\n      animationRef.current = requestAnimationFrame(animate)\n    }\n\n    animationRef.current = requestAnimationFrame(animate)\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current)\n      }\n    }\n  }, [\n    recording,\n    recordedData,\n    viewPosition,\n    isRecordingComplete,\n    sensitivity,\n    updateRate,\n    showHandle,\n    barWidth,\n    baseBarHeight,\n    barGap,\n    barRadius,\n    barColor,\n  ])\n\n  const handleScrub = useCallback(\n    (clientX: number) => {\n      const container = containerRef.current\n      if (!container || recording || !isRecordingComplete) return\n\n      const rect = container.getBoundingClientRect()\n      const x = Math.max(0, Math.min(clientX - rect.left, rect.width))\n      const position = x / rect.width\n\n      setViewPosition(position)\n    },\n    [recording, isRecordingComplete]\n  )\n\n  const handleMouseDown = (e: React.MouseEvent<HTMLDivElement>) => {\n    if (recording || !isRecordingComplete) return\n\n    e.preventDefault()\n    setIsDragging(true)\n    handleScrub(e.clientX)\n  }\n\n  useEffect(() => {\n    if (!isDragging) return\n\n    const handleMouseMove = (e: MouseEvent) => {\n      handleScrub(e.clientX)\n    }\n\n    const handleMouseUp = () => {\n      setIsDragging(false)\n    }\n\n    document.addEventListener(\"mousemove\", handleMouseMove)\n    document.addEventListener(\"mouseup\", handleMouseUp)\n\n    return () => {\n      document.removeEventListener(\"mousemove\", handleMouseMove)\n      document.removeEventListener(\"mouseup\", handleMouseUp)\n    }\n  }, [isDragging, handleScrub])\n\n  return (\n    <div\n      aria-label={\n        isRecordingComplete && !recording\n          ? \"Drag to scrub through recording\"\n          : undefined\n      }\n      aria-valuenow={\n        isRecordingComplete && !recording ? viewPosition * 100 : undefined\n      }\n      aria-valuemin={isRecordingComplete && !recording ? 0 : undefined}\n      aria-valuemax={isRecordingComplete && !recording ? 100 : undefined}\n      className={cn(\n        \"relative flex items-center\",\n        isRecordingComplete && !recording && \"cursor-pointer\",\n        className\n      )}\n      onMouseDown={handleMouseDown}\n      ref={containerRef}\n      role={isRecordingComplete && !recording ? \"slider\" : undefined}\n      style={{ height: heightStyle }}\n      tabIndex={isRecordingComplete && !recording ? 0 : undefined}\n      {...props}\n    >\n      <canvas className=\"block h-full w-full\" ref={canvasRef} />\n    </div>\n  )\n}\n"
    },
    {
      "path": "components/ui/live-waveform.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport { useEffect, useRef, type HTMLAttributes } from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nexport type LiveWaveformProps = HTMLAttributes<HTMLDivElement> & {\n  active?: boolean\n  processing?: boolean\n  deviceId?: string\n  barWidth?: number\n  barHeight?: number\n  barGap?: number\n  barRadius?: number\n  barColor?: string\n  fadeEdges?: boolean\n  fadeWidth?: number\n  height?: string | number\n  sensitivity?: number\n  smoothingTimeConstant?: number\n  fftSize?: number\n  historySize?: number\n  updateRate?: number\n  mode?: \"scrolling\" | \"static\"\n  onError?: (error: Error) => void\n  onStreamReady?: (stream: MediaStream) => void\n  onStreamEnd?: () => void\n}\n\nexport const LiveWaveform = ({\n  active = false,\n  processing = false,\n  deviceId,\n  barWidth = 3,\n  barGap = 1,\n  barRadius = 1.5,\n  barColor,\n  fadeEdges = true,\n  fadeWidth = 24,\n  barHeight: baseBarHeight = 4,\n  height = 64,\n  sensitivity = 1,\n  smoothingTimeConstant = 0.8,\n  fftSize = 256,\n  historySize = 60,\n  updateRate = 30,\n  mode = \"static\",\n  onError,\n  onStreamReady,\n  onStreamEnd,\n  className,\n  ...props\n}: LiveWaveformProps) => {\n  const canvasRef = useRef<HTMLCanvasElement>(null)\n  const containerRef = useRef<HTMLDivElement>(null)\n  const historyRef = useRef<number[]>([])\n  const analyserRef = useRef<AnalyserNode | null>(null)\n  const audioContextRef = useRef<AudioContext | null>(null)\n  const streamRef = useRef<MediaStream | null>(null)\n  const animationRef = useRef<number>(0)\n  const lastUpdateRef = useRef<number>(0)\n  const processingAnimationRef = useRef<number | null>(null)\n  const lastActiveDataRef = useRef<number[]>([])\n  const transitionProgressRef = useRef(0)\n  const staticBarsRef = useRef<number[]>([])\n  const needsRedrawRef = useRef(true)\n  const gradientCacheRef = useRef<CanvasGradient | null>(null)\n  const lastWidthRef = useRef(0)\n\n  const heightStyle = typeof height === \"number\" ? `${height}px` : height\n\n  // Handle canvas resizing\n  useEffect(() => {\n    const canvas = canvasRef.current\n    const container = containerRef.current\n    if (!canvas || !container) return\n\n    const resizeObserver = new ResizeObserver(() => {\n      const rect = container.getBoundingClientRect()\n      const dpr = window.devicePixelRatio || 1\n\n      canvas.width = rect.width * dpr\n      canvas.height = rect.height * dpr\n      canvas.style.width = `${rect.width}px`\n      canvas.style.height = `${rect.height}px`\n\n      const ctx = canvas.getContext(\"2d\")\n      if (ctx) {\n        ctx.scale(dpr, dpr)\n      }\n\n      gradientCacheRef.current = null\n      lastWidthRef.current = rect.width\n      needsRedrawRef.current = true\n    })\n\n    resizeObserver.observe(container)\n    return () => resizeObserver.disconnect()\n  }, [])\n\n  useEffect(() => {\n    if (processing && !active) {\n      let time = 0\n      transitionProgressRef.current = 0\n\n      const animateProcessing = () => {\n        time += 0.03\n        transitionProgressRef.current = Math.min(\n          1,\n          transitionProgressRef.current + 0.02\n        )\n\n        const processingData = []\n        const barCount = Math.floor(\n          (containerRef.current?.getBoundingClientRect().width || 200) /\n            (barWidth + barGap)\n        )\n\n        if (mode === \"static\") {\n          const halfCount = Math.floor(barCount / 2)\n\n          for (let i = 0; i < barCount; i++) {\n            const normalizedPosition = (i - halfCount) / halfCount\n            const centerWeight = 1 - Math.abs(normalizedPosition) * 0.4\n\n            const wave1 = Math.sin(time * 1.5 + normalizedPosition * 3) * 0.25\n            const wave2 = Math.sin(time * 0.8 - normalizedPosition * 2) * 0.2\n            const wave3 = Math.cos(time * 2 + normalizedPosition) * 0.15\n            const combinedWave = wave1 + wave2 + wave3\n            const processingValue = (0.2 + combinedWave) * centerWeight\n\n            let finalValue = processingValue\n            if (\n              lastActiveDataRef.current.length > 0 &&\n              transitionProgressRef.current < 1\n            ) {\n              const lastDataIndex = Math.min(\n                i,\n                lastActiveDataRef.current.length - 1\n              )\n              const lastValue = lastActiveDataRef.current[lastDataIndex] || 0\n              finalValue =\n                lastValue * (1 - transitionProgressRef.current) +\n                processingValue * transitionProgressRef.current\n            }\n\n            processingData.push(Math.max(0.05, Math.min(1, finalValue)))\n          }\n        } else {\n          for (let i = 0; i < barCount; i++) {\n            const normalizedPosition = (i - barCount / 2) / (barCount / 2)\n            const centerWeight = 1 - Math.abs(normalizedPosition) * 0.4\n\n            const wave1 = Math.sin(time * 1.5 + i * 0.15) * 0.25\n            const wave2 = Math.sin(time * 0.8 - i * 0.1) * 0.2\n            const wave3 = Math.cos(time * 2 + i * 0.05) * 0.15\n            const combinedWave = wave1 + wave2 + wave3\n            const processingValue = (0.2 + combinedWave) * centerWeight\n\n            let finalValue = processingValue\n            if (\n              lastActiveDataRef.current.length > 0 &&\n              transitionProgressRef.current < 1\n            ) {\n              const lastDataIndex = Math.floor(\n                (i / barCount) * lastActiveDataRef.current.length\n              )\n              const lastValue = lastActiveDataRef.current[lastDataIndex] || 0\n              finalValue =\n                lastValue * (1 - transitionProgressRef.current) +\n                processingValue * transitionProgressRef.current\n            }\n\n            processingData.push(Math.max(0.05, Math.min(1, finalValue)))\n          }\n        }\n\n        if (mode === \"static\") {\n          staticBarsRef.current = processingData\n        } else {\n          historyRef.current = processingData\n        }\n\n        needsRedrawRef.current = true\n        processingAnimationRef.current =\n          requestAnimationFrame(animateProcessing)\n      }\n\n      animateProcessing()\n\n      return () => {\n        if (processingAnimationRef.current) {\n          cancelAnimationFrame(processingAnimationRef.current)\n        }\n      }\n    } else if (!active && !processing) {\n      const hasData =\n        mode === \"static\"\n          ? staticBarsRef.current.length > 0\n          : historyRef.current.length > 0\n\n      if (hasData) {\n        let fadeProgress = 0\n        const fadeToIdle = () => {\n          fadeProgress += 0.03\n          if (fadeProgress < 1) {\n            if (mode === \"static\") {\n              staticBarsRef.current = staticBarsRef.current.map(\n                (value) => value * (1 - fadeProgress)\n              )\n            } else {\n              historyRef.current = historyRef.current.map(\n                (value) => value * (1 - fadeProgress)\n              )\n            }\n            needsRedrawRef.current = true\n            requestAnimationFrame(fadeToIdle)\n          } else {\n            if (mode === \"static\") {\n              staticBarsRef.current = []\n            } else {\n              historyRef.current = []\n            }\n          }\n        }\n        fadeToIdle()\n      }\n    }\n  }, [processing, active, barWidth, barGap, mode])\n\n  // Handle microphone setup and teardown\n  useEffect(() => {\n    if (!active) {\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach((track) => track.stop())\n        streamRef.current = null\n        onStreamEnd?.()\n      }\n      if (\n        audioContextRef.current &&\n        audioContextRef.current.state !== \"closed\"\n      ) {\n        audioContextRef.current.close()\n        audioContextRef.current = null\n      }\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current)\n        animationRef.current = 0\n      }\n      return\n    }\n\n    const setupMicrophone = async () => {\n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({\n          audio: deviceId\n            ? {\n                deviceId: { exact: deviceId },\n                echoCancellation: true,\n                noiseSuppression: true,\n                autoGainControl: true,\n              }\n            : {\n                echoCancellation: true,\n                noiseSuppression: true,\n                autoGainControl: true,\n              },\n        })\n        streamRef.current = stream\n        onStreamReady?.(stream)\n\n        const AudioContextConstructor =\n          window.AudioContext ||\n          (window as unknown as { webkitAudioContext: typeof AudioContext })\n            .webkitAudioContext\n        const audioContext = new AudioContextConstructor()\n        const analyser = audioContext.createAnalyser()\n        analyser.fftSize = fftSize\n        analyser.smoothingTimeConstant = smoothingTimeConstant\n\n        const source = audioContext.createMediaStreamSource(stream)\n        source.connect(analyser)\n\n        audioContextRef.current = audioContext\n        analyserRef.current = analyser\n\n        // Clear history when starting\n        historyRef.current = []\n      } catch (error) {\n        onError?.(error as Error)\n      }\n    }\n\n    setupMicrophone()\n\n    return () => {\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach((track) => track.stop())\n        streamRef.current = null\n        onStreamEnd?.()\n      }\n      if (\n        audioContextRef.current &&\n        audioContextRef.current.state !== \"closed\"\n      ) {\n        audioContextRef.current.close()\n        audioContextRef.current = null\n      }\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current)\n        animationRef.current = 0\n      }\n    }\n  }, [\n    active,\n    deviceId,\n    fftSize,\n    smoothingTimeConstant,\n    onError,\n    onStreamReady,\n    onStreamEnd,\n  ])\n\n  // Animation loop\n  useEffect(() => {\n    const canvas = canvasRef.current\n    if (!canvas) return\n\n    const ctx = canvas.getContext(\"2d\")\n    if (!ctx) return\n\n    let rafId: number\n\n    const animate = (currentTime: number) => {\n      // Render waveform\n      const rect = canvas.getBoundingClientRect()\n\n      // Update audio data if active\n      if (active && currentTime - lastUpdateRef.current > updateRate) {\n        lastUpdateRef.current = currentTime\n\n        if (analyserRef.current) {\n          const dataArray = new Uint8Array(\n            analyserRef.current.frequencyBinCount\n          )\n          analyserRef.current.getByteFrequencyData(dataArray)\n\n          if (mode === \"static\") {\n            // For static mode, update bars in place\n            const startFreq = Math.floor(dataArray.length * 0.05)\n            const endFreq = Math.floor(dataArray.length * 0.4)\n            const relevantData = dataArray.slice(startFreq, endFreq)\n\n            const barCount = Math.floor(rect.width / (barWidth + barGap))\n            const halfCount = Math.floor(barCount / 2)\n            const newBars: number[] = []\n\n            // Mirror the data for symmetric display\n            for (let i = halfCount - 1; i >= 0; i--) {\n              const dataIndex = Math.floor(\n                (i / halfCount) * relevantData.length\n              )\n              const value = Math.min(\n                1,\n                (relevantData[dataIndex] / 255) * sensitivity\n              )\n              newBars.push(Math.max(0.05, value))\n            }\n\n            for (let i = 0; i < halfCount; i++) {\n              const dataIndex = Math.floor(\n                (i / halfCount) * relevantData.length\n              )\n              const value = Math.min(\n                1,\n                (relevantData[dataIndex] / 255) * sensitivity\n              )\n              newBars.push(Math.max(0.05, value))\n            }\n\n            staticBarsRef.current = newBars\n            lastActiveDataRef.current = newBars\n          } else {\n            // Scrolling mode - original behavior\n            let sum = 0\n            const startFreq = Math.floor(dataArray.length * 0.05)\n            const endFreq = Math.floor(dataArray.length * 0.4)\n            const relevantData = dataArray.slice(startFreq, endFreq)\n\n            for (let i = 0; i < relevantData.length; i++) {\n              sum += relevantData[i]\n            }\n            const average = (sum / relevantData.length / 255) * sensitivity\n\n            // Add to history\n            historyRef.current.push(Math.min(1, Math.max(0.05, average)))\n            lastActiveDataRef.current = [...historyRef.current]\n\n            // Maintain history size\n            if (historyRef.current.length > historySize) {\n              historyRef.current.shift()\n            }\n          }\n          needsRedrawRef.current = true\n        }\n      }\n\n      // Only redraw if needed\n      if (!needsRedrawRef.current && !active) {\n        rafId = requestAnimationFrame(animate)\n        return\n      }\n\n      needsRedrawRef.current = active\n      ctx.clearRect(0, 0, rect.width, rect.height)\n\n      const computedBarColor =\n        barColor ||\n        (() => {\n          const style = getComputedStyle(canvas)\n          // Try to get the computed color value directly\n          const color = style.color\n          return color || \"#000\"\n        })()\n\n      const step = barWidth + barGap\n      const barCount = Math.floor(rect.width / step)\n      const centerY = rect.height / 2\n\n      // Draw bars based on mode\n      if (mode === \"static\") {\n        // Static mode - bars in fixed positions\n        const dataToRender = processing\n          ? staticBarsRef.current\n          : active\n            ? staticBarsRef.current\n            : staticBarsRef.current.length > 0\n              ? staticBarsRef.current\n              : []\n\n        for (let i = 0; i < barCount && i < dataToRender.length; i++) {\n          const value = dataToRender[i] || 0.1\n          const x = i * step\n          const barHeight = Math.max(baseBarHeight, value * rect.height * 0.8)\n          const y = centerY - barHeight / 2\n\n          ctx.fillStyle = computedBarColor\n          ctx.globalAlpha = 0.4 + value * 0.6\n\n          if (barRadius > 0) {\n            ctx.beginPath()\n            ctx.roundRect(x, y, barWidth, barHeight, barRadius)\n            ctx.fill()\n          } else {\n            ctx.fillRect(x, y, barWidth, barHeight)\n          }\n        }\n      } else {\n        // Scrolling mode - original behavior\n        for (let i = 0; i < barCount && i < historyRef.current.length; i++) {\n          const dataIndex = historyRef.current.length - 1 - i\n          const value = historyRef.current[dataIndex] || 0.1\n          const x = rect.width - (i + 1) * step\n          const barHeight = Math.max(baseBarHeight, value * rect.height * 0.8)\n          const y = centerY - barHeight / 2\n\n          ctx.fillStyle = computedBarColor\n          ctx.globalAlpha = 0.4 + value * 0.6\n\n          if (barRadius > 0) {\n            ctx.beginPath()\n            ctx.roundRect(x, y, barWidth, barHeight, barRadius)\n            ctx.fill()\n          } else {\n            ctx.fillRect(x, y, barWidth, barHeight)\n          }\n        }\n      }\n\n      // Apply edge fading\n      if (fadeEdges && fadeWidth > 0 && rect.width > 0) {\n        // Cache gradient if width hasn't changed\n        if (!gradientCacheRef.current || lastWidthRef.current !== rect.width) {\n          const gradient = ctx.createLinearGradient(0, 0, rect.width, 0)\n          const fadePercent = Math.min(0.3, fadeWidth / rect.width)\n\n          // destination-out: removes destination where source alpha is high\n          // We want: fade edges out, keep center solid\n          // Left edge: start opaque (1) = remove, fade to transparent (0) = keep\n          gradient.addColorStop(0, \"rgba(255,255,255,1)\")\n          gradient.addColorStop(fadePercent, \"rgba(255,255,255,0)\")\n          // Center stays transparent = keep everything\n          gradient.addColorStop(1 - fadePercent, \"rgba(255,255,255,0)\")\n          // Right edge: fade from transparent (0) = keep to opaque (1) = remove\n          gradient.addColorStop(1, \"rgba(255,255,255,1)\")\n\n          gradientCacheRef.current = gradient\n          lastWidthRef.current = rect.width\n        }\n\n        ctx.globalCompositeOperation = \"destination-out\"\n        ctx.fillStyle = gradientCacheRef.current\n        ctx.fillRect(0, 0, rect.width, rect.height)\n        ctx.globalCompositeOperation = \"source-over\"\n      }\n\n      ctx.globalAlpha = 1\n\n      rafId = requestAnimationFrame(animate)\n    }\n\n    rafId = requestAnimationFrame(animate)\n\n    return () => {\n      if (rafId) {\n        cancelAnimationFrame(rafId)\n      }\n    }\n  }, [\n    active,\n    processing,\n    sensitivity,\n    updateRate,\n    historySize,\n    barWidth,\n    baseBarHeight,\n    barGap,\n    barRadius,\n    barColor,\n    fadeEdges,\n    fadeWidth,\n    mode,\n  ])\n\n  return (\n    <div\n      className={cn(\"relative h-full w-full\", className)}\n      ref={containerRef}\n      style={{ height: heightStyle }}\n      aria-label={\n        active\n          ? \"Live audio waveform\"\n          : processing\n            ? \"Processing audio\"\n            : \"Audio waveform idle\"\n      }\n      role=\"img\"\n      {...props}\n    >\n      {!active && !processing && (\n        <div className=\"border-muted-foreground/20 absolute top-1/2 right-0 left-0 -translate-y-1/2 border-t-2 border-dotted\" />\n      )}\n      <canvas\n        className=\"block h-full w-full\"\n        ref={canvasRef}\n        aria-hidden=\"true\"\n      />\n    </div>\n  )\n}\n"
    },
    {
      "path": "components/ui/shimmering-text.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport React, { useMemo, useRef } from \"react\"\nimport { motion, useInView, UseInViewOptions } from \"motion/react\"\n\nimport { cn } from \"@/lib/utils\"\n\ninterface ShimmeringTextProps {\n  /** Text to display with shimmer effect */\n  text: string\n  /** Animation duration in seconds */\n  duration?: number\n  /** Delay before starting animation */\n  delay?: number\n  /** Whether to repeat the animation */\n  repeat?: boolean\n  /** Pause duration between repeats in seconds */\n  repeatDelay?: number\n  /** Custom className */\n  className?: string\n  /** Whether to start animation when component enters viewport */\n  startOnView?: boolean\n  /** Whether to animate only once */\n  once?: boolean\n  /** Margin for in-view detection (rootMargin) */\n  inViewMargin?: UseInViewOptions[\"margin\"]\n  /** Shimmer spread multiplier */\n  spread?: number\n  /** Base text color */\n  color?: string\n  /** Shimmer gradient color */\n  shimmerColor?: string\n}\n\nexport function ShimmeringText({\n  text,\n  duration = 2,\n  delay = 0,\n  repeat = true,\n  repeatDelay = 0.5,\n  className,\n  startOnView = true,\n  once = false,\n  inViewMargin,\n  spread = 2,\n  color,\n  shimmerColor,\n}: ShimmeringTextProps) {\n  const ref = useRef<HTMLSpanElement>(null)\n  const isInView = useInView(ref, { once, margin: inViewMargin })\n\n  // Calculate dynamic spread based on text length\n  const dynamicSpread = useMemo(() => {\n    return text.length * spread\n  }, [text, spread])\n\n  // Determine if we should start animation\n  const shouldAnimate = !startOnView || isInView\n\n  return (\n    <motion.span\n      ref={ref}\n      className={cn(\n        \"relative inline-block bg-[length:250%_100%,auto] bg-clip-text text-transparent\",\n        \"[--base-color:var(--muted-foreground)] [--shimmer-color:var(--foreground)]\",\n        \"[background-repeat:no-repeat,padding-box]\",\n        \"[--shimmer-bg:linear-gradient(90deg,transparent_calc(50%-var(--spread)),var(--shimmer-color),transparent_calc(50%+var(--spread)))]\",\n        \"dark:[--base-color:var(--muted-foreground)] dark:[--shimmer-color:var(--foreground)]\",\n        className\n      )}\n      style={\n        {\n          \"--spread\": `${dynamicSpread}px`,\n          ...(color && { \"--base-color\": color }),\n          ...(shimmerColor && { \"--shimmer-color\": shimmerColor }),\n          backgroundImage: `var(--shimmer-bg), linear-gradient(var(--base-color), var(--base-color))`,\n        } as React.CSSProperties\n      }\n      initial={{\n        backgroundPosition: \"100% center\",\n        opacity: 0,\n      }}\n      animate={\n        shouldAnimate\n          ? {\n              backgroundPosition: \"0% center\",\n              opacity: 1,\n            }\n          : {}\n      }\n      transition={{\n        backgroundPosition: {\n          repeat: repeat ? Infinity : 0,\n          duration,\n          delay,\n          repeatDelay,\n          ease: \"linear\",\n        },\n        opacity: {\n          duration: 0.3,\n          delay,\n        },\n      }}\n    >\n      {text}\n    </motion.span>\n  )\n}\n"
    },
    {
      "path": "components/ui/audio-player.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport {\n  ComponentProps,\n  createContext,\n  HTMLProps,\n  ReactNode,\n  RefObject,\n  useCallback,\n  useContext,\n  useEffect,\n  useMemo,\n  useRef,\n  useState,\n} from \"react\"\nimport * as SliderPrimitive from \"@radix-ui/react-slider\"\nimport { Check, PauseIcon, PlayIcon, Settings } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\nimport { Button } from \"@/components/ui/button\"\nimport {\n  DropdownMenu,\n  DropdownMenuContent,\n  DropdownMenuItem,\n  DropdownMenuTrigger,\n} from \"@/components/ui/dropdown-menu\"\n\nenum ReadyState {\n  HAVE_NOTHING = 0,\n  HAVE_METADATA = 1,\n  HAVE_CURRENT_DATA = 2,\n  HAVE_FUTURE_DATA = 3,\n  HAVE_ENOUGH_DATA = 4,\n}\n\nenum NetworkState {\n  NETWORK_EMPTY = 0,\n  NETWORK_IDLE = 1,\n  NETWORK_LOADING = 2,\n  NETWORK_NO_SOURCE = 3,\n}\n\nfunction formatTime(seconds: number) {\n  const hrs = Math.floor(seconds / 3600)\n  const mins = Math.floor((seconds % 3600) / 60)\n  const secs = Math.floor(seconds % 60)\n\n  const formattedMins = mins < 10 ? `0${mins}` : mins\n  const formattedSecs = secs < 10 ? `0${secs}` : secs\n\n  return hrs > 0\n    ? `${hrs}:${formattedMins}:${formattedSecs}`\n    : `${mins}:${formattedSecs}`\n}\n\ninterface AudioPlayerItem<TData = unknown> {\n  id: string | number\n  src: string\n  data?: TData\n}\n\ninterface AudioPlayerApi<TData = unknown> {\n  ref: RefObject<HTMLAudioElement | null>\n  activeItem: AudioPlayerItem<TData> | null\n  duration: number | undefined\n  error: MediaError | null\n  isPlaying: boolean\n  isBuffering: boolean\n  playbackRate: number\n  isItemActive: (id: string | number | null) => boolean\n  setActiveItem: (item: AudioPlayerItem<TData> | null) => Promise<void>\n  play: (item?: AudioPlayerItem<TData> | null) => Promise<void>\n  pause: () => void\n  seek: (time: number) => void\n  setPlaybackRate: (rate: number) => void\n}\n\nconst AudioPlayerContext = createContext<AudioPlayerApi<unknown> | null>(null)\n\nexport function useAudioPlayer<TData = unknown>(): AudioPlayerApi<TData> {\n  const api = useContext(AudioPlayerContext) as AudioPlayerApi<TData> | null\n  if (!api) {\n    throw new Error(\n      \"useAudioPlayer cannot be called outside of AudioPlayerProvider\"\n    )\n  }\n  return api\n}\n\nconst AudioPlayerTimeContext = createContext<number | null>(null)\n\nexport const useAudioPlayerTime = () => {\n  const time = useContext(AudioPlayerTimeContext)\n  if (time === null) {\n    throw new Error(\n      \"useAudioPlayerTime cannot be called outside of AudioPlayerProvider\"\n    )\n  }\n  return time\n}\n\nexport function AudioPlayerProvider<TData = unknown>({\n  children,\n}: {\n  children: ReactNode\n}) {\n  const audioRef = useRef<HTMLAudioElement>(null)\n  const itemRef = useRef<AudioPlayerItem<TData> | null>(null)\n  const playPromiseRef = useRef<Promise<void> | null>(null)\n  const [readyState, setReadyState] = useState<number>(0)\n  const [networkState, setNetworkState] = useState<number>(0)\n  const [time, setTime] = useState<number>(0)\n  const [duration, setDuration] = useState<number | undefined>(undefined)\n  const [error, setError] = useState<MediaError | null>(null)\n  const [activeItem, _setActiveItem] = useState<AudioPlayerItem<TData> | null>(\n    null\n  )\n  const [paused, setPaused] = useState(true)\n  const [playbackRate, setPlaybackRateState] = useState<number>(1)\n\n  const setActiveItem = useCallback(\n    async (item: AudioPlayerItem<TData> | null) => {\n      if (!audioRef.current) return\n\n      if (item?.id === itemRef.current?.id) {\n        return\n      }\n      itemRef.current = item\n      const currentRate = audioRef.current.playbackRate\n      audioRef.current.pause()\n      audioRef.current.currentTime = 0\n      if (item === null) {\n        audioRef.current.removeAttribute(\"src\")\n      } else {\n        audioRef.current.src = item.src\n      }\n      audioRef.current.load()\n      audioRef.current.playbackRate = currentRate\n    },\n    []\n  )\n\n  const play = useCallback(\n    async (item?: AudioPlayerItem<TData> | null) => {\n      if (!audioRef.current) return\n\n      if (playPromiseRef.current) {\n        try {\n          await playPromiseRef.current\n        } catch (error) {\n          console.error(\"Play promise error:\", error)\n        }\n      }\n\n      if (item === undefined) {\n        const playPromise = audioRef.current.play()\n        playPromiseRef.current = playPromise\n        return playPromise\n      }\n      if (item?.id === activeItem?.id) {\n        const playPromise = audioRef.current.play()\n        playPromiseRef.current = playPromise\n        return playPromise\n      }\n\n      itemRef.current = item\n      const currentRate = audioRef.current.playbackRate\n      if (!audioRef.current.paused) {\n        audioRef.current.pause()\n      }\n      audioRef.current.currentTime = 0\n      if (item === null) {\n        audioRef.current.removeAttribute(\"src\")\n      } else {\n        audioRef.current.src = item.src\n      }\n      audioRef.current.load()\n      audioRef.current.playbackRate = currentRate\n      const playPromise = audioRef.current.play()\n      playPromiseRef.current = playPromise\n      return playPromise\n    },\n    [activeItem]\n  )\n\n  const pause = useCallback(async () => {\n    if (!audioRef.current) return\n\n    if (playPromiseRef.current) {\n      try {\n        await playPromiseRef.current\n      } catch (e) {\n        console.error(e)\n      }\n    }\n\n    audioRef.current.pause()\n    playPromiseRef.current = null\n  }, [])\n\n  const seek = useCallback((time: number) => {\n    if (!audioRef.current) return\n    audioRef.current.currentTime = time\n  }, [])\n\n  const setPlaybackRate = useCallback((rate: number) => {\n    if (!audioRef.current) return\n    audioRef.current.playbackRate = rate\n    setPlaybackRateState(rate)\n  }, [])\n\n  const isItemActive = useCallback(\n    (id: string | number | null) => {\n      return activeItem?.id === id\n    },\n    [activeItem]\n  )\n\n  useAnimationFrame(() => {\n    if (audioRef.current) {\n      _setActiveItem(itemRef.current)\n      setReadyState(audioRef.current.readyState)\n      setNetworkState(audioRef.current.networkState)\n      setTime(audioRef.current.currentTime)\n      setDuration(audioRef.current.duration)\n      setPaused(audioRef.current.paused)\n      setError(audioRef.current.error)\n      setPlaybackRateState(audioRef.current.playbackRate)\n    }\n  })\n\n  const isPlaying = !paused\n  const isBuffering =\n    readyState < ReadyState.HAVE_FUTURE_DATA &&\n    networkState === NetworkState.NETWORK_LOADING\n\n  const api = useMemo<AudioPlayerApi<TData>>(\n    () => ({\n      ref: audioRef,\n      duration,\n      error,\n      isPlaying,\n      isBuffering,\n      activeItem,\n      playbackRate,\n      isItemActive,\n      setActiveItem,\n      play,\n      pause,\n      seek,\n      setPlaybackRate,\n    }),\n    [\n      audioRef,\n      duration,\n      error,\n      isPlaying,\n      isBuffering,\n      activeItem,\n      playbackRate,\n      isItemActive,\n      setActiveItem,\n      play,\n      pause,\n      seek,\n      setPlaybackRate,\n    ]\n  )\n\n  return (\n    <AudioPlayerContext.Provider value={api as AudioPlayerApi<unknown>}>\n      <AudioPlayerTimeContext.Provider value={time}>\n        <audio ref={audioRef} className=\"hidden\" crossOrigin=\"anonymous\" />\n        {children}\n      </AudioPlayerTimeContext.Provider>\n    </AudioPlayerContext.Provider>\n  )\n}\n\nexport const AudioPlayerProgress = ({\n  ...otherProps\n}: Omit<\n  ComponentProps<typeof SliderPrimitive.Root>,\n  \"min\" | \"max\" | \"value\"\n>) => {\n  const player = useAudioPlayer()\n  const time = useAudioPlayerTime()\n  const wasPlayingRef = useRef(false)\n\n  return (\n    <SliderPrimitive.Root\n      {...otherProps}\n      value={[time]}\n      onValueChange={(vals) => {\n        player.seek(vals[0])\n        otherProps.onValueChange?.(vals)\n      }}\n      min={0}\n      max={player.duration ?? 0}\n      step={otherProps.step || 0.25}\n      onPointerDown={(e) => {\n        wasPlayingRef.current = player.isPlaying\n        player.pause()\n        otherProps.onPointerDown?.(e)\n      }}\n      onPointerUp={(e) => {\n        if (wasPlayingRef.current) {\n          player.play()\n        }\n        otherProps.onPointerUp?.(e)\n      }}\n      className={cn(\n        \"group/player relative flex h-4 touch-none items-center select-none data-[disabled]:opacity-50 data-[orientation=vertical]:h-full data-[orientation=vertical]:min-h-44 data-[orientation=vertical]:w-auto data-[orientation=vertical]:flex-col\",\n        otherProps.className\n      )}\n      onKeyDown={(e) => {\n        if (e.key === \" \") {\n          e.preventDefault()\n          if (!player.isPlaying) {\n            player.play()\n          } else {\n            player.pause()\n          }\n        }\n        otherProps.onKeyDown?.(e)\n      }}\n      disabled={\n        player.duration === undefined ||\n        !Number.isFinite(player.duration) ||\n        Number.isNaN(player.duration)\n      }\n    >\n      <SliderPrimitive.Track className=\"bg-muted relative h-[4px] w-full grow overflow-hidden rounded-full\">\n        <SliderPrimitive.Range className=\"bg-primary absolute h-full\" />\n      </SliderPrimitive.Track>\n      <SliderPrimitive.Thumb\n        className=\"relative flex h-0 w-0 items-center justify-center opacity-0 group-hover/player:opacity-100 focus-visible:opacity-100 focus-visible:outline-none disabled:pointer-events-none disabled:opacity-50\"\n        data-slot=\"slider-thumb\"\n      >\n        <div className=\"bg-foreground absolute size-3 rounded-full\" />\n      </SliderPrimitive.Thumb>\n    </SliderPrimitive.Root>\n  )\n}\n\nexport const AudioPlayerTime = ({\n  className,\n  ...otherProps\n}: HTMLProps<HTMLSpanElement>) => {\n  const time = useAudioPlayerTime()\n  return (\n    <span\n      {...otherProps}\n      className={cn(\"text-muted-foreground text-sm tabular-nums\", className)}\n    >\n      {formatTime(time)}\n    </span>\n  )\n}\n\nexport const AudioPlayerDuration = ({\n  className,\n  ...otherProps\n}: HTMLProps<HTMLSpanElement>) => {\n  const player = useAudioPlayer()\n  return (\n    <span\n      {...otherProps}\n      className={cn(\"text-muted-foreground text-sm tabular-nums\", className)}\n    >\n      {player.duration !== null &&\n      player.duration !== undefined &&\n      !Number.isNaN(player.duration)\n        ? formatTime(player.duration)\n        : \"--:--\"}\n    </span>\n  )\n}\n\ninterface SpinnerProps {\n  className?: string\n}\n\nfunction Spinner({ className }: SpinnerProps) {\n  return (\n    <div\n      className={cn(\n        \"border-muted border-t-foreground size-3.5 animate-spin rounded-full border-2\",\n        className\n      )}\n      role=\"status\"\n      aria-label=\"Loading\"\n    >\n      <span className=\"sr-only\">Loading...</span>\n    </div>\n  )\n}\n\ninterface PlayButtonProps extends React.ComponentProps<typeof Button> {\n  playing: boolean\n  onPlayingChange: (playing: boolean) => void\n  loading?: boolean\n}\n\nconst PlayButton = ({\n  playing,\n  onPlayingChange,\n  className,\n  onClick,\n  loading,\n  ...otherProps\n}: PlayButtonProps) => {\n  return (\n    <Button\n      {...otherProps}\n      onClick={(e) => {\n        onPlayingChange(!playing)\n        onClick?.(e)\n      }}\n      className={cn(\"relative\", className)}\n      aria-label={playing ? \"Pause\" : \"Play\"}\n      type=\"button\"\n    >\n      {playing ? (\n        <PauseIcon\n          className={cn(\"size-4\", loading && \"opacity-0\")}\n          aria-hidden=\"true\"\n        />\n      ) : (\n        <PlayIcon\n          className={cn(\"size-4\", loading && \"opacity-0\")}\n          aria-hidden=\"true\"\n        />\n      )}\n      {loading && (\n        <div className=\"absolute inset-0 flex items-center justify-center rounded-[inherit] backdrop-blur-xs\">\n          <Spinner />\n        </div>\n      )}\n    </Button>\n  )\n}\n\nexport interface AudioPlayerButtonProps<TData = unknown>\n  extends React.ComponentProps<typeof Button> {\n  item?: AudioPlayerItem<TData>\n}\n\nexport function AudioPlayerButton<TData = unknown>({\n  item,\n  ...otherProps\n}: AudioPlayerButtonProps<TData>) {\n  const player = useAudioPlayer<TData>()\n\n  if (!item) {\n    return (\n      <PlayButton\n        {...otherProps}\n        playing={player.isPlaying}\n        onPlayingChange={(shouldPlay) => {\n          if (shouldPlay) {\n            player.play()\n          } else {\n            player.pause()\n          }\n        }}\n        loading={player.isBuffering && player.isPlaying}\n      />\n    )\n  }\n\n  return (\n    <PlayButton\n      {...otherProps}\n      playing={player.isItemActive(item.id) && player.isPlaying}\n      onPlayingChange={(shouldPlay) => {\n        if (shouldPlay) {\n          player.play(item)\n        } else {\n          player.pause()\n        }\n      }}\n      loading={\n        player.isItemActive(item.id) && player.isBuffering && player.isPlaying\n      }\n    />\n  )\n}\n\ntype Callback = (delta: number) => void\n\nfunction useAnimationFrame(callback: Callback) {\n  const requestRef = useRef<number | null>(null)\n  const previousTimeRef = useRef<number | null>(null)\n  const callbackRef = useRef<Callback>(callback)\n\n  useEffect(() => {\n    callbackRef.current = callback\n  }, [callback])\n\n  useEffect(() => {\n    const animate = (time: number) => {\n      if (previousTimeRef.current !== null) {\n        const delta = time - previousTimeRef.current\n        callbackRef.current(delta)\n      }\n      previousTimeRef.current = time\n      requestRef.current = requestAnimationFrame(animate)\n    }\n\n    requestRef.current = requestAnimationFrame(animate)\n\n    return () => {\n      if (requestRef.current) cancelAnimationFrame(requestRef.current)\n      previousTimeRef.current = null\n    }\n  }, [])\n}\n\nconst PLAYBACK_SPEEDS = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2] as const\n\nexport interface AudioPlayerSpeedProps\n  extends React.ComponentProps<typeof Button> {\n  speeds?: readonly number[]\n}\n\nexport function AudioPlayerSpeed({\n  speeds = PLAYBACK_SPEEDS,\n  className,\n  variant = \"ghost\",\n  size = \"icon\",\n  ...props\n}: AudioPlayerSpeedProps) {\n  const player = useAudioPlayer()\n  const currentSpeed = player.playbackRate\n\n  return (\n    <DropdownMenu>\n      <DropdownMenuTrigger asChild>\n        <Button\n          variant={variant}\n          size={size}\n          className={cn(className)}\n          aria-label=\"Playback speed\"\n          {...props}\n        >\n          <Settings className=\"size-4\" />\n        </Button>\n      </DropdownMenuTrigger>\n      <DropdownMenuContent align=\"end\" className=\"min-w-[120px]\">\n        {speeds.map((speed) => (\n          <DropdownMenuItem\n            key={speed}\n            onClick={() => player.setPlaybackRate(speed)}\n            className=\"flex items-center justify-between\"\n          >\n            <span className={speed === 1 ? \"\" : \"font-mono\"}>\n              {speed === 1 ? \"Normal\" : `${speed}x`}\n            </span>\n            {currentSpeed === speed && <Check className=\"size-4\" />}\n          </DropdownMenuItem>\n        ))}\n      </DropdownMenuContent>\n    </DropdownMenu>\n  )\n}\n\nexport interface AudioPlayerSpeedButtonGroupProps\n  extends Omit<React.HTMLAttributes<HTMLDivElement>, \"children\"> {\n  speeds?: readonly number[]\n}\n\nexport function AudioPlayerSpeedButtonGroup({\n  speeds = [0.5, 1, 1.5, 2],\n  className,\n  ...props\n}: AudioPlayerSpeedButtonGroupProps) {\n  const player = useAudioPlayer()\n  const currentSpeed = player.playbackRate\n\n  return (\n    <div\n      className={cn(\"flex items-center gap-1\", className)}\n      role=\"group\"\n      aria-label=\"Playback speed controls\"\n      {...props}\n    >\n      {speeds.map((speed) => (\n        <Button\n          key={speed}\n          variant={currentSpeed === speed ? \"default\" : \"outline\"}\n          size=\"sm\"\n          onClick={() => player.setPlaybackRate(speed)}\n          className=\"min-w-[50px] font-mono text-xs\"\n        >\n          {speed}x\n        </Button>\n      ))}\n    </div>\n  )\n}\n\nexport const exampleTracks = [\n  {\n    id: \"0\",\n    name: \"II - 00\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/00.mp3\",\n  },\n  {\n    id: \"1\",\n    name: \"II - 01\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/01.mp3\",\n  },\n  {\n    id: \"2\",\n    name: \"II - 02\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/02.mp3\",\n  },\n  {\n    id: \"3\",\n    name: \"II - 03\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/03.mp3\",\n  },\n  {\n    id: \"4\",\n    name: \"II - 04\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/04.mp3\",\n  },\n  {\n    id: \"5\",\n    name: \"II - 05\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/05.mp3\",\n  },\n  {\n    id: \"6\",\n    name: \"II - 06\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/06.mp3\",\n  },\n  {\n    id: \"7\",\n    name: \"II - 07\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/07.mp3\",\n  },\n  {\n    id: \"8\",\n    name: \"II - 08\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/08.mp3\",\n  },\n  {\n    id: \"9\",\n    name: \"II - 09\",\n    url: \"https://storage.googleapis.com/eleven-public-cdn/audio/ui-elevenlabs-io/09.mp3\",\n  },\n]\n"
    },
    {
      "path": "components/ui/message.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "import type { ComponentProps, HTMLAttributes } from \"react\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\nimport {\n  Avatar,\n  AvatarFallback,\n  AvatarImage,\n} from \"@/components/ui/avatar\"\n\nexport type MessageProps = HTMLAttributes<HTMLDivElement> & {\n  from: \"user\" | \"assistant\"\n}\n\nexport const Message = ({ className, from, ...props }: MessageProps) => (\n  <div\n    className={cn(\n      \"group flex w-full items-end justify-end gap-2 py-4\",\n      from === \"user\" ? \"is-user\" : \"is-assistant flex-row-reverse justify-end\",\n      className\n    )}\n    {...props}\n  />\n)\n\nconst messageContentVariants = cva(\n  \"is-user:dark flex flex-col gap-2 overflow-hidden rounded-lg text-sm\",\n  {\n    variants: {\n      variant: {\n        contained: [\n          \"max-w-[80%] px-4 py-3\",\n          \"group-[.is-user]:bg-primary group-[.is-user]:text-primary-foreground\",\n          \"group-[.is-assistant]:bg-secondary group-[.is-assistant]:text-foreground\",\n        ],\n        flat: [\n          \"group-[.is-user]:max-w-[80%] group-[.is-user]:bg-secondary group-[.is-user]:px-4 group-[.is-user]:py-3 group-[.is-user]:text-foreground\",\n          \"group-[.is-assistant]:text-foreground\",\n        ],\n      },\n    },\n    defaultVariants: {\n      variant: \"contained\",\n    },\n  }\n)\n\nexport type MessageContentProps = HTMLAttributes<HTMLDivElement> &\n  VariantProps<typeof messageContentVariants>\n\nexport const MessageContent = ({\n  children,\n  className,\n  variant,\n  ...props\n}: MessageContentProps) => (\n  <div\n    className={cn(messageContentVariants({ variant, className }))}\n    {...props}\n  >\n    {children}\n  </div>\n)\n\nexport type MessageAvatarProps = ComponentProps<typeof Avatar> & {\n  src: string\n  name?: string\n}\n\nexport const MessageAvatar = ({\n  src,\n  name,\n  className,\n  ...props\n}: MessageAvatarProps) => (\n  <Avatar className={cn(\"ring-border size-8 ring-1\", className)} {...props}>\n    <AvatarImage alt=\"\" className=\"mt-0 mb-0\" src={src} />\n    <AvatarFallback>{name?.slice(0, 2) || \"ME\"}</AvatarFallback>\n  </Avatar>\n)\n"
    },
    {
      "path": "components/ui/conversation.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport type { ComponentProps } from \"react\"\nimport { useCallback } from \"react\"\nimport { ArrowDownIcon } from \"lucide-react\"\nimport { StickToBottom, useStickToBottomContext } from \"use-stick-to-bottom\"\n\nimport { cn } from \"@/lib/utils\"\nimport { Button } from \"@/components/ui/button\"\n\nexport type ConversationProps = ComponentProps<typeof StickToBottom>\n\nexport const Conversation = ({ className, ...props }: ConversationProps) => (\n  <StickToBottom\n    className={cn(\"relative flex-1 overflow-y-auto\", className)}\n    initial=\"smooth\"\n    resize=\"smooth\"\n    role=\"log\"\n    {...props}\n  />\n)\n\nexport type ConversationContentProps = ComponentProps<\n  typeof StickToBottom.Content\n>\n\nexport const ConversationContent = ({\n  className,\n  ...props\n}: ConversationContentProps) => (\n  <StickToBottom.Content className={cn(\"p-4\", className)} {...props} />\n)\n\nexport type ConversationEmptyStateProps = Omit<\n  ComponentProps<\"div\">,\n  \"title\"\n> & {\n  title?: React.ReactNode\n  description?: React.ReactNode\n  icon?: React.ReactNode\n}\n\nexport const ConversationEmptyState = ({\n  className,\n  title = \"No messages yet\",\n  description = \"Start a conversation to see messages here\",\n  icon,\n  children,\n  ...props\n}: ConversationEmptyStateProps) => (\n  <div\n    className={cn(\n      \"flex size-full flex-col items-center justify-center gap-3 p-8 text-center\",\n      className\n    )}\n    {...props}\n  >\n    {children ?? (\n      <>\n        {icon && <div className=\"text-muted-foreground\">{icon}</div>}\n        <div className=\"space-y-1\">\n          <h3 className=\"text-sm font-medium\">{title}</h3>\n          {description && (\n            <p className=\"text-muted-foreground text-sm\">{description}</p>\n          )}\n        </div>\n      </>\n    )}\n  </div>\n)\n\nexport type ConversationScrollButtonProps = ComponentProps<typeof Button>\n\nexport const ConversationScrollButton = ({\n  className,\n  ...props\n}: ConversationScrollButtonProps) => {\n  const { isAtBottom, scrollToBottom } = useStickToBottomContext()\n\n  const handleScrollToBottom = useCallback(() => {\n    scrollToBottom()\n  }, [scrollToBottom])\n\n  return (\n    !isAtBottom && (\n      <Button\n        className={cn(\n          \"bg-background dark:bg-background absolute bottom-4 left-[50%] translate-x-[-50%] rounded-full shadow-md\",\n          className\n        )}\n        onClick={handleScrollToBottom}\n        size=\"icon\"\n        type=\"button\"\n        variant=\"outline\"\n        {...props}\n      >\n        <ArrowDownIcon className=\"size-4\" />\n      </Button>\n    )\n  )\n}\n"
    },
    {
      "path": "components/ui/response.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport { memo, type ComponentProps } from \"react\"\nimport { Streamdown } from \"streamdown\"\n\nimport { cn } from \"@/lib/utils\"\n\ntype ResponseProps = ComponentProps<typeof Streamdown>\n\nexport const Response = memo(\n  ({ className, ...props }: ResponseProps) => (\n    <Streamdown\n      className={cn(\n        \"size-full [&>*:first-child]:mt-0 [&>*:last-child]:mb-0\",\n        className\n      )}\n      {...props}\n    />\n  ),\n  (prevProps, nextProps) => prevProps.children === nextProps.children\n)\n\nResponse.displayName = \"Response\"\n"
    },
    {
      "path": "components/ui/bar-visualizer.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport * as React from \"react\"\nimport { useEffect, useMemo, useRef, useState } from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nexport interface AudioAnalyserOptions {\n  fftSize?: number\n  smoothingTimeConstant?: number\n  minDecibels?: number\n  maxDecibels?: number\n}\n\nfunction createAudioAnalyser(\n  mediaStream: MediaStream,\n  options: AudioAnalyserOptions = {}\n) {\n  const audioContext = new (window.AudioContext ||\n    (window as unknown as { webkitAudioContext: typeof AudioContext })\n      .webkitAudioContext)()\n  const source = audioContext.createMediaStreamSource(mediaStream)\n  const analyser = audioContext.createAnalyser()\n\n  if (options.fftSize) analyser.fftSize = options.fftSize\n  if (options.smoothingTimeConstant !== undefined) {\n    analyser.smoothingTimeConstant = options.smoothingTimeConstant\n  }\n  if (options.minDecibels !== undefined)\n    analyser.minDecibels = options.minDecibels\n  if (options.maxDecibels !== undefined)\n    analyser.maxDecibels = options.maxDecibels\n\n  source.connect(analyser)\n\n  const cleanup = () => {\n    source.disconnect()\n    audioContext.close()\n  }\n\n  return { analyser, audioContext, cleanup }\n}\n\n/**\n * Hook for tracking the volume of an audio stream using the Web Audio API.\n * @param mediaStream - The MediaStream to analyze\n * @param options - Audio analyser options\n * @returns The current volume level (0-1)\n */\nexport function useAudioVolume(\n  mediaStream?: MediaStream | null,\n  options: AudioAnalyserOptions = { fftSize: 32, smoothingTimeConstant: 0 }\n) {\n  const [volume, setVolume] = useState(0)\n  const volumeRef = useRef(0)\n  const frameId = useRef<number | undefined>(undefined)\n\n  // Memoize options to prevent unnecessary re-renders\n  const memoizedOptions = useMemo(\n    () => options,\n    [\n      options.fftSize,\n      options.smoothingTimeConstant,\n      options.minDecibels,\n      options.maxDecibels,\n    ]\n  )\n\n  useEffect(() => {\n    if (!mediaStream) {\n      setVolume(0)\n      volumeRef.current = 0\n      return\n    }\n\n    const { analyser, cleanup } = createAudioAnalyser(\n      mediaStream,\n      memoizedOptions\n    )\n\n    const bufferLength = analyser.frequencyBinCount\n    const dataArray = new Uint8Array(bufferLength)\n    let lastUpdate = 0\n    const updateInterval = 1000 / 30 // 30 FPS\n\n    const updateVolume = (timestamp: number) => {\n      if (timestamp - lastUpdate >= updateInterval) {\n        analyser.getByteFrequencyData(dataArray)\n        let sum = 0\n        for (let i = 0; i < dataArray.length; i++) {\n          const a = dataArray[i]\n          sum += a * a\n        }\n        const newVolume = Math.sqrt(sum / dataArray.length) / 255\n\n        // Only update state if volume changed significantly\n        if (Math.abs(newVolume - volumeRef.current) > 0.01) {\n          volumeRef.current = newVolume\n          setVolume(newVolume)\n        }\n        lastUpdate = timestamp\n      }\n      frameId.current = requestAnimationFrame(updateVolume)\n    }\n\n    frameId.current = requestAnimationFrame(updateVolume)\n\n    return () => {\n      cleanup()\n      if (frameId.current) {\n        cancelAnimationFrame(frameId.current)\n      }\n    }\n  }, [mediaStream, memoizedOptions])\n\n  return volume\n}\n\nexport interface MultiBandVolumeOptions {\n  bands?: number\n  loPass?: number // Low frequency cutoff\n  hiPass?: number // High frequency cutoff\n  updateInterval?: number // Update interval in ms\n  analyserOptions?: AudioAnalyserOptions\n}\n\nconst multibandDefaults: MultiBandVolumeOptions = {\n  bands: 5,\n  loPass: 100,\n  hiPass: 600,\n  updateInterval: 32,\n  analyserOptions: { fftSize: 2048 },\n}\n\n// Memoized normalization function to avoid recreating on each render\nconst normalizeDb = (value: number) => {\n  if (value === -Infinity) return 0\n  const minDb = -100\n  const maxDb = -10\n  const db = 1 - (Math.max(minDb, Math.min(maxDb, value)) * -1) / 100\n  return Math.sqrt(db)\n}\n\n/**\n * Hook for tracking volume across multiple frequency bands\n * @param mediaStream - The MediaStream to analyze\n * @param options - Multiband options\n * @returns Array of volume levels for each frequency band\n */\nexport function useMultibandVolume(\n  mediaStream?: MediaStream | null,\n  options: MultiBandVolumeOptions = {}\n) {\n  const opts = useMemo(\n    () => ({ ...multibandDefaults, ...options }),\n    [\n      options.bands,\n      options.loPass,\n      options.hiPass,\n      options.updateInterval,\n      options.analyserOptions?.fftSize,\n      options.analyserOptions?.smoothingTimeConstant,\n      options.analyserOptions?.minDecibels,\n      options.analyserOptions?.maxDecibels,\n    ]\n  )\n\n  const [frequencyBands, setFrequencyBands] = useState<number[]>(() =>\n    new Array(opts.bands).fill(0)\n  )\n  const bandsRef = useRef<number[]>(new Array(opts.bands).fill(0))\n  const frameId = useRef<number | undefined>(undefined)\n\n  useEffect(() => {\n    if (!mediaStream) {\n      const emptyBands = new Array(opts.bands).fill(0)\n      setFrequencyBands(emptyBands)\n      bandsRef.current = emptyBands\n      return\n    }\n\n    const { analyser, cleanup } = createAudioAnalyser(\n      mediaStream,\n      opts.analyserOptions\n    )\n\n    const bufferLength = analyser.frequencyBinCount\n    const dataArray = new Float32Array(bufferLength)\n    const sliceStart = opts.loPass!\n    const sliceEnd = opts.hiPass!\n    const sliceLength = sliceEnd - sliceStart\n    const chunkSize = Math.ceil(sliceLength / opts.bands!)\n\n    let lastUpdate = 0\n    const updateInterval = opts.updateInterval!\n\n    const updateVolume = (timestamp: number) => {\n      if (timestamp - lastUpdate >= updateInterval) {\n        analyser.getFloatFrequencyData(dataArray)\n\n        // Process directly without creating intermediate arrays\n        const chunks = new Array(opts.bands!)\n\n        for (let i = 0; i < opts.bands!; i++) {\n          let sum = 0\n          let count = 0\n          const startIdx = sliceStart + i * chunkSize\n          const endIdx = Math.min(sliceStart + (i + 1) * chunkSize, sliceEnd)\n\n          for (let j = startIdx; j < endIdx; j++) {\n            sum += normalizeDb(dataArray[j])\n            count++\n          }\n\n          chunks[i] = count > 0 ? sum / count : 0\n        }\n\n        // Only update state if bands changed significantly\n        let hasChanged = false\n        for (let i = 0; i < chunks.length; i++) {\n          if (Math.abs(chunks[i] - bandsRef.current[i]) > 0.01) {\n            hasChanged = true\n            break\n          }\n        }\n\n        if (hasChanged) {\n          bandsRef.current = chunks\n          setFrequencyBands(chunks)\n        }\n\n        lastUpdate = timestamp\n      }\n\n      frameId.current = requestAnimationFrame(updateVolume)\n    }\n\n    frameId.current = requestAnimationFrame(updateVolume)\n\n    return () => {\n      cleanup()\n      if (frameId.current) {\n        cancelAnimationFrame(frameId.current)\n      }\n    }\n  }, [mediaStream, opts])\n\n  return frequencyBands\n}\n\ntype AnimationState =\n  | \"connecting\"\n  | \"initializing\"\n  | \"listening\"\n  | \"speaking\"\n  | \"thinking\"\n  | undefined\n\nexport const useBarAnimator = (\n  state: AnimationState,\n  columns: number,\n  interval: number\n): number[] => {\n  const indexRef = useRef(0)\n  const [currentFrame, setCurrentFrame] = useState<number[]>([])\n  const animationFrameId = useRef<number | null>(null)\n\n  // Memoize sequence generation\n  const sequence = useMemo(() => {\n    if (state === \"thinking\" || state === \"listening\") {\n      return generateListeningSequenceBar(columns)\n    } else if (state === \"connecting\" || state === \"initializing\") {\n      return generateConnectingSequenceBar(columns)\n    } else if (state === undefined || state === \"speaking\") {\n      return [new Array(columns).fill(0).map((_, idx) => idx)]\n    } else {\n      return [[]]\n    }\n  }, [state, columns])\n\n  useEffect(() => {\n    indexRef.current = 0\n    setCurrentFrame(sequence[0] || [])\n  }, [sequence])\n\n  useEffect(() => {\n    let startTime = performance.now()\n\n    const animate = (time: DOMHighResTimeStamp) => {\n      const timeElapsed = time - startTime\n\n      if (timeElapsed >= interval) {\n        indexRef.current = (indexRef.current + 1) % sequence.length\n        setCurrentFrame(sequence[indexRef.current] || [])\n        startTime = time\n      }\n\n      animationFrameId.current = requestAnimationFrame(animate)\n    }\n\n    animationFrameId.current = requestAnimationFrame(animate)\n\n    return () => {\n      if (animationFrameId.current !== null) {\n        cancelAnimationFrame(animationFrameId.current)\n      }\n    }\n  }, [interval, sequence])\n\n  return currentFrame\n}\n\n// Memoize sequence generators\nconst generateConnectingSequenceBar = (columns: number): number[][] => {\n  const seq = []\n  for (let x = 0; x < columns; x++) {\n    seq.push([x, columns - 1 - x])\n  }\n  return seq\n}\n\nconst generateListeningSequenceBar = (columns: number): number[][] => {\n  const center = Math.floor(columns / 2)\n  const noIndex = -1\n  return [[center], [noIndex]]\n}\n\nexport type AgentState =\n  | \"connecting\"\n  | \"initializing\"\n  | \"listening\"\n  | \"speaking\"\n  | \"thinking\"\n\nexport interface BarVisualizerProps\n  extends React.HTMLAttributes<HTMLDivElement> {\n  /** Voice assistant state */\n  state?: AgentState\n  /** Number of bars to display */\n  barCount?: number\n  /** Audio source */\n  mediaStream?: MediaStream | null\n  /** Min/max height as percentage */\n  minHeight?: number\n  maxHeight?: number\n  /** Enable demo mode with fake audio data */\n  demo?: boolean\n  /** Align bars from center instead of bottom */\n  centerAlign?: boolean\n}\n\nconst BarVisualizerComponent = React.forwardRef<\n  HTMLDivElement,\n  BarVisualizerProps\n>(\n  (\n    {\n      state,\n      barCount = 15,\n      mediaStream,\n      minHeight = 20,\n      maxHeight = 100,\n      demo = false,\n      centerAlign = false,\n      className,\n      style,\n      ...props\n    },\n    ref\n  ) => {\n    // Audio processing\n    const realVolumeBands = useMultibandVolume(mediaStream, {\n      bands: barCount,\n      loPass: 100,\n      hiPass: 200,\n    })\n\n    // Generate fake volume data for demo mode using refs to avoid state updates\n    const fakeVolumeBandsRef = useRef<number[]>(new Array(barCount).fill(0.2))\n    const [fakeVolumeBands, setFakeVolumeBands] = useState<number[]>(() =>\n      new Array(barCount).fill(0.2)\n    )\n    const fakeAnimationRef = useRef<number | undefined>(undefined)\n\n    // Animate fake volume bands for speaking and listening states\n    useEffect(() => {\n      if (!demo) return\n\n      if (state !== \"speaking\" && state !== \"listening\") {\n        const bands = new Array(barCount).fill(0.2)\n        fakeVolumeBandsRef.current = bands\n        setFakeVolumeBands(bands)\n        return\n      }\n\n      let lastUpdate = 0\n      const updateInterval = 50\n      const startTime = Date.now() / 1000\n\n      const updateFakeVolume = (timestamp: number) => {\n        if (timestamp - lastUpdate >= updateInterval) {\n          const time = Date.now() / 1000 - startTime\n          const newBands = new Array(barCount)\n\n          for (let i = 0; i < barCount; i++) {\n            const waveOffset = i * 0.5\n            const baseVolume = Math.sin(time * 2 + waveOffset) * 0.3 + 0.5\n            const randomNoise = Math.random() * 0.2\n            newBands[i] = Math.max(0.1, Math.min(1, baseVolume + randomNoise))\n          }\n\n          // Only update if values changed significantly\n          let hasChanged = false\n          for (let i = 0; i < barCount; i++) {\n            if (Math.abs(newBands[i] - fakeVolumeBandsRef.current[i]) > 0.05) {\n              hasChanged = true\n              break\n            }\n          }\n\n          if (hasChanged) {\n            fakeVolumeBandsRef.current = newBands\n            setFakeVolumeBands(newBands)\n          }\n\n          lastUpdate = timestamp\n        }\n\n        fakeAnimationRef.current = requestAnimationFrame(updateFakeVolume)\n      }\n\n      fakeAnimationRef.current = requestAnimationFrame(updateFakeVolume)\n\n      return () => {\n        if (fakeAnimationRef.current) {\n          cancelAnimationFrame(fakeAnimationRef.current)\n        }\n      }\n    }, [demo, state, barCount])\n\n    // Use fake or real volume data based on demo mode\n    const volumeBands = useMemo(\n      () => (demo ? fakeVolumeBands : realVolumeBands),\n      [demo, fakeVolumeBands, realVolumeBands]\n    )\n\n    // Animation sequencing\n    const highlightedIndices = useBarAnimator(\n      state,\n      barCount,\n      state === \"connecting\"\n        ? 2000 / barCount\n        : state === \"thinking\"\n          ? 150\n          : state === \"listening\"\n            ? 500\n            : 1000\n    )\n\n    return (\n      <div\n        ref={ref}\n        data-state={state}\n        className={cn(\n          \"relative flex justify-center gap-1.5\",\n          centerAlign ? \"items-center\" : \"items-end\",\n          \"bg-muted h-32 w-full overflow-hidden rounded-lg p-4\",\n          className\n        )}\n        style={{\n          ...style,\n        }}\n        {...props}\n      >\n        {volumeBands.map((volume, index) => {\n          const heightPct = Math.min(\n            maxHeight,\n            Math.max(minHeight, volume * 100 + 5)\n          )\n          const isHighlighted = highlightedIndices?.includes(index) ?? false\n\n          return (\n            <Bar\n              key={index}\n              heightPct={heightPct}\n              isHighlighted={isHighlighted}\n              state={state}\n            />\n          )\n        })}\n      </div>\n    )\n  }\n)\n\n// Memoized Bar component to prevent unnecessary re-renders\nconst Bar = React.memo<{\n  heightPct: number\n  isHighlighted: boolean\n  state?: AgentState\n}>(({ heightPct, isHighlighted, state }) => (\n  <div\n    data-highlighted={isHighlighted}\n    className={cn(\n      \"max-w-[12px] min-w-[8px] flex-1 transition-all duration-150\",\n      \"rounded-full\",\n      \"bg-border data-[highlighted=true]:bg-primary\",\n      state === \"speaking\" && \"bg-primary\",\n      state === \"thinking\" && isHighlighted && \"animate-pulse\"\n    )}\n    style={{\n      height: `${heightPct}%`,\n      animationDuration: state === \"thinking\" ? \"300ms\" : undefined,\n    }}\n  />\n))\n\nBar.displayName = \"Bar\"\n\n// Wrap the main component with React.memo for prop comparison optimization\nconst BarVisualizer = React.memo(\n  BarVisualizerComponent,\n  (prevProps, nextProps) => {\n    return (\n      prevProps.state === nextProps.state &&\n      prevProps.barCount === nextProps.barCount &&\n      prevProps.mediaStream === nextProps.mediaStream &&\n      prevProps.minHeight === nextProps.minHeight &&\n      prevProps.maxHeight === nextProps.maxHeight &&\n      prevProps.demo === nextProps.demo &&\n      prevProps.centerAlign === nextProps.centerAlign &&\n      prevProps.className === nextProps.className &&\n      JSON.stringify(prevProps.style) === JSON.stringify(nextProps.style)\n    )\n  }\n)\n\nBarVisualizerComponent.displayName = \"BarVisualizerComponent\"\nBarVisualizer.displayName = \"BarVisualizer\"\n\nexport { BarVisualizer }\n"
    },
    {
      "path": "components/ui/matrix.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport * as React from \"react\"\nimport { useEffect, useMemo, useRef, useState } from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nexport type Frame = number[][]\ntype MatrixMode = \"default\" | \"vu\"\n\ninterface CellPosition {\n  x: number\n  y: number\n}\n\ninterface MatrixProps extends React.HTMLAttributes<HTMLDivElement> {\n  rows: number\n  cols: number\n  pattern?: Frame\n  frames?: Frame[]\n  fps?: number\n  autoplay?: boolean\n  loop?: boolean\n  size?: number\n  gap?: number\n  palette?: {\n    on: string\n    off: string\n  }\n  brightness?: number\n  ariaLabel?: string\n  onFrame?: (index: number) => void\n  mode?: MatrixMode\n  levels?: number[]\n}\n\nfunction clamp(value: number): number {\n  return Math.max(0, Math.min(1, value))\n}\n\nfunction ensureFrameSize(frame: Frame, rows: number, cols: number): Frame {\n  const result: Frame = []\n  for (let r = 0; r < rows; r++) {\n    const row = frame[r] || []\n    result.push([])\n    for (let c = 0; c < cols; c++) {\n      result[r][c] = row[c] ?? 0\n    }\n  }\n  return result\n}\n\nfunction useAnimation(\n  frames: Frame[] | undefined,\n  options: {\n    fps: number\n    autoplay: boolean\n    loop: boolean\n    onFrame?: (index: number) => void\n  }\n): { frameIndex: number; isPlaying: boolean } {\n  const [frameIndex, setFrameIndex] = useState(0)\n  const [isPlaying, setIsPlaying] = useState(options.autoplay)\n  const frameIdRef = useRef<number | undefined>(undefined)\n  const lastTimeRef = useRef<number>(0)\n  const accumulatorRef = useRef<number>(0)\n\n  useEffect(() => {\n    if (!frames || frames.length === 0 || !isPlaying) {\n      return\n    }\n\n    const frameInterval = 1000 / options.fps\n\n    const animate = (currentTime: number) => {\n      if (lastTimeRef.current === 0) {\n        lastTimeRef.current = currentTime\n      }\n\n      const deltaTime = currentTime - lastTimeRef.current\n      lastTimeRef.current = currentTime\n      accumulatorRef.current += deltaTime\n\n      if (accumulatorRef.current >= frameInterval) {\n        accumulatorRef.current -= frameInterval\n\n        setFrameIndex((prev) => {\n          const next = prev + 1\n          if (next >= frames.length) {\n            if (options.loop) {\n              options.onFrame?.(0)\n              return 0\n            } else {\n              setIsPlaying(false)\n              return prev\n            }\n          }\n          options.onFrame?.(next)\n          return next\n        })\n      }\n\n      frameIdRef.current = requestAnimationFrame(animate)\n    }\n\n    frameIdRef.current = requestAnimationFrame(animate)\n\n    return () => {\n      if (frameIdRef.current) {\n        cancelAnimationFrame(frameIdRef.current)\n      }\n    }\n  }, [frames, isPlaying, options.fps, options.loop, options.onFrame])\n\n  useEffect(() => {\n    setFrameIndex(0)\n    setIsPlaying(options.autoplay)\n    lastTimeRef.current = 0\n    accumulatorRef.current = 0\n  }, [frames, options.autoplay])\n\n  return { frameIndex, isPlaying }\n}\n\nfunction emptyFrame(rows: number, cols: number): Frame {\n  return Array.from({ length: rows }, () => Array(cols).fill(0))\n}\n\nfunction setPixel(frame: Frame, row: number, col: number, value: number): void {\n  if (row >= 0 && row < frame.length && col >= 0 && col < frame[0].length) {\n    frame[row][col] = value\n  }\n}\n\nexport const digits: Frame[] = [\n  [\n    [0, 1, 1, 1, 0],\n    [1, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [0, 1, 1, 1, 0],\n  ],\n  [\n    [0, 0, 1, 0, 0],\n    [0, 1, 1, 0, 0],\n    [0, 0, 1, 0, 0],\n    [0, 0, 1, 0, 0],\n    [0, 0, 1, 0, 0],\n    [0, 0, 1, 0, 0],\n    [0, 1, 1, 1, 0],\n  ],\n  [\n    [0, 1, 1, 1, 0],\n    [1, 0, 0, 0, 1],\n    [0, 0, 0, 0, 1],\n    [0, 0, 0, 1, 0],\n    [0, 0, 1, 0, 0],\n    [0, 1, 0, 0, 0],\n    [1, 1, 1, 1, 1],\n  ],\n  [\n    [0, 1, 1, 1, 0],\n    [1, 0, 0, 0, 1],\n    [0, 0, 0, 0, 1],\n    [0, 0, 1, 1, 0],\n    [0, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [0, 1, 1, 1, 0],\n  ],\n  [\n    [0, 0, 0, 1, 0],\n    [0, 0, 1, 1, 0],\n    [0, 1, 0, 1, 0],\n    [1, 0, 0, 1, 0],\n    [1, 1, 1, 1, 1],\n    [0, 0, 0, 1, 0],\n    [0, 0, 0, 1, 0],\n  ],\n  [\n    [1, 1, 1, 1, 1],\n    [1, 0, 0, 0, 0],\n    [1, 1, 1, 1, 0],\n    [0, 0, 0, 0, 1],\n    [0, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [0, 1, 1, 1, 0],\n  ],\n  [\n    [0, 1, 1, 1, 0],\n    [1, 0, 0, 0, 0],\n    [1, 0, 0, 0, 0],\n    [1, 1, 1, 1, 0],\n    [1, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [0, 1, 1, 1, 0],\n  ],\n  [\n    [1, 1, 1, 1, 1],\n    [0, 0, 0, 0, 1],\n    [0, 0, 0, 1, 0],\n    [0, 0, 1, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n  ],\n  [\n    [0, 1, 1, 1, 0],\n    [1, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [0, 1, 1, 1, 0],\n    [1, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [0, 1, 1, 1, 0],\n  ],\n  [\n    [0, 1, 1, 1, 0],\n    [1, 0, 0, 0, 1],\n    [1, 0, 0, 0, 1],\n    [0, 1, 1, 1, 1],\n    [0, 0, 0, 0, 1],\n    [0, 0, 0, 0, 1],\n    [0, 1, 1, 1, 0],\n  ],\n]\n\nexport const chevronLeft: Frame = [\n  [0, 0, 0, 1, 0],\n  [0, 0, 1, 0, 0],\n  [0, 1, 0, 0, 0],\n  [0, 0, 1, 0, 0],\n  [0, 0, 0, 1, 0],\n]\n\nexport const chevronRight: Frame = [\n  [0, 1, 0, 0, 0],\n  [0, 0, 1, 0, 0],\n  [0, 0, 0, 1, 0],\n  [0, 0, 1, 0, 0],\n  [0, 1, 0, 0, 0],\n]\n\nexport const loader: Frame[] = (() => {\n  const frames: Frame[] = []\n  const size = 7\n  const center = 3\n  const radius = 2.5\n\n  for (let frame = 0; frame < 12; frame++) {\n    const f = emptyFrame(size, size)\n    for (let i = 0; i < 8; i++) {\n      const angle = (frame / 12) * Math.PI * 2 + (i / 8) * Math.PI * 2\n      const x = Math.round(center + Math.cos(angle) * radius)\n      const y = Math.round(center + Math.sin(angle) * radius)\n      const brightness = 1 - i / 10\n      setPixel(f, y, x, Math.max(0.2, brightness))\n    }\n    frames.push(f)\n  }\n\n  return frames\n})()\n\nexport const pulse: Frame[] = (() => {\n  const frames: Frame[] = []\n  const size = 7\n  const center = 3\n\n  for (let frame = 0; frame < 16; frame++) {\n    const f = emptyFrame(size, size)\n    const phase = (frame / 16) * Math.PI * 2\n    const intensity = (Math.sin(phase) + 1) / 2\n\n    setPixel(f, center, center, 1)\n\n    const radius = Math.floor((1 - intensity) * 3) + 1\n    for (let dy = -radius; dy <= radius; dy++) {\n      for (let dx = -radius; dx <= radius; dx++) {\n        const dist = Math.sqrt(dx * dx + dy * dy)\n        if (Math.abs(dist - radius) < 0.7) {\n          setPixel(f, center + dy, center + dx, intensity * 0.6)\n        }\n      }\n    }\n\n    frames.push(f)\n  }\n\n  return frames\n})()\n\nexport function vu(columns: number, levels: number[]): Frame {\n  const rows = 7\n  const frame = emptyFrame(rows, columns)\n\n  for (let col = 0; col < Math.min(columns, levels.length); col++) {\n    const level = Math.max(0, Math.min(1, levels[col]))\n    const height = Math.floor(level * rows)\n\n    for (let row = 0; row < rows; row++) {\n      const rowFromBottom = rows - 1 - row\n      if (rowFromBottom < height) {\n        let brightness = 1\n        if (row < rows * 0.3) {\n          brightness = 1\n        } else if (row < rows * 0.6) {\n          brightness = 0.8\n        } else {\n          brightness = 0.6\n        }\n        frame[row][col] = brightness\n      }\n    }\n  }\n\n  return frame\n}\n\nexport const wave: Frame[] = (() => {\n  const frames: Frame[] = []\n  const rows = 7\n  const cols = 7\n\n  for (let frame = 0; frame < 24; frame++) {\n    const f = emptyFrame(rows, cols)\n    const phase = (frame / 24) * Math.PI * 2\n\n    for (let col = 0; col < cols; col++) {\n      const colPhase = (col / cols) * Math.PI * 2\n      const height = Math.sin(phase + colPhase) * 2.5 + 3.5\n      const row = Math.floor(height)\n\n      if (row >= 0 && row < rows) {\n        setPixel(f, row, col, 1)\n        const frac = height - row\n        if (row > 0) setPixel(f, row - 1, col, 1 - frac)\n        if (row < rows - 1) setPixel(f, row + 1, col, frac)\n      }\n    }\n\n    frames.push(f)\n  }\n\n  return frames\n})()\n\nexport const snake: Frame[] = (() => {\n  const frames: Frame[] = []\n  const rows = 7\n  const cols = 7\n  const path: Array<[number, number]> = []\n\n  let x = 0\n  let y = 0\n  let dx = 1\n  let dy = 0\n\n  const visited = new Set<string>()\n  while (path.length < rows * cols) {\n    path.push([y, x])\n    visited.add(`${y},${x}`)\n\n    const nextX = x + dx\n    const nextY = y + dy\n\n    if (\n      nextX >= 0 &&\n      nextX < cols &&\n      nextY >= 0 &&\n      nextY < rows &&\n      !visited.has(`${nextY},${nextX}`)\n    ) {\n      x = nextX\n      y = nextY\n    } else {\n      const newDx = -dy\n      const newDy = dx\n      dx = newDx\n      dy = newDy\n\n      const nextX = x + dx\n      const nextY = y + dy\n\n      if (\n        nextX >= 0 &&\n        nextX < cols &&\n        nextY >= 0 &&\n        nextY < rows &&\n        !visited.has(`${nextY},${nextX}`)\n      ) {\n        x = nextX\n        y = nextY\n      } else {\n        break\n      }\n    }\n  }\n\n  const snakeLength = 5\n  for (let frame = 0; frame < path.length; frame++) {\n    const f = emptyFrame(rows, cols)\n\n    for (let i = 0; i < snakeLength; i++) {\n      const idx = frame - i\n      if (idx >= 0 && idx < path.length) {\n        const [y, x] = path[idx]\n        const brightness = 1 - i / snakeLength\n        setPixel(f, y, x, brightness)\n      }\n    }\n\n    frames.push(f)\n  }\n\n  return frames\n})()\n\nexport const Matrix = React.forwardRef<HTMLDivElement, MatrixProps>(\n  (\n    {\n      rows,\n      cols,\n      pattern,\n      frames,\n      fps = 12,\n      autoplay = true,\n      loop = true,\n      size = 10,\n      gap = 2,\n      palette = {\n        on: \"currentColor\",\n        off: \"var(--muted-foreground)\",\n      },\n      brightness = 1,\n      ariaLabel,\n      onFrame,\n      mode = \"default\",\n      levels,\n      className,\n      ...props\n    },\n    ref\n  ) => {\n    const { frameIndex } = useAnimation(frames, {\n      fps,\n      autoplay: autoplay && !pattern,\n      loop,\n      onFrame,\n    })\n\n    const currentFrame = useMemo(() => {\n      if (mode === \"vu\" && levels && levels.length > 0) {\n        return ensureFrameSize(vu(cols, levels), rows, cols)\n      }\n\n      if (pattern) {\n        return ensureFrameSize(pattern, rows, cols)\n      }\n\n      if (frames && frames.length > 0) {\n        return ensureFrameSize(frames[frameIndex] || frames[0], rows, cols)\n      }\n\n      return ensureFrameSize([], rows, cols)\n    }, [pattern, frames, frameIndex, rows, cols, mode, levels])\n\n    const cellPositions = useMemo(() => {\n      const positions: CellPosition[][] = []\n\n      for (let row = 0; row < rows; row++) {\n        positions[row] = []\n        for (let col = 0; col < cols; col++) {\n          positions[row][col] = {\n            x: col * (size + gap),\n            y: row * (size + gap),\n          }\n        }\n      }\n\n      return positions\n    }, [rows, cols, size, gap])\n\n    const svgDimensions = useMemo(() => {\n      return {\n        width: cols * (size + gap) - gap,\n        height: rows * (size + gap) - gap,\n      }\n    }, [rows, cols, size, gap])\n\n    const isAnimating = !pattern && frames && frames.length > 0\n\n    return (\n      <div\n        ref={ref}\n        role=\"img\"\n        aria-label={ariaLabel ?? \"matrix display\"}\n        aria-live={isAnimating ? \"polite\" : undefined}\n        className={cn(\"relative inline-block\", className)}\n        style={\n          {\n            \"--matrix-on\": palette.on,\n            \"--matrix-off\": palette.off,\n            \"--matrix-gap\": `${gap}px`,\n            \"--matrix-size\": `${size}px`,\n          } as React.CSSProperties\n        }\n        {...props}\n      >\n        <svg\n          width={svgDimensions.width}\n          height={svgDimensions.height}\n          viewBox={`0 0 ${svgDimensions.width} ${svgDimensions.height}`}\n          xmlns=\"http://www.w3.org/2000/svg\"\n          className=\"block\"\n          style={{ overflow: \"visible\" }}\n        >\n          <defs>\n            <radialGradient id=\"matrix-pixel-on\" cx=\"50%\" cy=\"50%\" r=\"50%\">\n              <stop offset=\"0%\" stopColor=\"var(--matrix-on)\" stopOpacity=\"1\" />\n              <stop\n                offset=\"70%\"\n                stopColor=\"var(--matrix-on)\"\n                stopOpacity=\"0.85\"\n              />\n              <stop\n                offset=\"100%\"\n                stopColor=\"var(--matrix-on)\"\n                stopOpacity=\"0.6\"\n              />\n            </radialGradient>\n\n            <radialGradient id=\"matrix-pixel-off\" cx=\"50%\" cy=\"50%\" r=\"50%\">\n              <stop\n                offset=\"0%\"\n                stopColor=\"var(--muted-foreground)\"\n                stopOpacity=\"1\"\n              />\n              <stop\n                offset=\"100%\"\n                stopColor=\"var(--muted-foreground)\"\n                stopOpacity=\"0.7\"\n              />\n            </radialGradient>\n\n            <filter\n              id=\"matrix-glow\"\n              x=\"-50%\"\n              y=\"-50%\"\n              width=\"200%\"\n              height=\"200%\"\n            >\n              <feGaussianBlur stdDeviation=\"2\" result=\"blur\" />\n              <feComposite in=\"SourceGraphic\" in2=\"blur\" operator=\"over\" />\n            </filter>\n          </defs>\n\n          <style>\n            {`\n              .matrix-pixel {\n                transition: opacity 300ms ease-out, transform 150ms ease-out;\n                transform-origin: center;\n                transform-box: fill-box;\n              }\n              .matrix-pixel-active {\n                filter: url(#matrix-glow);\n              }\n            `}\n          </style>\n\n          {currentFrame.map((row, rowIndex) =>\n            row.map((value, colIndex) => {\n              const pos = cellPositions[rowIndex]?.[colIndex]\n              if (!pos) return null\n\n              const opacity = clamp(brightness * value)\n              const isActive = opacity > 0.5\n              const isOn = opacity > 0.05\n              const fill = isOn\n                ? \"url(#matrix-pixel-on)\"\n                : \"url(#matrix-pixel-off)\"\n\n              const scale = isActive ? 1.1 : 1\n              const radius = (size / 2) * 0.9\n\n              return (\n                <circle\n                  key={`${rowIndex}-${colIndex}`}\n                  className={cn(\n                    \"matrix-pixel\",\n                    isActive && \"matrix-pixel-active\",\n                    !isOn && \"opacity-20 dark:opacity-[0.1]\"\n                  )}\n                  cx={pos.x + size / 2}\n                  cy={pos.y + size / 2}\n                  r={radius}\n                  fill={fill}\n                  opacity={isOn ? opacity : 0.1}\n                  style={{\n                    transform: `scale(${scale})`,\n                  }}\n                />\n              )\n            })\n          )}\n        </svg>\n      </div>\n    )\n  }\n)\n\nMatrix.displayName = \"Matrix\"\n"
    },
    {
      "path": "components/ui/voice-picker.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport * as React from \"react\"\nimport type { ElevenLabs } from \"@elevenlabs/elevenlabs-js\"\nimport { Check, ChevronsUpDown, Pause, Play } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\nimport {\n  AudioPlayerProvider,\n  useAudioPlayer,\n} from \"@/components/ui/audio-player\"\nimport { Button } from \"@/components/ui/button\"\nimport {\n  Command,\n  CommandEmpty,\n  CommandGroup,\n  CommandInput,\n  CommandItem,\n  CommandList,\n} from \"@/components/ui/command\"\nimport { Orb } from \"@/components/ui/orb\"\nimport {\n  Popover,\n  PopoverContent,\n  PopoverTrigger,\n} from \"@/components/ui/popover\"\n\ninterface VoicePickerProps {\n  voices: ElevenLabs.Voice[]\n  value?: string\n  onValueChange?: (value: string) => void\n  placeholder?: string\n  className?: string\n  open?: boolean\n  onOpenChange?: (open: boolean) => void\n}\n\nfunction VoicePicker({\n  voices,\n  value,\n  onValueChange,\n  placeholder = \"Select a voice...\",\n  className,\n  open,\n  onOpenChange,\n}: VoicePickerProps) {\n  const [internalOpen, setInternalOpen] = React.useState(false)\n  const isControlled = open !== undefined\n  const isOpen = isControlled ? open : internalOpen\n  const setIsOpen = isControlled ? onOpenChange : setInternalOpen\n\n  const selectedVoice = voices.find((v) => v.voiceId === value)\n\n  return (\n    <AudioPlayerProvider>\n      <Popover open={isOpen} onOpenChange={setIsOpen}>\n        <PopoverTrigger asChild>\n          <Button\n            variant=\"outline\"\n            role=\"combobox\"\n            aria-expanded={isOpen}\n            className={cn(\"w-full justify-between\", className)}\n          >\n            {selectedVoice ? (\n              <div className=\"flex items-center gap-2 overflow-hidden\">\n                <div className=\"relative size-6 shrink-0 overflow-visible\">\n                  <Orb agentState=\"thinking\" className=\"absolute inset-0\" />\n                </div>\n                <span className=\"truncate\">{selectedVoice.name}</span>\n              </div>\n            ) : (\n              placeholder\n            )}\n            <ChevronsUpDown className=\"ml-2 size-4 shrink-0 opacity-50\" />\n          </Button>\n        </PopoverTrigger>\n        <PopoverContent className=\"w-[var(--radix-popover-trigger-width)] p-0\">\n          <Command>\n            <CommandInput placeholder=\"Search voices...\" />\n            <CommandList>\n              <CommandEmpty>No voice found.</CommandEmpty>\n              <CommandGroup>\n                {voices.map((voice) => (\n                  <VoicePickerItem\n                    key={voice.voiceId}\n                    voice={voice}\n                    isSelected={value === voice.voiceId}\n                    onSelect={() => {\n                      onValueChange?.(voice.voiceId!)\n                    }}\n                  />\n                ))}\n              </CommandGroup>\n            </CommandList>\n          </Command>\n        </PopoverContent>\n      </Popover>\n    </AudioPlayerProvider>\n  )\n}\n\ninterface VoicePickerItemProps {\n  voice: ElevenLabs.Voice\n  isSelected: boolean\n  onSelect: () => void\n}\n\nfunction VoicePickerItem({\n  voice,\n  isSelected,\n  onSelect,\n}: VoicePickerItemProps) {\n  const [isHovered, setIsHovered] = React.useState(false)\n  const player = useAudioPlayer()\n\n  const preview = voice.previewUrl\n  const audioItem = React.useMemo(\n    () => (preview ? { id: voice.voiceId!, src: preview, data: voice } : null),\n    [preview, voice]\n  )\n\n  const isPlaying =\n    audioItem && player.isItemActive(audioItem.id) && player.isPlaying\n\n  const handlePreview = React.useCallback(\n    async (e: React.MouseEvent) => {\n      e.preventDefault()\n      e.stopPropagation()\n\n      if (!audioItem) return\n\n      if (isPlaying) {\n        player.pause()\n      } else {\n        player.play(audioItem)\n      }\n    },\n    [audioItem, isPlaying, player]\n  )\n\n  return (\n    <CommandItem\n      value={voice.voiceId!}\n      keywords={[\n        voice.name,\n        voice.labels?.accent,\n        voice.labels?.gender,\n        voice.labels?.age,\n        voice.labels?.description,\n        voice.labels?.[\"use case\"],\n      ].filter((k): k is string => Boolean(k))}\n      onSelect={onSelect}\n      className=\"flex items-center gap-3\"\n    >\n      <div\n        className=\"relative z-10 size-8 shrink-0 cursor-pointer overflow-visible\"\n        onMouseEnter={() => setIsHovered(true)}\n        onMouseLeave={() => setIsHovered(false)}\n        onClick={handlePreview}\n      >\n        <Orb\n          agentState={isPlaying ? \"talking\" : undefined}\n          className=\"pointer-events-none absolute inset-0\"\n        />\n        {preview && isHovered && (\n          <div className=\"pointer-events-none absolute inset-0 flex size-8 shrink-0 items-center justify-center rounded-full bg-black/40 backdrop-blur-sm transition-opacity hover:bg-black/50\">\n            {isPlaying ? (\n              <Pause className=\"size-3 text-white\" />\n            ) : (\n              <Play className=\"size-3 text-white\" />\n            )}\n          </div>\n        )}\n      </div>\n\n      <div className=\"flex flex-1 flex-col gap-0.5\">\n        <span className=\"font-medium\">{voice.name}</span>\n        {voice.labels && (\n          <div className=\"text-muted-foreground flex items-center gap-1.5 text-xs\">\n            {voice.labels.accent && <span>{voice.labels.accent}</span>}\n            {voice.labels.gender && <span></span>}\n            {voice.labels.gender && (\n              <span className=\"capitalize\">{voice.labels.gender}</span>\n            )}\n            {voice.labels.age && <span></span>}\n            {voice.labels.age && (\n              <span className=\"capitalize\">{voice.labels.age}</span>\n            )}\n          </div>\n        )}\n      </div>\n\n      <Check\n        className={cn(\n          \"ml-auto size-4 shrink-0\",\n          isSelected ? \"opacity-100\" : \"opacity-0\"\n        )}\n      />\n    </CommandItem>\n  )\n}\n\nexport { VoicePicker, VoicePickerItem }\n"
    },
    {
      "path": "components/ui/voice-button.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport * as React from \"react\"\nimport { CheckIcon, XIcon } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\nimport { Button } from \"@/components/ui/button\"\nimport { LiveWaveform } from \"@/components/ui/live-waveform\"\n\nexport type VoiceButtonState =\n  | \"idle\"\n  | \"recording\"\n  | \"processing\"\n  | \"success\"\n  | \"error\"\n\nexport interface VoiceButtonProps\n  extends Omit<React.ButtonHTMLAttributes<HTMLButtonElement>, \"onError\"> {\n  /**\n   * Current state of the voice button\n   * @default \"idle\"\n   */\n  state?: VoiceButtonState\n\n  /**\n   * Callback when button is clicked\n   */\n  onPress?: () => void\n\n  /**\n   * Content to display on the left side (label)\n   * Can be a string or ReactNode for custom components\n   */\n  label?: React.ReactNode\n\n  /**\n   * Content to display on the right side (e.g., keyboard shortcut)\n   * Can be a string or ReactNode for custom components\n   * @example \"Space\" or <kbd>K</kbd>\n   */\n  trailing?: React.ReactNode\n\n  /**\n   * Icon to display in the center when idle (for icon size buttons)\n   */\n  icon?: React.ReactNode\n\n  /**\n   * Custom variant for the button\n   * @default \"outline\"\n   */\n  variant?:\n    | \"default\"\n    | \"destructive\"\n    | \"outline\"\n    | \"secondary\"\n    | \"ghost\"\n    | \"link\"\n\n  /**\n   * Size of the button\n   * @default \"default\"\n   */\n  size?: \"default\" | \"sm\" | \"lg\" | \"icon\"\n\n  /**\n   * Custom className for the button\n   */\n  className?: string\n\n  /**\n   * Custom className for the waveform container\n   */\n  waveformClassName?: string\n\n  /**\n   * Duration in ms to show success/error states\n   * @default 1500\n   */\n  feedbackDuration?: number\n\n  /**\n   * Disable the button\n   */\n  disabled?: boolean\n}\n\nexport const VoiceButton = React.forwardRef<\n  HTMLButtonElement,\n  VoiceButtonProps\n>(\n  (\n    {\n      state = \"idle\",\n      onPress,\n      label,\n      trailing,\n      icon,\n      variant = \"outline\",\n      size = \"default\",\n      className,\n      waveformClassName,\n      feedbackDuration = 1500,\n      disabled,\n      onClick,\n      ...props\n    },\n    ref\n  ) => {\n    const [showFeedback, setShowFeedback] = React.useState(false)\n\n    React.useEffect(() => {\n      if (state === \"success\" || state === \"error\") {\n        setShowFeedback(true)\n        const timeout = setTimeout(\n          () => setShowFeedback(false),\n          feedbackDuration\n        )\n        return () => clearTimeout(timeout)\n      } else {\n        // Reset feedback when state changes away from success/error\n        setShowFeedback(false)\n      }\n    }, [state, feedbackDuration])\n\n    const handleClick = (e: React.MouseEvent<HTMLButtonElement>) => {\n      onClick?.(e)\n      onPress?.()\n    }\n\n    const isRecording = state === \"recording\"\n    const isProcessing = state === \"processing\"\n    const isSuccess = state === \"success\"\n    const isError = state === \"error\"\n\n    const buttonVariant = variant\n    const isDisabled = disabled || isProcessing\n\n    const displayLabel = label\n\n    const shouldShowWaveform = isRecording || isProcessing || showFeedback\n    const shouldShowTrailing = !shouldShowWaveform && trailing\n\n    return (\n      <Button\n        ref={ref}\n        type=\"button\"\n        variant={buttonVariant}\n        size={size}\n        onClick={handleClick}\n        disabled={isDisabled}\n        className={cn(\n          \"gap-2 transition-all duration-200\",\n          size === \"icon\" && \"relative\",\n          className\n        )}\n        aria-label={\"Voice Button\"}\n        {...props}\n      >\n        {size !== \"icon\" && displayLabel && (\n          <span className=\"inline-flex shrink-0 items-center justify-start\">\n            {displayLabel}\n          </span>\n        )}\n\n        <div\n          className={cn(\n            \"relative box-content flex shrink-0 items-center justify-center overflow-hidden transition-all duration-300\",\n            size === \"icon\"\n              ? \"absolute inset-0 rounded-sm border-0\"\n              : \"h-5 w-24 rounded-sm border\",\n            isRecording\n              ? \"bg-primary/10 dark:bg-primary/5\"\n              : size === \"icon\"\n                ? \"bg-muted/50 border-0\"\n                : \"border-border bg-muted/50\",\n            waveformClassName\n          )}\n        >\n          {shouldShowWaveform && (\n            <LiveWaveform\n              active={isRecording}\n              processing={isProcessing || isSuccess}\n              barWidth={2}\n              barGap={1}\n              barRadius={4}\n              fadeEdges={false}\n              sensitivity={1.8}\n              smoothingTimeConstant={0.85}\n              height={20}\n              mode=\"static\"\n              className=\"animate-in fade-in absolute inset-0 h-full w-full duration-300\"\n            />\n          )}\n\n          {shouldShowTrailing && (\n            <div className=\"animate-in fade-in absolute inset-0 flex items-center justify-center duration-300\">\n              {typeof trailing === \"string\" ? (\n                <span className=\"text-muted-foreground px-1.5 font-mono text-[10px] font-medium select-none\">\n                  {trailing}\n                </span>\n              ) : (\n                trailing\n              )}\n            </div>\n          )}\n\n          {!shouldShowWaveform &&\n            !shouldShowTrailing &&\n            icon &&\n            size === \"icon\" && (\n              <div className=\"animate-in fade-in absolute inset-0 flex items-center justify-center duration-300\">\n                {icon}\n              </div>\n            )}\n\n          {isSuccess && showFeedback && (\n            <div className=\"animate-in fade-in bg-background/80 absolute inset-0 flex items-center justify-center duration-300\">\n              <span className=\"text-primary text-[10px] font-medium\">\n                <CheckIcon className=\"size-3.5\" />\n              </span>\n            </div>\n          )}\n\n          {/* Error Icon */}\n          {isError && showFeedback && (\n            <div className=\"animate-in fade-in bg-background/80 absolute inset-0 flex items-center justify-center duration-300\">\n              <span className=\"text-destructive text-[10px] font-medium\">\n                <XIcon className=\"size-3.5\" />\n              </span>\n            </div>\n          )}\n        </div>\n      </Button>\n    )\n  }\n)\n\nVoiceButton.displayName = \"VoiceButton\"\n"
    },
    {
      "path": "components/ui/conversation-bar.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport * as React from \"react\"\nimport { useConversation } from \"@elevenlabs/react\"\nimport {\n  ArrowUpIcon,\n  ChevronDown,\n  Keyboard,\n  Mic,\n  MicOff,\n  PhoneIcon,\n  XIcon,\n} from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\nimport { Button } from \"@/components/ui/button\"\nimport { Card } from \"@/components/ui/card\"\nimport { LiveWaveform } from \"@/components/ui/live-waveform\"\nimport { Separator } from \"@/components/ui/separator\"\nimport { Textarea } from \"@/components/ui/textarea\"\n\nexport interface ConversationBarProps {\n  /**\n   * ElevenLabs Agent ID to connect to\n   */\n  agentId: string\n\n  /**\n   * Custom className for the container\n   */\n  className?: string\n\n  /**\n   * Custom className for the waveform\n   */\n  waveformClassName?: string\n\n  /**\n   * Callback when conversation connects\n   */\n  onConnect?: () => void\n\n  /**\n   * Callback when conversation disconnects\n   */\n  onDisconnect?: () => void\n\n  /**\n   * Callback when an error occurs\n   */\n  onError?: (error: Error) => void\n\n  /**\n   * Callback when a message is received\n   */\n  onMessage?: (message: { source: \"user\" | \"ai\"; message: string }) => void\n\n  /**\n   * Callback when user sends a message\n   */\n  onSendMessage?: (message: string) => void\n}\n\nexport const ConversationBar = React.forwardRef<\n  HTMLDivElement,\n  ConversationBarProps\n>(\n  (\n    {\n      agentId,\n      className,\n      waveformClassName,\n      onConnect,\n      onDisconnect,\n      onError,\n      onMessage,\n      onSendMessage,\n    },\n    ref\n  ) => {\n    const [isMuted, setIsMuted] = React.useState(false)\n    const [agentState, setAgentState] = React.useState<\n      \"disconnected\" | \"connecting\" | \"connected\" | \"disconnecting\" | null\n    >(\"disconnected\")\n    const [keyboardOpen, setKeyboardOpen] = React.useState(false)\n    const [textInput, setTextInput] = React.useState(\"\")\n    const mediaStreamRef = React.useRef<MediaStream | null>(null)\n\n    const conversation = useConversation({\n      onConnect: () => {\n        onConnect?.()\n      },\n      onDisconnect: () => {\n        setAgentState(\"disconnected\")\n        onDisconnect?.()\n        setKeyboardOpen(false)\n      },\n      onMessage: (message) => {\n        onMessage?.(message)\n      },\n      micMuted: isMuted,\n      onError: (error: unknown) => {\n        console.error(\"Error:\", error)\n        setAgentState(\"disconnected\")\n        const errorObj =\n          error instanceof Error\n            ? error\n            : new Error(\n                typeof error === \"string\" ? error : JSON.stringify(error)\n              )\n        onError?.(errorObj)\n      },\n    })\n\n    const getMicStream = React.useCallback(async () => {\n      if (mediaStreamRef.current) return mediaStreamRef.current\n\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n      mediaStreamRef.current = stream\n\n      return stream\n    }, [])\n\n    const startConversation = React.useCallback(async () => {\n      try {\n        setAgentState(\"connecting\")\n\n        await getMicStream()\n\n        await conversation.startSession({\n          agentId,\n          connectionType: \"webrtc\",\n          onStatusChange: (status) => setAgentState(status.status),\n        })\n      } catch (error) {\n        console.error(\"Error starting conversation:\", error)\n        setAgentState(\"disconnected\")\n        onError?.(error as Error)\n      }\n    }, [conversation, getMicStream, agentId, onError])\n\n    const handleEndSession = React.useCallback(() => {\n      conversation.endSession()\n      setAgentState(\"disconnected\")\n\n      if (mediaStreamRef.current) {\n        mediaStreamRef.current.getTracks().forEach((t) => t.stop())\n        mediaStreamRef.current = null\n      }\n    }, [conversation])\n\n    const toggleMute = React.useCallback(() => {\n      setIsMuted((prev) => !prev)\n    }, [])\n\n    const handleStartOrEnd = React.useCallback(() => {\n      if (agentState === \"connected\" || agentState === \"connecting\") {\n        handleEndSession()\n      } else if (agentState === \"disconnected\") {\n        startConversation()\n      }\n    }, [agentState, handleEndSession, startConversation])\n\n    const handleSendText = React.useCallback(() => {\n      if (!textInput.trim()) return\n\n      const messageToSend = textInput\n      conversation.sendUserMessage(messageToSend)\n      setTextInput(\"\")\n      onSendMessage?.(messageToSend)\n    }, [conversation, textInput, onSendMessage])\n\n    const isConnected = agentState === \"connected\"\n\n    const handleTextChange = React.useCallback(\n      (e: React.ChangeEvent<HTMLTextAreaElement>) => {\n        const value = e.target.value\n        setTextInput(value)\n\n        if (value.trim() && isConnected) {\n          conversation.sendContextualUpdate(value)\n        }\n      },\n      [conversation, isConnected]\n    )\n\n    const handleKeyDown = React.useCallback(\n      (e: React.KeyboardEvent<HTMLTextAreaElement>) => {\n        if (e.key === \"Enter\" && !e.shiftKey) {\n          e.preventDefault()\n          handleSendText()\n        }\n      },\n      [handleSendText]\n    )\n\n    React.useEffect(() => {\n      return () => {\n        if (mediaStreamRef.current) {\n          mediaStreamRef.current.getTracks().forEach((t) => t.stop())\n        }\n      }\n    }, [])\n\n    return (\n      <div\n        ref={ref}\n        className={cn(\"flex w-full items-end justify-center p-4\", className)}\n      >\n        <Card className=\"m-0 w-full gap-0 border p-0 shadow-lg\">\n          <div className=\"flex flex-col-reverse\">\n            <div>\n              {keyboardOpen && <Separator />}\n              <div className=\"flex items-center justify-between gap-2 p-2\">\n                <div className=\"h-8 w-[120px] md:h-10\">\n                  <div\n                    className={cn(\n                      \"flex h-full items-center gap-2 rounded-md py-1\",\n                      \"bg-foreground/5 text-foreground/70\"\n                    )}\n                  >\n                    <div className=\"h-full flex-1\">\n                      <div\n                        className={cn(\n                          \"relative flex h-full w-full shrink-0 items-center justify-center overflow-hidden rounded-sm\",\n                          waveformClassName\n                        )}\n                      >\n                        <LiveWaveform\n                          key={\n                            agentState === \"disconnected\" ? \"idle\" : \"active\"\n                          }\n                          active={isConnected && !isMuted}\n                          processing={agentState === \"connecting\"}\n                          barWidth={3}\n                          barGap={1}\n                          barRadius={4}\n                          fadeEdges={true}\n                          fadeWidth={24}\n                          sensitivity={1.8}\n                          smoothingTimeConstant={0.85}\n                          height={20}\n                          mode=\"static\"\n                          className={cn(\n                            \"h-full w-full transition-opacity duration-300\",\n                            agentState === \"disconnected\" && \"opacity-0\"\n                          )}\n                        />\n                        {agentState === \"disconnected\" && (\n                          <div className=\"absolute inset-0 flex items-center justify-center\">\n                            <span className=\"text-foreground/50 text-[10px] font-medium\">\n                              Customer Support\n                            </span>\n                          </div>\n                        )}\n                      </div>\n                    </div>\n                  </div>\n                </div>\n                <div className=\"flex items-center\">\n                  <Button\n                    variant=\"ghost\"\n                    size=\"icon\"\n                    onClick={toggleMute}\n                    aria-pressed={isMuted}\n                    className={cn(isMuted ? \"bg-foreground/5\" : \"\")}\n                    disabled={!isConnected}\n                  >\n                    {isMuted ? <MicOff /> : <Mic />}\n                  </Button>\n                  <Button\n                    variant=\"ghost\"\n                    size=\"icon\"\n                    onClick={() => setKeyboardOpen((v) => !v)}\n                    aria-pressed={keyboardOpen}\n                    className=\"relative\"\n                    disabled={!isConnected}\n                  >\n                    <Keyboard\n                      className={\n                        \"h-5 w-5 transform-gpu transition-all duration-200 ease-[cubic-bezier(0.22,1,0.36,1)] \" +\n                        (keyboardOpen\n                          ? \"scale-75 opacity-0\"\n                          : \"scale-100 opacity-100\")\n                      }\n                    />\n                    <ChevronDown\n                      className={\n                        \"absolute inset-0 m-auto h-5 w-5 transform-gpu transition-all delay-50 duration-200 ease-[cubic-bezier(0.34,1.56,0.64,1)] \" +\n                        (keyboardOpen\n                          ? \"scale-100 opacity-100\"\n                          : \"scale-75 opacity-0\")\n                      }\n                    />\n                  </Button>\n                  <Separator orientation=\"vertical\" className=\"mx-1 -my-2.5\" />\n                  <Button\n                    variant=\"ghost\"\n                    size=\"icon\"\n                    onClick={handleStartOrEnd}\n                    disabled={agentState === \"disconnecting\"}\n                  >\n                    {isConnected || agentState === \"connecting\" ? (\n                      <XIcon className=\"h-5 w-5\" />\n                    ) : (\n                      <PhoneIcon className=\"h-5 w-5\" />\n                    )}\n                  </Button>\n                </div>\n              </div>\n            </div>\n\n            <div\n              className={cn(\n                \"overflow-hidden transition-all duration-300 ease-out\",\n                keyboardOpen ? \"max-h-[120px]\" : \"max-h-0\"\n              )}\n            >\n              <div className=\"relative px-2 pt-2 pb-2\">\n                <Textarea\n                  value={textInput}\n                  onChange={handleTextChange}\n                  onKeyDown={handleKeyDown}\n                  placeholder=\"Enter your message...\"\n                  className=\"min-h-[100px] resize-none border-0 pr-12 shadow-none focus-visible:ring-0\"\n                  disabled={!isConnected}\n                />\n                <Button\n                  size=\"icon\"\n                  variant=\"ghost\"\n                  onClick={handleSendText}\n                  disabled={!textInput.trim() || !isConnected}\n                  className=\"absolute right-3 bottom-3 h-8 w-8\"\n                >\n                  <ArrowUpIcon className=\"h-4 w-4\" />\n                </Button>\n              </div>\n            </div>\n          </div>\n        </Card>\n      </div>\n    )\n  }\n)\n\nConversationBar.displayName = \"ConversationBar\"\n"
    },
    {
      "path": "components/ui/mic-selector.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport { useCallback, useEffect, useState } from \"react\"\nimport { Check, ChevronsUpDown, Mic, MicOff } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\nimport { Button } from \"@/components/ui/button\"\nimport {\n  DropdownMenu,\n  DropdownMenuContent,\n  DropdownMenuItem,\n  DropdownMenuSeparator,\n  DropdownMenuTrigger,\n} from \"@/components/ui/dropdown-menu\"\nimport { LiveWaveform } from \"@/components/ui/live-waveform\"\n\nexport interface AudioDevice {\n  deviceId: string\n  label: string\n  groupId: string\n}\n\nexport interface MicSelectorProps {\n  value?: string\n  onValueChange?: (deviceId: string) => void\n  muted?: boolean\n  onMutedChange?: (muted: boolean) => void\n  disabled?: boolean\n  className?: string\n}\n\nexport function MicSelector({\n  value,\n  onValueChange,\n  muted,\n  onMutedChange,\n  disabled,\n  className,\n}: MicSelectorProps) {\n  const { devices, loading, error, hasPermission, loadDevices } =\n    useAudioDevices()\n  const [selectedDevice, setSelectedDevice] = useState<string>(value || \"\")\n  const [internalMuted, setInternalMuted] = useState(false)\n  const [isDropdownOpen, setIsDropdownOpen] = useState(false)\n\n  // Use controlled muted if provided, otherwise use internal state\n  const isMuted = muted !== undefined ? muted : internalMuted\n\n  // Update internal state when controlled value changes\n  useEffect(() => {\n    if (value !== undefined) {\n      setSelectedDevice(value)\n    }\n  }, [value])\n\n  // Select first device by default\n  const defaultDeviceId = devices[0]?.deviceId || \"\"\n  useEffect(() => {\n    if (!selectedDevice && defaultDeviceId) {\n      const newDevice = defaultDeviceId\n      setSelectedDevice(newDevice)\n      onValueChange?.(newDevice)\n    }\n  }, [defaultDeviceId, selectedDevice, onValueChange])\n\n  const currentDevice = devices.find((d) => d.deviceId === selectedDevice) ||\n    devices[0] || {\n      label: loading ? \"Loading...\" : \"No microphone\",\n      deviceId: \"\",\n    }\n\n  const handleDeviceSelect = (deviceId: string, e?: React.MouseEvent) => {\n    e?.preventDefault()\n    setSelectedDevice(deviceId)\n    onValueChange?.(deviceId)\n  }\n\n  const handleDropdownOpenChange = async (open: boolean) => {\n    setIsDropdownOpen(open)\n    if (open && !hasPermission && !loading) {\n      await loadDevices()\n    }\n  }\n\n  const toggleMute = () => {\n    const newMuted = !isMuted\n    if (muted === undefined) {\n      setInternalMuted(newMuted)\n    }\n    onMutedChange?.(newMuted)\n  }\n\n  const isPreviewActive = isDropdownOpen && !isMuted\n\n  return (\n    <DropdownMenu onOpenChange={handleDropdownOpenChange}>\n      <DropdownMenuTrigger asChild>\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className={cn(\n            \"hover:bg-accent flex w-48 cursor-pointer items-center gap-1.5\",\n            className\n          )}\n          disabled={loading || disabled}\n        >\n          {isMuted ? (\n            <MicOff className=\"h-4 w-4 flex-shrink-0\" />\n          ) : (\n            <Mic className=\"h-4 w-4 flex-shrink-0\" />\n          )}\n          <span className=\"flex-1 truncate text-left\">\n            {currentDevice.label}\n          </span>\n          <ChevronsUpDown className=\"h-3 w-3 flex-shrink-0\" />\n        </Button>\n      </DropdownMenuTrigger>\n      <DropdownMenuContent align=\"center\" side=\"top\" className=\"w-72\">\n        {loading ? (\n          <DropdownMenuItem disabled>Loading devices...</DropdownMenuItem>\n        ) : error ? (\n          <DropdownMenuItem disabled>Error: {error}</DropdownMenuItem>\n        ) : (\n          devices.map((device) => (\n            <DropdownMenuItem\n              key={device.deviceId}\n              onClick={(e) => handleDeviceSelect(device.deviceId, e)}\n              onSelect={(e) => e.preventDefault()}\n              className=\"flex items-center justify-between\"\n            >\n              <span className=\"truncate\">{device.label}</span>\n              {selectedDevice === device.deviceId && (\n                <Check className=\"h-4 w-4 flex-shrink-0\" />\n              )}\n            </DropdownMenuItem>\n          ))\n        )}\n        {devices.length > 0 && (\n          <>\n            <DropdownMenuSeparator />\n            <div className=\"flex items-center gap-2 p-2\">\n              <Button\n                variant=\"ghost\"\n                size=\"sm\"\n                onClick={(e) => {\n                  e.preventDefault()\n                  toggleMute()\n                }}\n                className=\"h-8 gap-2\"\n              >\n                {isMuted ? (\n                  <MicOff className=\"h-4 w-4\" />\n                ) : (\n                  <Mic className=\"h-4 w-4\" />\n                )}\n                <span className=\"text-sm\">{isMuted ? \"Unmute\" : \"Mute\"}</span>\n              </Button>\n              <div className=\"bg-accent ml-auto w-16 overflow-hidden rounded-md p-1.5\">\n                <LiveWaveform\n                  active={isPreviewActive}\n                  deviceId={selectedDevice || defaultDeviceId}\n                  mode=\"static\"\n                  height={15}\n                  barWidth={3}\n                  barGap={1}\n                />\n              </div>\n            </div>\n          </>\n        )}\n      </DropdownMenuContent>\n    </DropdownMenu>\n  )\n}\n\nexport function useAudioDevices() {\n  const [devices, setDevices] = useState<AudioDevice[]>([])\n  const [loading, setLoading] = useState(true)\n  const [error, setError] = useState<string | null>(null)\n  const [hasPermission, setHasPermission] = useState(false)\n\n  const loadDevicesWithoutPermission = useCallback(async () => {\n    try {\n      setLoading(true)\n      setError(null)\n\n      const deviceList = await navigator.mediaDevices.enumerateDevices()\n\n      const audioInputs = deviceList\n        .filter((device) => device.kind === \"audioinput\")\n        .map((device) => {\n          let cleanLabel =\n            device.label || `Microphone ${device.deviceId.slice(0, 8)}`\n          cleanLabel = cleanLabel.replace(/\\s*\\([^)]*\\)/g, \"\").trim()\n\n          return {\n            deviceId: device.deviceId,\n            label: cleanLabel,\n            groupId: device.groupId,\n          }\n        })\n\n      setDevices(audioInputs)\n    } catch (err) {\n      setError(\n        err instanceof Error ? err.message : \"Failed to get audio devices\"\n      )\n      console.error(\"Error getting audio devices:\", err)\n    } finally {\n      setLoading(false)\n    }\n  }, [])\n\n  const loadDevicesWithPermission = useCallback(async () => {\n    if (loading) return\n\n    try {\n      setLoading(true)\n      setError(null)\n\n      const tempStream = await navigator.mediaDevices.getUserMedia({\n        audio: true,\n      })\n      tempStream.getTracks().forEach((track) => track.stop())\n\n      const deviceList = await navigator.mediaDevices.enumerateDevices()\n\n      const audioInputs = deviceList\n        .filter((device) => device.kind === \"audioinput\")\n        .map((device) => {\n          let cleanLabel =\n            device.label || `Microphone ${device.deviceId.slice(0, 8)}`\n          cleanLabel = cleanLabel.replace(/\\s*\\([^)]*\\)/g, \"\").trim()\n\n          return {\n            deviceId: device.deviceId,\n            label: cleanLabel,\n            groupId: device.groupId,\n          }\n        })\n\n      setDevices(audioInputs)\n      setHasPermission(true)\n    } catch (err) {\n      setError(\n        err instanceof Error ? err.message : \"Failed to get audio devices\"\n      )\n      console.error(\"Error getting audio devices:\", err)\n    } finally {\n      setLoading(false)\n    }\n  }, [loading])\n\n  useEffect(() => {\n    loadDevicesWithoutPermission()\n  }, [loadDevicesWithoutPermission])\n\n  useEffect(() => {\n    const handleDeviceChange = () => {\n      if (hasPermission) {\n        loadDevicesWithPermission()\n      } else {\n        loadDevicesWithoutPermission()\n      }\n    }\n\n    navigator.mediaDevices.addEventListener(\"devicechange\", handleDeviceChange)\n\n    return () => {\n      navigator.mediaDevices.removeEventListener(\n        \"devicechange\",\n        handleDeviceChange\n      )\n    }\n  }, [hasPermission, loadDevicesWithPermission, loadDevicesWithoutPermission])\n\n  return {\n    devices,\n    loading,\n    error,\n    hasPermission,\n    loadDevices: loadDevicesWithPermission,\n  }\n}\n"
    },
    {
      "path": "components/ui/transcript-viewer.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport {\n  createContext,\n  useContext,\n  useMemo,\n  type ComponentPropsWithoutRef,\n  type ComponentPropsWithRef,\n  type HTMLAttributes,\n  type ReactNode,\n} from \"react\"\nimport type { CharacterAlignmentResponseModel } from \"@elevenlabs/elevenlabs-js/api/types/CharacterAlignmentResponseModel\"\nimport { Pause, Play } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\nimport {\n  useTranscriptViewer,\n  type SegmentComposer,\n  type TranscriptSegment,\n  type TranscriptWord as TranscriptWordType,\n  type UseTranscriptViewerResult,\n} from \"@/registry/elevenlabs-ui/hooks/use-transcript-viewer\"\nimport { Button } from \"@/components/ui/button\"\nimport {\n  ScrubBarContainer,\n  ScrubBarProgress,\n  ScrubBarThumb,\n  ScrubBarTimeLabel,\n  ScrubBarTrack,\n} from \"@/components/ui/scrub-bar\"\n\ntype TranscriptGap = Extract<TranscriptSegment, { kind: \"gap\" }>\n\ntype TranscriptViewerContextValue = UseTranscriptViewerResult & {\n  audioProps: Omit<ComponentPropsWithRef<\"audio\">, \"children\" | \"src\">\n}\n\nconst TranscriptViewerContext =\n  createContext<TranscriptViewerContextValue | null>(null)\n\nfunction useTranscriptViewerContext() {\n  const context = useContext(TranscriptViewerContext)\n  if (!context) {\n    throw new Error(\n      \"useTranscriptViewerContext must be used within a TranscriptViewer\"\n    )\n  }\n  return context\n}\n\ntype TranscriptViewerProviderProps = {\n  value: TranscriptViewerContextValue\n  children: ReactNode\n}\n\nfunction TranscriptViewerProvider({\n  value,\n  children,\n}: TranscriptViewerProviderProps) {\n  return (\n    <TranscriptViewerContext.Provider value={value}>\n      {children}\n    </TranscriptViewerContext.Provider>\n  )\n}\n\ntype AudioType =\n  | \"audio/mpeg\"\n  | \"audio/wav\"\n  | \"audio/ogg\"\n  | \"audio/mp3\"\n  | \"audio/m4a\"\n  | \"audio/aac\"\n  | \"audio/webm\"\n\ntype TranscriptViewerContainerProps = {\n  audioSrc: string\n  audioType: AudioType\n  alignment: CharacterAlignmentResponseModel\n  segmentComposer?: SegmentComposer\n  hideAudioTags?: boolean\n  children?: ReactNode\n} & Omit<ComponentPropsWithoutRef<\"div\">, \"children\"> &\n  Pick<\n    Parameters<typeof useTranscriptViewer>[0],\n    \"onPlay\" | \"onPause\" | \"onTimeUpdate\" | \"onEnded\" | \"onDurationChange\"\n  >\n\nfunction TranscriptViewerContainer({\n  audioSrc,\n  audioType = \"audio/mpeg\",\n  alignment,\n  segmentComposer,\n  hideAudioTags = true,\n  children,\n  className,\n  onPlay,\n  onPause,\n  onTimeUpdate,\n  onEnded,\n  onDurationChange,\n  ...props\n}: TranscriptViewerContainerProps) {\n  const viewerState = useTranscriptViewer({\n    alignment,\n    hideAudioTags,\n    segmentComposer,\n    onPlay,\n    onPause,\n    onTimeUpdate,\n    onEnded,\n    onDurationChange,\n  })\n\n  const { audioRef } = viewerState\n\n  const audioProps = useMemo(\n    () => ({\n      ref: audioRef,\n      controls: false,\n      preload: \"metadata\" as const,\n      src: audioSrc,\n      children: <source src={audioSrc} type={audioType} />,\n    }),\n    [audioRef, audioSrc]\n  )\n\n  const contextValue = useMemo(\n    () => ({\n      ...viewerState,\n      audioProps,\n    }),\n    [viewerState, audioProps]\n  )\n\n  return (\n    <TranscriptViewerProvider value={contextValue}>\n      <div\n        data-slot=\"transcript-viewer-root\"\n        className={cn(\"space-y-4 p-4\", className)}\n        {...props}\n      >\n        {children}\n      </div>\n    </TranscriptViewerProvider>\n  )\n}\n\ntype TranscriptViewerWordStatus = \"spoken\" | \"unspoken\" | \"current\"\ninterface TranscriptViewerWordProps\n  extends Omit<HTMLAttributes<HTMLSpanElement>, \"children\"> {\n  word: TranscriptWordType\n  status: TranscriptViewerWordStatus\n  children?: ReactNode\n}\n\nfunction TranscriptViewerWord({\n  word,\n  status,\n  className,\n  children,\n  ...props\n}: TranscriptViewerWordProps) {\n  return (\n    <span\n      data-slot=\"transcript-word\"\n      data-kind=\"word\"\n      data-status={status}\n      className={cn(\n        \"rounded-sm px-0.5 transition-colors\",\n        status === \"spoken\" && \"text-foreground\",\n        status === \"unspoken\" && \"text-muted-foreground\",\n        status === \"current\" && \"bg-primary text-primary-foreground\",\n        className\n      )}\n      {...props}\n    >\n      {children ?? word.text}\n    </span>\n  )\n}\n\ninterface TranscriptViewerWordsProps extends HTMLAttributes<HTMLDivElement> {\n  renderWord?: (props: {\n    word: TranscriptWordType\n    status: TranscriptViewerWordStatus\n  }) => ReactNode\n  renderGap?: (props: {\n    segment: TranscriptGap\n    status: TranscriptViewerWordStatus\n  }) => ReactNode\n  wordClassNames?: string\n  gapClassNames?: string\n}\n\nfunction TranscriptViewerWords({\n  className,\n  renderWord,\n  renderGap,\n  wordClassNames,\n  gapClassNames,\n  ...props\n}: TranscriptViewerWordsProps) {\n  const {\n    spokenSegments,\n    unspokenSegments,\n    currentWord,\n    segments,\n    duration,\n    currentTime,\n  } = useTranscriptViewerContext()\n\n  const nearEnd = useMemo(() => {\n    if (!duration) return false\n    return currentTime >= duration - 0.01\n  }, [currentTime, duration])\n\n  const segmentsWithStatus = useMemo(() => {\n    if (nearEnd) {\n      return segments.map((segment) => ({ segment, status: \"spoken\" as const }))\n    }\n\n    const entries: Array<{\n      segment: TranscriptSegment\n      status: TranscriptViewerWordStatus\n    }> = []\n\n    for (const segment of spokenSegments) {\n      entries.push({ segment, status: \"spoken\" })\n    }\n\n    if (currentWord) {\n      entries.push({ segment: currentWord, status: \"current\" })\n    }\n\n    for (const segment of unspokenSegments) {\n      entries.push({ segment, status: \"unspoken\" })\n    }\n\n    return entries\n  }, [spokenSegments, unspokenSegments, currentWord, nearEnd, segments])\n\n  return (\n    <div\n      data-slot=\"transcript-words\"\n      className={cn(\"text-xl leading-relaxed\", className)}\n      {...props}\n    >\n      {segmentsWithStatus.map(({ segment, status }) => {\n        if (segment.kind === \"gap\") {\n          const content = renderGap\n            ? renderGap({ segment, status })\n            : segment.text\n          return (\n            <span\n              key={`gap-${segment.segmentIndex}`}\n              data-kind=\"gap\"\n              data-status={status}\n              className={cn(gapClassNames)}\n            >\n              {content}\n            </span>\n          )\n        }\n\n        if (renderWord) {\n          return (\n            <span\n              key={`word-${segment.segmentIndex}`}\n              data-kind=\"word\"\n              data-status={status}\n              className={cn(wordClassNames)}\n            >\n              {renderWord({ word: segment, status })}\n            </span>\n          )\n        }\n\n        return (\n          <TranscriptViewerWord\n            key={`word-${segment.segmentIndex}`}\n            word={segment}\n            status={status}\n            className={wordClassNames}\n          />\n        )\n      })}\n    </div>\n  )\n}\n\nfunction TranscriptViewerAudio({\n  ...props\n}: ComponentPropsWithoutRef<\"audio\">) {\n  const { audioProps } = useTranscriptViewerContext()\n  return (\n    <audio\n      data-slot=\"transcript-audio\"\n      {...audioProps}\n      {...props}\n      ref={audioProps.ref}\n    />\n  )\n}\n\ntype RenderChildren = (state: { isPlaying: boolean }) => ReactNode\n\ntype TranscriptViewerPlayPauseButtonProps = Omit<\n  ComponentPropsWithoutRef<typeof Button>,\n  \"children\"\n> & {\n  children?: ReactNode | RenderChildren\n}\n\nfunction TranscriptViewerPlayPauseButton({\n  className,\n  children,\n  onClick,\n  ...props\n}: TranscriptViewerPlayPauseButtonProps) {\n  const { isPlaying, play, pause } = useTranscriptViewerContext()\n  const Icon = isPlaying ? Pause : Play\n\n  const handleClick = (event: React.MouseEvent<HTMLButtonElement>) => {\n    if (isPlaying) pause()\n    else play()\n    onClick?.(event)\n  }\n\n  const content =\n    typeof children === \"function\"\n      ? (children as RenderChildren)({ isPlaying })\n      : children\n\n  return (\n    <Button\n      data-slot=\"transcript-play-pause-button\"\n      type=\"button\"\n      variant=\"outline\"\n      size=\"icon\"\n      aria-label={isPlaying ? \"Pause audio\" : \"Play audio\"}\n      data-playing={isPlaying}\n      className={cn(\"cursor-pointer\", className)}\n      onClick={handleClick}\n      {...props}\n    >\n      {content ?? <Icon className=\"size-5\" />}\n    </Button>\n  )\n}\n\ntype TranscriptViewerScrubBarProps = Omit<\n  ComponentPropsWithoutRef<typeof ScrubBarContainer>,\n  \"duration\" | \"value\" | \"onScrub\" | \"onScrubStart\" | \"onScrubEnd\"\n> & {\n  showTimeLabels?: boolean\n  labelsClassName?: string\n  trackClassName?: string\n  progressClassName?: string\n  thumbClassName?: string\n}\n\n/**\n * A context-aware implementation of the scrub bar specific to the transcript viewer.\n */\nfunction TranscriptViewerScrubBar({\n  className,\n  showTimeLabels = true,\n  labelsClassName,\n  trackClassName,\n  progressClassName,\n  thumbClassName,\n  ...props\n}: TranscriptViewerScrubBarProps) {\n  const { duration, currentTime, seekToTime, startScrubbing, endScrubbing } =\n    useTranscriptViewerContext()\n  return (\n    <ScrubBarContainer\n      data-slot=\"transcript-scrub-bar\"\n      duration={duration}\n      value={currentTime}\n      onScrubStart={startScrubbing}\n      onScrubEnd={endScrubbing}\n      onScrub={seekToTime}\n      className={className}\n      {...props}\n    >\n      <div className=\"flex flex-1 flex-col gap-1\">\n        <ScrubBarTrack className={trackClassName}>\n          <ScrubBarProgress className={progressClassName} />\n          <ScrubBarThumb className={thumbClassName} />\n        </ScrubBarTrack>\n        {showTimeLabels && (\n          <div\n            className={cn(\n              \"text-muted-foreground flex items-center justify-between text-xs\",\n              labelsClassName\n            )}\n          >\n            <ScrubBarTimeLabel time={currentTime} />\n            <ScrubBarTimeLabel time={duration - currentTime} />\n          </div>\n        )}\n      </div>\n    </ScrubBarContainer>\n  )\n}\n\nexport {\n  TranscriptViewerContainer,\n  TranscriptViewerWords,\n  TranscriptViewerWord,\n  TranscriptViewerAudio,\n  TranscriptViewerPlayPauseButton,\n  TranscriptViewerScrubBar,\n  TranscriptViewerProvider,\n  useTranscriptViewerContext,\n}\nexport type { CharacterAlignmentResponseModel }\n"
    },
    {
      "path": "components/ui/scrub-bar.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport * as React from \"react\"\nimport {\n  createContext,\n  useCallback,\n  useContext,\n  useRef,\n  type ComponentProps,\n  type HTMLAttributes,\n} from \"react\"\n\nimport { cn } from \"@/lib/utils\"\nimport { Progress } from \"@/components/ui/progress\"\n\nfunction formatTimestamp(value: number) {\n  if (!Number.isFinite(value) || value < 0) return \"0:00\"\n  const totalSeconds = Math.floor(value)\n  const minutes = Math.floor(totalSeconds / 60)\n  const seconds = totalSeconds % 60\n  return `${minutes}:${seconds.toString().padStart(2, \"0\")}`\n}\n\ninterface ScrubBarContextValue {\n  duration: number\n  value: number\n  progress: number\n  onScrub?: (time: number) => void\n  onScrubStart?: () => void\n  onScrubEnd?: () => void\n}\n\nconst ScrubBarContext = createContext<ScrubBarContextValue | null>(null)\n\nfunction useScrubBarContext() {\n  const context = useContext(ScrubBarContext)\n  if (!context) {\n    throw new Error(\"useScrubBarContext must be used within a ScrubBar.Root\")\n  }\n  return context\n}\n\ninterface ScrubBarContainerProps extends HTMLAttributes<HTMLDivElement> {\n  duration: number\n  value: number\n  onScrub?: (time: number) => void\n  onScrubStart?: () => void\n  onScrubEnd?: () => void\n}\n\nfunction ScrubBarContainer({\n  duration,\n  value,\n  onScrub,\n  onScrubStart,\n  onScrubEnd,\n  children,\n  className,\n  ...props\n}: ScrubBarContainerProps) {\n  const progress = duration > 0 ? (value / duration) * 100 : 0\n\n  const contextValue: ScrubBarContextValue = {\n    duration,\n    value,\n    progress,\n    onScrub,\n    onScrubStart,\n    onScrubEnd,\n  }\n\n  return (\n    <ScrubBarContext.Provider value={contextValue}>\n      <div\n        data-slot=\"scrub-bar-root\"\n        className={cn(\"flex w-full items-center\", className)}\n        {...props}\n      >\n        {children}\n      </div>\n    </ScrubBarContext.Provider>\n  )\n}\nScrubBarContainer.displayName = \"ScrubBarContainer\"\n\ntype ScrubBarTrackProps = HTMLAttributes<HTMLDivElement>\n\nfunction ScrubBarTrack({ className, children, ...props }: ScrubBarTrackProps) {\n  const trackRef = useRef<HTMLDivElement | null>(null)\n  const { duration, onScrub, onScrubStart, onScrubEnd, value } =\n    useScrubBarContext()\n\n  const getTimeFromClientX = useCallback(\n    (clientX: number) => {\n      const track = trackRef.current\n      if (!track || !duration) return null\n      const rect = track.getBoundingClientRect()\n      const ratio = (clientX - rect.left) / rect.width\n      const clamped = Math.min(Math.max(ratio, 0), 1)\n      return duration * clamped\n    },\n    [duration]\n  )\n\n  const handlePointerDown = useCallback(\n    (event: React.PointerEvent<HTMLDivElement>) => {\n      if (!duration) return\n      event.preventDefault()\n      onScrubStart?.()\n      const time = getTimeFromClientX(event.clientX)\n      if (time != null) {\n        onScrub?.(time)\n      }\n\n      const handleMove = (moveEvent: PointerEvent) => {\n        const nextTime = getTimeFromClientX(moveEvent.clientX)\n        if (nextTime != null) {\n          onScrub?.(nextTime)\n        }\n      }\n\n      const handleUp = () => {\n        onScrubEnd?.()\n        window.removeEventListener(\"pointermove\", handleMove)\n        window.removeEventListener(\"pointerup\", handleUp)\n      }\n\n      window.addEventListener(\"pointermove\", handleMove)\n      window.addEventListener(\"pointerup\", handleUp, { once: true })\n    },\n    [duration, getTimeFromClientX, onScrub, onScrubEnd, onScrubStart]\n  )\n\n  const clampedValue = Math.min(Math.max(value, 0), duration || 0)\n\n  return (\n    <div\n      ref={trackRef}\n      data-slot=\"scrub-bar-track\"\n      className={cn(\n        \"bg-secondary relative h-2 w-full grow cursor-pointer touch-none rounded-full transition-none select-none\",\n        className\n      )}\n      onPointerDown={handlePointerDown}\n      role=\"slider\"\n      aria-valuemin={0}\n      aria-valuemax={duration || 0}\n      aria-valuenow={clampedValue}\n      {...props}\n    >\n      {children}\n    </div>\n  )\n}\nScrubBarTrack.displayName = \"ScrubBarTrack\"\n\ntype ScrubBarProgressProps = Omit<ComponentProps<typeof Progress>, \"value\">\n\nfunction ScrubBarProgress({ className, ...props }: ScrubBarProgressProps) {\n  const { progress } = useScrubBarContext()\n\n  return (\n    <Progress\n      data-slot=\"scrub-bar-progress\"\n      value={progress}\n      className={cn(\"absolute h-full [&>div]:transition-none\", className)}\n      {...props}\n    />\n  )\n}\nScrubBarProgress.displayName = \"ScrubBarProgress\"\n\ntype ScrubBarThumbProps = HTMLAttributes<HTMLDivElement>\n\nfunction ScrubBarThumb({ className, children, ...props }: ScrubBarThumbProps) {\n  const { progress } = useScrubBarContext()\n  return (\n    <div\n      data-slot=\"scrub-bar-thumb\"\n      className={cn(\n        \"bg-primary absolute top-1/2 block h-4 w-4 -translate-x-1/2 -translate-y-1/2 rounded-full transition-colors disabled:pointer-events-none disabled:opacity-50\",\n        className\n      )}\n      style={{ left: `${progress}%` }}\n      {...props}\n    >\n      {children}\n    </div>\n  )\n}\nScrubBarThumb.displayName = \"ScrubBarThumb\"\n\ninterface ScrubBarTimeLabelProps extends HTMLAttributes<HTMLSpanElement> {\n  time: number\n  format?: (time: number) => string\n}\n\nfunction ScrubBarTimeLabel({\n  className,\n  time,\n  format = formatTimestamp,\n  ...props\n}: ScrubBarTimeLabelProps) {\n  return (\n    <span\n      data-slot=\"scrub-bar-time-label\"\n      {...props}\n      className={cn(\"tabular-nums\", className)}\n    >\n      {format(time)}\n    </span>\n  )\n}\nScrubBarTimeLabel.displayName = \"ScrubBarTimeLabel\"\n\nexport {\n  ScrubBarContainer,\n  ScrubBarTrack,\n  ScrubBarProgress,\n  ScrubBarThumb,\n  ScrubBarTimeLabel,\n}\n"
    },
    {
      "path": "components/ui/speech-input.tsx",
      "type": "registry:ui",
      "target": "",
      "content": "\"use client\"\n\nimport {\n  Children,\n  createContext,\n  forwardRef,\n  isValidElement,\n  useCallback,\n  useContext,\n  useEffect,\n  useRef,\n  type ComponentPropsWithoutRef,\n  type ReactNode,\n} from \"react\"\nimport { cva, VariantProps } from \"class-variance-authority\"\nimport { motion } from \"framer-motion\"\nimport { MicIcon, SquareIcon, XIcon } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\nimport {\n  useScribe,\n  type AudioFormat,\n  type CommitStrategy,\n} from \"@/registry/elevenlabs-ui/hooks/use-scribe\"\nimport { Button } from \"@/components/ui/button\"\n\nconst buttonVariants = cva(\"!px-0\", {\n  variants: {\n    size: {\n      default: \"h-9 w-9\",\n      sm: \"h-8 w-8\",\n      lg: \"h-10 w-10\",\n    },\n  },\n  defaultVariants: {\n    size: \"default\",\n  },\n})\n\n// Context for sharing state between compound components\ninterface SpeechInputContextValue {\n  isConnected: boolean\n  isConnecting: boolean\n  transcript: string\n  partialTranscript: string\n  committedTranscripts: string[]\n  error: string | null\n  start: () => Promise<void>\n  stop: () => void\n  cancel: () => void\n  size: VariantProps<typeof buttonVariants>[\"size\"]\n}\n\nconst SpeechInputContext = createContext<SpeechInputContextValue | null>(null)\n\nfunction useSpeechInput() {\n  const context = useContext(SpeechInputContext)\n  if (!context) {\n    throw new Error(\n      \"SpeechInput compound components must be used within a SpeechInput\"\n    )\n  }\n  return context\n}\n\n// Root component\ninterface SpeechInputEvent {\n  partialTranscript: string\n  committedTranscripts: string[]\n  transcript: string\n}\n\ninterface SpeechInputProps {\n  children: ReactNode\n  getToken: () => Promise<string>\n  onChange?: (event: SpeechInputEvent) => void\n  onCancel?: (event: SpeechInputEvent) => void\n  onStart?: (event: SpeechInputEvent) => void\n  onStop?: (event: SpeechInputEvent) => void\n  className?: string\n  size?: VariantProps<typeof buttonVariants>[\"size\"]\n\n  // Connection options\n  modelId?: string\n  baseUri?: string\n\n  // VAD options\n  commitStrategy?: CommitStrategy\n  vadSilenceThresholdSecs?: number\n  vadThreshold?: number\n  minSpeechDurationMs?: number\n  minSilenceDurationMs?: number\n  languageCode?: string\n\n  // Microphone options (for automatic microphone mode)\n  microphone?: {\n    deviceId?: string\n    echoCancellation?: boolean\n    noiseSuppression?: boolean\n    autoGainControl?: boolean\n    channelCount?: number\n  }\n\n  // Manual audio options\n  audioFormat?: AudioFormat\n  sampleRate?: number\n\n  // Error callbacks\n  onError?: (error: Error | Event) => void\n  onAuthError?: (data: { error: string }) => void\n  onQuotaExceededError?: (data: { error: string }) => void\n}\n\nconst buildTranscript = ({\n  partialTranscript,\n  committedTranscripts,\n}: {\n  partialTranscript: string\n  committedTranscripts: string[]\n}): string => {\n  const committed = committedTranscripts.join(\" \").trim()\n  const partial = partialTranscript.trim()\n\n  if (committed && partial) {\n    return `${committed} ${partial}`\n  }\n  return committed || partial\n}\n\nconst buildEvent = ({\n  partialTranscript,\n  committedTranscripts,\n}: {\n  partialTranscript: string\n  committedTranscripts: string[]\n}): SpeechInputEvent => {\n  return {\n    partialTranscript,\n    committedTranscripts,\n    transcript: buildTranscript({ partialTranscript, committedTranscripts }),\n  }\n}\n\nconst SpeechInput = forwardRef<HTMLDivElement, SpeechInputProps>(\n  function SpeechInput(\n    {\n      children,\n      getToken,\n      onChange,\n      onCancel,\n      onStart,\n      onStop,\n      className,\n      size = \"default\",\n      modelId = \"scribe_v2_realtime\",\n      baseUri,\n      commitStrategy,\n      vadSilenceThresholdSecs,\n      vadThreshold,\n      minSpeechDurationMs,\n      minSilenceDurationMs,\n      languageCode,\n      microphone = {\n        echoCancellation: true,\n        noiseSuppression: true,\n      },\n      audioFormat,\n      sampleRate,\n      onError,\n      onAuthError,\n      onQuotaExceededError,\n    },\n    ref\n  ) {\n    const transcriptsRef = useRef({\n      partialTranscript: \"\",\n      committedTranscripts: [] as string[],\n    })\n    const startRequestIdRef = useRef(0)\n\n    const scribe = useScribe({\n      modelId,\n      baseUri,\n      commitStrategy,\n      vadSilenceThresholdSecs,\n      vadThreshold,\n      minSpeechDurationMs,\n      minSilenceDurationMs,\n      languageCode,\n      audioFormat,\n      sampleRate,\n      microphone,\n      onPartialTranscript: (data) => {\n        transcriptsRef.current.partialTranscript = data.text\n        onChange?.(buildEvent(transcriptsRef.current))\n      },\n      onCommittedTranscript: (data) => {\n        transcriptsRef.current.committedTranscripts.push(data.text)\n        transcriptsRef.current.partialTranscript = \"\"\n        onChange?.(buildEvent(transcriptsRef.current))\n      },\n      onError,\n      onAuthError,\n      onQuotaExceededError,\n    })\n\n    const isConnecting = scribe.status === \"connecting\"\n\n    const start = useCallback(async () => {\n      const requestId = startRequestIdRef.current + 1\n      startRequestIdRef.current = requestId\n\n      transcriptsRef.current = {\n        partialTranscript: \"\",\n        committedTranscripts: [],\n      }\n      scribe.clearTranscripts()\n\n      try {\n        const token = await getToken()\n        if (startRequestIdRef.current !== requestId) {\n          return\n        }\n\n        await scribe.connect({\n          token,\n        })\n        if (startRequestIdRef.current !== requestId) {\n          scribe.disconnect()\n          return\n        }\n        onStart?.(buildEvent(transcriptsRef.current))\n      } catch {\n        // Error is handled by onError callback\n      }\n      // eslint-disable-next-line react-hooks/exhaustive-deps\n    }, [getToken, scribe, onStart, microphone])\n\n    const stop = () => {\n      startRequestIdRef.current += 1\n      scribe.disconnect()\n      onStop?.(buildEvent(transcriptsRef.current))\n    }\n\n    const cancel = () => {\n      startRequestIdRef.current += 1\n      const event = buildEvent(transcriptsRef.current)\n      scribe.disconnect()\n      scribe.clearTranscripts()\n      transcriptsRef.current = {\n        partialTranscript: \"\",\n        committedTranscripts: [],\n      }\n      onCancel?.(event)\n    }\n\n    const contextValue: SpeechInputContextValue = {\n      isConnected: scribe.isConnected,\n      isConnecting,\n      start,\n      stop,\n      cancel,\n      error: scribe.error,\n      size,\n      ...buildEvent({\n        partialTranscript: scribe.partialTranscript,\n        committedTranscripts: scribe.committedTranscripts.map((t) => t.text),\n      }),\n    }\n\n    useEffect(() => {\n      return () => {\n        startRequestIdRef.current += 1\n        scribe.disconnect()\n      }\n    }, [scribe.disconnect])\n\n    return (\n      <SpeechInputContext.Provider value={contextValue}>\n        <div\n          ref={ref}\n          className={cn(\n            \"relative inline-flex items-center overflow-hidden rounded-lg border border-transparent transition-all duration-200\",\n            scribe.isConnected\n              ? \"bg-background dark:bg-muted border-input shadow-sm\"\n              : \"\",\n            className\n          )}\n        >\n          {children}\n        </div>\n      </SpeechInputContext.Provider>\n    )\n  }\n)\n\n// Record button - toggles between mic icon and stop icon\ntype SpeechInputRecordButtonProps = Omit<\n  ComponentPropsWithoutRef<typeof Button>,\n  \"size\"\n>\n\nconst SpeechInputRecordButton = forwardRef<\n  HTMLButtonElement,\n  SpeechInputRecordButtonProps\n>(function SpeechInputRecordButton(\n  { className, onClick, variant = \"ghost\", disabled, ...props },\n  ref\n) {\n  const speechInput = useSpeechInput()\n\n  return (\n    <Button\n      ref={ref}\n      variant={variant}\n      onClick={(e) => {\n        if (speechInput.isConnected) {\n          speechInput.stop()\n        } else {\n          speechInput.start()\n        }\n        onClick?.(e)\n      }}\n      disabled={disabled ?? speechInput.isConnecting}\n      className={cn(\n        buttonVariants({ size: speechInput.size }),\n        \"relative flex flex-shrink-0 items-center justify-center transition-all\",\n        speechInput.isConnected && \"scale-[80%]\",\n        className\n      )}\n      aria-label={\n        speechInput.isConnected ? \"Stop recording\" : \"Start recording\"\n      }\n      {...props}\n    >\n      <div\n        className={cn(\n          \"bg-primary absolute h-4 w-4 rounded-full transition-all duration-200\",\n          speechInput.isConnecting\n            ? \"scale-90 opacity-100\"\n            : \"scale-[60%] opacity-0\"\n        )}\n      />\n      <SquareIcon\n        className={cn(\n          \"text-destructive absolute h-4 w-4 fill-current transition-all duration-200\",\n          !speechInput.isConnecting && speechInput.isConnected\n            ? \"scale-100 opacity-100\"\n            : \"scale-[60%] opacity-0\"\n        )}\n      />\n      <MicIcon\n        className={cn(\n          \"absolute h-4 w-4 transition-all duration-200\",\n          !speechInput.isConnecting && !speechInput.isConnected\n            ? \"scale-100 opacity-100\"\n            : \"scale-[60%] opacity-0\"\n        )}\n      />\n    </Button>\n  )\n})\n\n// Preview - shows the current transcript with partial\ntype SpeechInputPreviewProps = ComponentPropsWithoutRef<\"div\"> & {\n  placeholder?: string\n}\n\nconst SpeechInputPreview = forwardRef<HTMLDivElement, SpeechInputPreviewProps>(\n  function SpeechInputPreview(\n    { className, placeholder = \"Listening...\", ...props },\n    ref\n  ) {\n    const speechInput = useSpeechInput()\n\n    const displayText =\n      speechInput.transcript || speechInput.partialTranscript || placeholder\n    const showPlaceholder = !speechInput.transcript.trim()\n\n    return (\n      <div\n        ref={ref}\n        // @ts-expect-error inert is not yet in React types\n        inert={speechInput.isConnected ? undefined : \"\"}\n        className={cn(\n          \"relative flex h-8 flex-shrink-0 items-center overflow-hidden text-sm transition-[opacity,transform,width] duration-200 ease-out\",\n          showPlaceholder\n            ? \"text-muted-foreground italic\"\n            : \"text-muted-foreground [mask-image:linear-gradient(to_right,transparent,black_16px,black_calc(100%-16px),transparent)]\",\n          speechInput.isConnected ? \"w-28 opacity-100\" : \"w-0 opacity-0\",\n          className\n        )}\n        title={displayText}\n        aria-hidden={!speechInput.isConnected}\n        {...props}\n      >\n        <motion.p\n          key=\"text\"\n          layout=\"position\"\n          className={`absolute top-0 right-0 bottom-0 flex h-full min-w-full items-center px-0 whitespace-nowrap`}\n        >\n          {displayText}\n        </motion.p>\n      </div>\n    )\n  }\n)\n\n// Cancel button\ntype SpeechInputCancelButtonProps = Omit<\n  ComponentPropsWithoutRef<typeof Button>,\n  \"size\"\n>\n\nconst SpeechInputCancelButton = forwardRef<\n  HTMLButtonElement,\n  SpeechInputCancelButtonProps\n>(function SpeechInputCancelButton(\n  { className, onClick, variant = \"ghost\", ...props },\n  ref\n) {\n  const speechInput = useSpeechInput()\n\n  return (\n    <Button\n      ref={ref}\n      variant={variant}\n      // @ts-expect-error inert is not yet in React types\n      inert={speechInput.isConnected ? undefined : \"\"}\n      onClick={(e) => {\n        speechInput.cancel()\n        onClick?.(e)\n      }}\n      className={cn(\n        buttonVariants({ size: speechInput.size }),\n        \"flex-shrink-0 transition-[opacity,transform,width] duration-200 ease-out\",\n        speechInput.isConnected\n          ? \"scale-[80%] opacity-100\"\n          : \"pointer-events-none w-0 scale-100 opacity-0\",\n        className\n      )}\n      aria-label=\"Cancel recording\"\n      {...props}\n    >\n      <XIcon className=\"h-3 w-3\" />\n    </Button>\n  )\n})\n\nexport {\n  SpeechInput,\n  SpeechInputRecordButton,\n  SpeechInputPreview,\n  SpeechInputCancelButton,\n  useSpeechInput,\n}\n"
    }
  ]
}